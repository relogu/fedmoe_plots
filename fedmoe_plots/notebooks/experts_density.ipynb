{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce54d73d",
   "metadata": {},
   "source": [
    "# Expert Density Analysis for Federated Mixture of Experts\n",
    "\n",
    "This notebook analyzes the impact of expert density (number of local experts per client) on model performance in federated learning scenarios with Mixture of Experts (MoE) architectures.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "1. **Data Collection**: Download metrics from WandB for different expert density configurations\n",
    "2. **Performance Analysis**: Compare perplexity vs. token consumption across configurations\n",
    "3. **Efficiency Evaluation**: Assess the trade-offs between expert density and training efficiency\n",
    "4. **Configuration Impact**: Understand how overlapping factors and client counts affect performance\n",
    "\n",
    "## Key Metrics\n",
    "\n",
    "- **Expert Density**: Number of local experts per client\n",
    "- **Overlapping Factor**: Factor determining expert sharing across clients\n",
    "- **Final Perplexity**: Model performance at the end of training\n",
    "- **Total Tokens**: Computational cost measure\n",
    "- **Efficiency**: Ratio of final perplexity to total tokens consumed\n",
    "\n",
    "## Analysis Workflow\n",
    "\n",
    "1. Load and filter runs from WandB based on run UUID patterns\n",
    "2. Extract configuration parameters for each run\n",
    "3. Download server and client metrics data\n",
    "4. Compute perplexity vs. token relationships\n",
    "5. Aggregate results by configuration parameters\n",
    "6. Generate visualizations and summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b1255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import operator\n",
    "from datetime import UTC, datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "\n",
    "from fedmoe_plots.data_analysis import (\n",
    "    ColumnNotFoundError,\n",
    "    get_device_throughput_series,\n",
    "    get_perplexity_versus_tokens,\n",
    ")\n",
    "from fedmoe_plots.plotting_utils import configure_logging_for_jupyter\n",
    "from fedmoe_plots.wandb_utils import (\n",
    "    ClientRunNotFoundError,\n",
    "    download_photon_metrics,\n",
    "    get_clientrun_property_from_config,\n",
    "    get_experts_global_batch_size,\n",
    "    get_n_local_experts,\n",
    "    get_non_experts_global_batch_size,\n",
    "    get_run_uuid_from_config,\n",
    "    remove_runs_by_regex,\n",
    ")\n",
    "\n",
    "configure_logging_for_jupyter()\n",
    "\n",
    "log = logging.getLogger(\"experts_density.ipynb\")\n",
    "\n",
    "EXCLUDE_INCOMPLETE_RUNS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3d8662",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_uuid_1 = \"4e_rho_bspol_scratch\"\n",
    "run_uuid_2 = \"8e_rho_bspol_scratch\"\n",
    "api = wandb.Api(timeout=100)\n",
    "runs = api.runs(\n",
    "    path=\"camlsys/photon\",\n",
    "    filters={\"display_name\": {\"$regex\": f\"(^{run_uuid_1})|(^{run_uuid_2})\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0be7302",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in runs:\n",
    "    log.info(\"Run name: %s, ID: %s, State: %s\", run.name, run.id, run.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181b0f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_n_total_clients = {\n",
    "    get_clientrun_property_from_config(\n",
    "        run,\n",
    "        get_property_fn=lambda config: config[\"fl\"][\"n_total_clients\"],\n",
    "    )\n",
    "    for run in runs\n",
    "}\n",
    "unique_local_batch_size = {\n",
    "    get_clientrun_property_from_config(\n",
    "        run,\n",
    "        get_property_fn=lambda config: config[\"llm_config\"][\"global_train_batch_size\"],\n",
    "    )\n",
    "    for run in runs\n",
    "}\n",
    "unique_overlapping_factor = {\n",
    "    get_clientrun_property_from_config(\n",
    "        run,\n",
    "        get_property_fn=lambda config: config[\"fl\"][\"experts_overlapping_factor\"],\n",
    "    )\n",
    "    for run in runs\n",
    "}\n",
    "unique_n_total_experts = {\n",
    "    get_clientrun_property_from_config(\n",
    "        run,\n",
    "        get_property_fn=lambda config: config[\"llm_config\"][\"model\"][\"ffn_config\"][\n",
    "            \"ff_n_experts\"\n",
    "        ],\n",
    "    )\n",
    "    for run in runs\n",
    "}\n",
    "unique_n_local_experts = {\n",
    "    get_clientrun_property_from_config(\n",
    "        run,\n",
    "        get_property_fn=get_n_local_experts,\n",
    "    )\n",
    "    for run in runs\n",
    "}\n",
    "log.info(\n",
    "    \"Unique n_total_clients: %s, unique_local_batch_size: %s, \"\n",
    "    \"unique_overlapping_factor: %s, unique_n_total_experts: %s, \"\n",
    "    \"unique_n_local_experts: %s\",\n",
    "    unique_n_total_clients,\n",
    "    unique_local_batch_size,\n",
    "    unique_overlapping_factor,\n",
    "    unique_n_total_experts,\n",
    "    unique_n_local_experts,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d187338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collection and processing for expert density analysis\n",
    "\n",
    "log.info(\"🔄 Starting data collection and processing...\")\n",
    "unique_run_uuids = {\n",
    "    str(\n",
    "        get_clientrun_property_from_config(\n",
    "            run,\n",
    "            get_property_fn=operator.itemgetter(\"run_uuid\"),\n",
    "        ),\n",
    "    )\n",
    "    for run in runs\n",
    "}\n",
    "log.info(\"Found %s runs to process\", len(unique_run_uuids))\n",
    "results_list = []\n",
    "\n",
    "for i, unique_run_uuid in enumerate(unique_run_uuids):\n",
    "    log.info(\n",
    "        \"📊 Processing run %s/%s: %s\",\n",
    "        i + 1,\n",
    "        len(unique_run_uuids),\n",
    "        unique_run_uuid,\n",
    "    )\n",
    "\n",
    "    run: wandb.apis.public.Run | None = (  # pyright: ignore[reportAttributeAccessIssue]\n",
    "        None\n",
    "    )\n",
    "    try:\n",
    "        # Get any run that matches the unique run UUID\n",
    "        run = next(r for r in runs if get_run_uuid_from_config(r) == unique_run_uuid)\n",
    "        assert run is not None, f\"Run with UUID {unique_run_uuid} not found\"\n",
    "\n",
    "        # Extract configuration parameters\n",
    "        config = run.config\n",
    "        run_uuid = get_clientrun_property_from_config(\n",
    "            run,\n",
    "            get_property_fn=operator.itemgetter(\"run_uuid\"),\n",
    "        )\n",
    "\n",
    "        n_total_clients = get_clientrun_property_from_config(\n",
    "            run,\n",
    "            get_property_fn=lambda config: config[\"fl\"][\"n_total_clients\"],\n",
    "        )\n",
    "\n",
    "        n_total_experts = get_clientrun_property_from_config(\n",
    "            run,\n",
    "            get_property_fn=lambda config: config[\"llm_config\"][\"model\"][\"ffn_config\"][\n",
    "                \"ff_n_experts\"\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        overlapping_factor = get_clientrun_property_from_config(\n",
    "            run,\n",
    "            get_property_fn=lambda config: config[\"fl\"][\"experts_overlapping_factor\"],\n",
    "        )\n",
    "\n",
    "        global_train_batch_size = get_clientrun_property_from_config(\n",
    "            run,\n",
    "            get_property_fn=lambda config: config[\"llm_config\"][\n",
    "                \"global_train_batch_size\"\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # Calculate derived metrics\n",
    "        n_local_experts = get_n_local_experts(config)\n",
    "        experts_global_batch_size = get_experts_global_batch_size(config)\n",
    "        non_experts_global_batch_size = get_non_experts_global_batch_size(config)\n",
    "\n",
    "        log.info(\n",
    "            \"📋 Configuration: TE=%s, LE=%s, Clients=%s, OF=%s\",\n",
    "            n_total_experts,\n",
    "            n_local_experts,\n",
    "            n_total_clients,\n",
    "            overlapping_factor,\n",
    "        )\n",
    "\n",
    "        # Download and process data\n",
    "        log.info(\"🔽 Downloading data for %s...\", run_uuid)\n",
    "\n",
    "        try:\n",
    "            # Download photon metrics for the run\n",
    "            assert run_uuid is not None, \"Run UUID must not be None\"\n",
    "            assert isinstance(\n",
    "                run_uuid,\n",
    "                str,\n",
    "            ), f\"Run UUID must be a string not a {type(run_uuid)}\"\n",
    "            _s_df, clients_df = download_photon_metrics(\n",
    "                base_name=\"camlsys/photon\",\n",
    "                run_uuid=run_uuid,\n",
    "            )\n",
    "\n",
    "            # Try to get perplexity vs tokens data\n",
    "            assert n_total_clients is not None, \"Total clients must not be None\"\n",
    "            assert isinstance(\n",
    "                n_total_clients,\n",
    "                int,\n",
    "            ), f\"Total clients must be an integer not a {type(n_total_clients)}\"\n",
    "            result = get_perplexity_versus_tokens(\n",
    "                client_metrics_df=clients_df,\n",
    "                n_clients_per_round=n_total_clients,\n",
    "            )\n",
    "\n",
    "            tokens, perplexity = result\n",
    "\n",
    "            if len(tokens) == 0 or len(perplexity) == 0:\n",
    "                log.warning(\"❌ Empty data arrays for %s\", run_uuid)\n",
    "                continue\n",
    "\n",
    "            # Try to get the throughput data\n",
    "            steps, throughput = get_device_throughput_series(\n",
    "                client_metrics_df=clients_df,\n",
    "                moving_window=10,\n",
    "            )\n",
    "\n",
    "            # Calculate metrics\n",
    "            final_perplexity = (\n",
    "                perplexity.iloc[-1] if len(perplexity) > 0 else float(\"nan\")\n",
    "            )\n",
    "            total_tokens = tokens.iloc[-1] if len(tokens) > 0 else 0\n",
    "            n_data_points = len(tokens)\n",
    "\n",
    "            log.info(\n",
    "                (\n",
    "                    \"   ✅ Data processed: %d points,\"\n",
    "                    \" Final perplexity: %.4f, Total tokens: %.0f\"\n",
    "                ),\n",
    "                n_data_points,\n",
    "                final_perplexity,\n",
    "                total_tokens,\n",
    "            )\n",
    "\n",
    "            # Store results\n",
    "            results_list.append(\n",
    "                {\n",
    "                    \"run_uuid\": str(run_uuid),\n",
    "                    \"n_total_clients\": n_total_clients,\n",
    "                    \"n_total_experts\": n_total_experts,\n",
    "                    \"n_local_experts\": n_local_experts,\n",
    "                    \"overlapping_factor\": overlapping_factor,\n",
    "                    \"global_train_batch_size\": global_train_batch_size,\n",
    "                    \"experts_global_batch_size\": experts_global_batch_size,\n",
    "                    \"non_experts_global_batch_size\": non_experts_global_batch_size,\n",
    "                    \"final_perplexity\": final_perplexity,\n",
    "                    \"total_tokens\": total_tokens,\n",
    "                    \"n_data_points\": n_data_points,\n",
    "                    \"tokens\": (\n",
    "                        tokens.tolist() if hasattr(tokens, \"tolist\") else list(tokens)\n",
    "                    ),\n",
    "                    \"perplexity\": (\n",
    "                        perplexity.tolist()\n",
    "                        if hasattr(perplexity, \"tolist\")\n",
    "                        else list(perplexity)\n",
    "                    ),\n",
    "                    \"steps\": (\n",
    "                        steps.tolist() if hasattr(steps, \"tolist\") else list(steps)\n",
    "                    ),\n",
    "                    \"throughput\": (\n",
    "                        throughput.tolist()\n",
    "                        if hasattr(throughput, \"tolist\")\n",
    "                        else list(throughput)\n",
    "                    ),\n",
    "                },\n",
    "            )\n",
    "\n",
    "        except ClientRunNotFoundError:\n",
    "            # Log exception with stack trace\n",
    "            log.exception(\n",
    "                \"   ⚠️  Client run not found for %s\",\n",
    "                run_uuid,\n",
    "                stack_info=True,\n",
    "            )\n",
    "\n",
    "            # Remove this run from WandB runs to avoid further processing\n",
    "            remove_runs_by_regex(\"camlsys/photon\", f\"^{run_uuid}*\")\n",
    "            continue\n",
    "\n",
    "        except ColumnNotFoundError:\n",
    "            log.exception(\n",
    "                \"   ⚠️ Column not found in client metrics DataFrame for %s. \"\n",
    "                \"We assume this run crashed and doesn't have the expected data.\",\n",
    "                run_uuid,\n",
    "                stack_info=True,\n",
    "            )\n",
    "\n",
    "            # Remove this run from WandB runs to avoid further processing\n",
    "            remove_runs_by_regex(\"camlsys/photon\", f\"^{run_uuid}*\")\n",
    "            continue\n",
    "\n",
    "        except Exception:\n",
    "            log.exception(\"   ❌ Error processing %s\", run_uuid, stack_info=True)\n",
    "            continue\n",
    "\n",
    "    except Exception:\n",
    "        assert run is not None, \"Run must not be None\"\n",
    "        log.exception(\n",
    "            \"   ❌ Error extracting config for run %s\",\n",
    "            run.name,\n",
    "            stack_info=True,\n",
    "        )\n",
    "        continue\n",
    "\n",
    "log.info(\"\\n✅ Data collection completed!\")\n",
    "log.info(\n",
    "    \"Successfully processed %d out of %d runs\",\n",
    "    len(results_list),\n",
    "    len(unique_run_uuids),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9e9e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info(\"\\n=== Summary ===\")\n",
    "log.info(\n",
    "    \"Successfully processed %d out of %d runs\",\n",
    "    len(results_list),\n",
    "    len(unique_run_uuids),\n",
    ")\n",
    "\n",
    "# Check for runs that didn't reach 1 billion tokens and log warnings\n",
    "incomplete_runs = []\n",
    "complete_runs = []\n",
    "if results_list:\n",
    "    log.info(\"\\n⚠️  TOKEN COUNT ANALYSIS ⚠️\")\n",
    "    log.info(\"=\" * 60)\n",
    "\n",
    "    billion_tokens = 1e9\n",
    "\n",
    "    for result in results_list:\n",
    "        if result[\"total_tokens\"] < billion_tokens:\n",
    "            incomplete_runs.append(result)\n",
    "        else:\n",
    "            complete_runs.append(result)\n",
    "\n",
    "    if incomplete_runs:\n",
    "        log.warning(\n",
    "            \"🔴 WARNING: %d run(s) did NOT reach 1 billion tokens:\",\n",
    "            len(incomplete_runs),\n",
    "        )\n",
    "        log.info(\"-\" * 60)\n",
    "\n",
    "        for i, result in enumerate(incomplete_runs, 1):\n",
    "            log.info(\"\\n%s. Run UUID: %s\", i, result[\"run_uuid\"])\n",
    "            log.info(\n",
    "                \"   Total Tokens: %s (%.3fB)\",\n",
    "                format(result[\"total_tokens\"], \",\"),\n",
    "                result[\"total_tokens\"] / 1e9,\n",
    "            )\n",
    "            log.info(\n",
    "                \"   Completion: %.1f%% of 1B tokens\",\n",
    "                result[\"total_tokens\"] / billion_tokens * 100,\n",
    "            )\n",
    "            log.info(\"   📋 Full Configuration:\")\n",
    "            log.info(\"      • Total Experts: %s\", result[\"n_total_experts\"])\n",
    "            log.info(\"      • Local Experts: %s\", result[\"n_local_experts\"])\n",
    "            log.info(\"      • Total Clients: %s\", result[\"n_total_clients\"])\n",
    "            log.info(\"      • Overlapping Factor: %.1f\", result[\"overlapping_factor\"])\n",
    "            log.info(\n",
    "                \"      • Expert Global Batch Size: %s\",\n",
    "                result[\"experts_global_batch_size\"],\n",
    "            )\n",
    "            log.info(\n",
    "                \"      • Non-Expert Global Batch Size: %s\",\n",
    "                result[\"non_experts_global_batch_size\"],\n",
    "            )\n",
    "            log.info(\"      • Local Batch Size: %s\", result[\"global_train_batch_size\"])\n",
    "            log.info(\"      • Final Perplexity: %.4f\", result[\"final_perplexity\"])\n",
    "            log.info(\"      • Data Points: %s\", result[\"n_data_points\"])\n",
    "\n",
    "    if complete_runs:\n",
    "        log.info(\n",
    "            \"✅ %d run(s) successfully reached 1+ billion tokens:\",\n",
    "            len(complete_runs),\n",
    "        )\n",
    "        for result in complete_runs:\n",
    "            log.info(\n",
    "                \"   • %s: %d tokens (%.3fB)\",\n",
    "                result[\"run_uuid\"],\n",
    "                result[\"total_tokens\"],\n",
    "                result[\"total_tokens\"] / 1e9,\n",
    "            )\n",
    "\n",
    "    log.info(\"\\n📊 Token Count Summary:\")\n",
    "    log.info(\"   • Complete runs (≥1B tokens): %d\", len(complete_runs))\n",
    "    log.info(\"   • Incomplete runs (<1B tokens): %d\", len(incomplete_runs))\n",
    "    if results_list:\n",
    "        avg_tokens = sum(r[\"total_tokens\"] for r in results_list) / len(results_list)\n",
    "        log.info(\n",
    "            \"   • Average tokens across all runs: %.0f (%.3fB)\",\n",
    "            avg_tokens,\n",
    "            avg_tokens / 1e9,\n",
    "        )\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "this_cell_results_list = results_list\n",
    "if EXCLUDE_INCOMPLETE_RUNS:\n",
    "    this_cell_results_list = complete_runs\n",
    "if this_cell_results_list:\n",
    "    results_df = pd.DataFrame(this_cell_results_list)\n",
    "    log.info(\"\\nResults DataFrame shape: %s\", results_df.shape)\n",
    "    log.info(\"\\nConfiguration summary:\")\n",
    "    summary_cols = [\n",
    "        \"run_uuid\",\n",
    "        \"n_local_experts\",\n",
    "        \"experts_global_batch_size\",\n",
    "        \"non_experts_global_batch_size\",\n",
    "        \"overlapping_factor\",\n",
    "        \"final_perplexity\",\n",
    "        \"n_total_experts\",\n",
    "    ]\n",
    "    log.info(results_df[summary_cols].to_string(index=False, float_format=\"%.4f\"))\n",
    "else:\n",
    "    log.info(\"No results to analyze\")\n",
    "    results_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503a2d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump complete run UUIDs to file\n",
    "\n",
    "if complete_runs:\n",
    "    # Extract just the UUIDs from complete runs\n",
    "    complete_run_uuids = [run[\"run_uuid\"] for run in complete_runs]\n",
    "\n",
    "    # Create output filename with timestamp\n",
    "    timestamp = datetime.now(tz=UTC).strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_file = Path(f\"complete_run_uuids_{timestamp}.json\")\n",
    "\n",
    "    # Save to JSON file for easy reading\n",
    "    output_data = {\n",
    "        \"timestamp\": timestamp,\n",
    "        \"total_complete_runs\": len(complete_run_uuids),\n",
    "        \"total_runs_analyzed\": len(results_list),\n",
    "        \"complete_run_uuids\": complete_run_uuids,\n",
    "        \"run_details\": [\n",
    "            {\n",
    "                \"run_uuid\": run[\"run_uuid\"],\n",
    "                \"n_total_experts\": run[\"n_total_experts\"],\n",
    "                \"n_local_experts\": run[\"n_local_experts\"],\n",
    "                \"overlapping_factor\": run[\"overlapping_factor\"],\n",
    "                \"final_perplexity\": run[\"final_perplexity\"],\n",
    "                \"total_tokens\": run[\"total_tokens\"],\n",
    "            }\n",
    "            for run in complete_runs\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    with output_file.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(output_data, f, indent=2)\n",
    "\n",
    "    log.info(\"✅ Complete run UUIDs saved to: %s\", output_file)\n",
    "    log.info(\"📊 Summary:\")\n",
    "    log.info(\"   - Total complete runs: %d\", len(complete_run_uuids))\n",
    "    log.info(\"   - Total runs analyzed: %d\", len(results_list))\n",
    "    log.info(\"   - Complete run UUIDs with total experts:\")\n",
    "    for i, run in enumerate(complete_runs, 1):\n",
    "        log.info(\"     %d. %s (TE: %d)\", i, run[\"run_uuid\"], run[\"n_total_experts\"])\n",
    "\n",
    "    # Also save a simple text file with just the UUIDs and total experts (one per line)\n",
    "    txt_file = Path(f\"complete_run_uuids_{timestamp}.txt\")\n",
    "    with txt_file.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"# Complete Run UUIDs with Total Experts\\n\")\n",
    "        f.write(\"# Format: run_uuid,n_total_experts\\n\")\n",
    "        for run in complete_runs:\n",
    "            f.write(f\"{run['run_uuid']},{run['n_total_experts']}\\n\")\n",
    "\n",
    "    log.info(\"📝 Also saved text version with total experts to: %s\", txt_file)\n",
    "\n",
    "else:\n",
    "    log.warning(\"❌ No complete runs found to save\")\n",
    "    log.info(\"   All %d runs are incomplete (< 1B tokens)\", len(results_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f6be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Expert Density Analysis with Independent, High-Quality Plots\n",
    "log.info(\"Generating enhanced Expert Density Analysis with improved cosmetics...\")\n",
    "\n",
    "this_cell_results_list = results_list\n",
    "if EXCLUDE_INCOMPLETE_RUNS:\n",
    "    this_cell_results_list = complete_runs\n",
    "\n",
    "if len(this_cell_results_list) > 0:\n",
    "    # Quick token count check before plotting\n",
    "    billion_tokens = 1e9\n",
    "    incomplete_runs = [\n",
    "        r for r in this_cell_results_list if r[\"total_tokens\"] < billion_tokens\n",
    "    ]\n",
    "\n",
    "    if incomplete_runs:\n",
    "        log.warning(\n",
    "            \"\\n ATTENTION: %s of %s runs didn't reach 1B tokens!\",\n",
    "            len(incomplete_runs),\n",
    "            len(this_cell_results_list),\n",
    "        )\n",
    "        log.info(\"   This may affect training convergence analysis.\\n\")\n",
    "\n",
    "    # Set up enhanced plotting style\n",
    "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "    colors = plt.cm.Set1(  # pyright: ignore[reportAttributeAccessIssue]\n",
    "        np.linspace(0, 1, len(this_cell_results_list)),\n",
    "    )\n",
    "\n",
    "    # ==== PLOT 1: Training Progress - Perplexity vs Total Tokens ====\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    for i, result in enumerate(this_cell_results_list):\n",
    "        tokens = np.array(result[\"tokens\"])\n",
    "        perplexity = np.array(result[\"perplexity\"])\n",
    "\n",
    "        # Enhanced legend label with key information\n",
    "        incomplete_indicator = \" ⚠️\" if result[\"total_tokens\"] < billion_tokens else \"\"\n",
    "        legend_label = (\n",
    "            f\"TE: {result['n_total_experts']}, LE: {result['n_local_experts']}, \"\n",
    "            f\"NC: {result['n_total_clients']}, OF: {result['overlapping_factor']:.1f}, \"\n",
    "            f\"EgBS: {result['experts_global_batch_size']},\"\n",
    "            f\" nEgBS: {result['non_experts_global_batch_size']}\"\n",
    "        )\n",
    "\n",
    "        # Use different line style for incomplete runs\n",
    "        linestyle = \"--\" if result[\"total_tokens\"] < billion_tokens else \"-\"\n",
    "        alpha = 0.7 if result[\"total_tokens\"] < billion_tokens else 0.9\n",
    "        linewidth = 2.0 if result[\"total_tokens\"] < billion_tokens else 2.5\n",
    "\n",
    "        plt.plot(\n",
    "            tokens,\n",
    "            perplexity,\n",
    "            label=legend_label,\n",
    "            linewidth=linewidth,\n",
    "            alpha=alpha,\n",
    "            color=colors[i],\n",
    "            linestyle=linestyle,\n",
    "            marker=\"o\" if i < 3 else (\"s\" if i < 6 else \"^\"),\n",
    "            markersize=4,\n",
    "            markevery=max(1, len(tokens) // 15),\n",
    "            markerfacecolor=\"white\",\n",
    "            markeredgewidth=1.5,\n",
    "            markeredgecolor=colors[i],\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Total Tokens\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.ylabel(\"Language Perplexity\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.title(\n",
    "        (\n",
    "            \"Training Progress: Perplexity vs Total Tokens\\n\"\n",
    "            \"Expert Density Analysis with Batch Size Configurations\"\n",
    "        ),\n",
    "        fontsize=16,\n",
    "        fontweight=\"bold\",\n",
    "        pad=20,\n",
    "    )\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend(\n",
    "        frameon=True,\n",
    "        fancybox=True,\n",
    "        shadow=True,\n",
    "        ncol=1 if len(this_cell_results_list) <= 4 else 2,\n",
    "        fontsize=10,\n",
    "        loc=\"upper right\",\n",
    "    )\n",
    "    plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3173d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Expert Density Analysis with Independent, High-Quality Plots\n",
    "log.info(\"Generating enhanced Expert Density Analysis with improved cosmetics...\")\n",
    "\n",
    "this_cell_results_list = results_list\n",
    "if EXCLUDE_INCOMPLETE_RUNS:\n",
    "    this_cell_results_list = complete_runs\n",
    "\n",
    "if len(this_cell_results_list) > 0:\n",
    "    # Quick token count check before plotting\n",
    "    billion_tokens = 1e9\n",
    "    incomplete_runs = [\n",
    "        r for r in this_cell_results_list if r[\"total_tokens\"] < billion_tokens\n",
    "    ]\n",
    "\n",
    "    if incomplete_runs:\n",
    "        log.warning(\n",
    "            \"\\n ATTENTION: %s of %s runs didn't reach 1B tokens!\",\n",
    "            len(incomplete_runs),\n",
    "            len(this_cell_results_list),\n",
    "        )\n",
    "        log.info(\"   This may affect training convergence analysis.\\n\")\n",
    "\n",
    "    # Set up enhanced plotting style\n",
    "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "    colors = plt.cm.Set1(  # pyright: ignore[reportAttributeAccessIssue]\n",
    "        np.linspace(0, 1, len(this_cell_results_list)),\n",
    "    )\n",
    "    # ==== PLOT 2: Final Performance Scatter ====\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Create scatter plot with enhanced styling\n",
    "    for result in this_cell_results_list:\n",
    "        marker = \"o\" if result[\"total_tokens\"] >= billion_tokens else \"^\"\n",
    "        alpha = 0.8 if result[\"total_tokens\"] >= billion_tokens else 0.6\n",
    "        edge_color = \"darkred\" if result[\"total_tokens\"] < billion_tokens else \"black\"\n",
    "        edge_width = 2.5 if result[\"total_tokens\"] < billion_tokens else 1.5\n",
    "\n",
    "        scatter = plt.scatter(\n",
    "            result[\"n_local_experts\"],\n",
    "            result[\"final_perplexity\"],\n",
    "            c=result[\"overlapping_factor\"],\n",
    "            s=200,\n",
    "            alpha=alpha,\n",
    "            cmap=\"viridis\",\n",
    "            edgecolors=edge_color,\n",
    "            linewidth=edge_width,\n",
    "            marker=marker,\n",
    "            vmin=min(r[\"overlapping_factor\"] for r in this_cell_results_list),\n",
    "            vmax=max(r[\"overlapping_factor\"] for r in this_cell_results_list),\n",
    "        )\n",
    "\n",
    "    # Enhanced annotations\n",
    "    for result in this_cell_results_list:\n",
    "        incomplete_indicator = \"⚠️\" if result[\"total_tokens\"] < billion_tokens else \"\"\n",
    "        annotation_text = (\n",
    "            f\"TE: {result['n_total_experts']}, LE:{result['n_local_experts']}, \"\n",
    "            f\"EBS: {result['experts_global_batch_size']},\"\n",
    "            f\" NEBS: {result['non_experts_global_batch_size']}, \"\n",
    "            f\"{result['total_tokens'] / 1e9:.2f}B tokens\"\n",
    "        )\n",
    "        plt.annotate(\n",
    "            annotation_text,\n",
    "            (result[\"n_local_experts\"], result[\"final_perplexity\"]),\n",
    "            xytext=(8, 8),\n",
    "            textcoords=\"offset points\",\n",
    "            fontsize=9,\n",
    "            bbox={\n",
    "                \"boxstyle\": \"round,pad=0.3\",\n",
    "                \"facecolor\": \"white\",\n",
    "                \"alpha\": 0.8,\n",
    "                \"edgecolor\": \"gray\",\n",
    "            },\n",
    "            arrowprops={\n",
    "                \"arrowstyle\": \"->\",\n",
    "                \"connectionstyle\": \"arc3,rad=0.1\",\n",
    "                \"alpha\": 0.6,\n",
    "            },\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Number of Local Experts\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.ylabel(\"Final Perplexity\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.title(\n",
    "        (\n",
    "            \"Final Performance vs Expert Configuration\\n\"\n",
    "            \"Color = Overlapping Factor | Red edges = Incomplete runs (<1B tokens)\"\n",
    "        ),\n",
    "        fontsize=16,\n",
    "        fontweight=\"bold\",\n",
    "        pad=20,\n",
    "    )\n",
    "\n",
    "    cbar = plt.colorbar(scatter, shrink=0.8, aspect=20)\n",
    "    cbar.set_label(\"Overlapping Factor\", fontsize=12, fontweight=\"bold\")\n",
    "    cbar.ax.tick_params(labelsize=10)\n",
    "\n",
    "    plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c560369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Expert Density Analysis with Independent, High-Quality Plots\n",
    "log.info(\"Generating enhanced Expert Density Analysis with improved cosmetics...\")\n",
    "\n",
    "this_cell_results_list = results_list\n",
    "if EXCLUDE_INCOMPLETE_RUNS:\n",
    "    this_cell_results_list = complete_runs\n",
    "\n",
    "if len(this_cell_results_list) > 0:\n",
    "    # Quick token count check before plotting\n",
    "    billion_tokens = 1e9\n",
    "    incomplete_runs = [\n",
    "        r for r in this_cell_results_list if r[\"total_tokens\"] < billion_tokens\n",
    "    ]\n",
    "\n",
    "    if incomplete_runs:\n",
    "        log.warning(\n",
    "            \"\\n ATTENTION: %s of %s runs didn't reach 1B tokens!\",\n",
    "            len(incomplete_runs),\n",
    "            len(this_cell_results_list),\n",
    "        )\n",
    "        log.info(\"   This may affect training convergence analysis.\\n\")\n",
    "\n",
    "    # Set up enhanced plotting style\n",
    "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "    colors = plt.cm.Set1(  # pyright: ignore[reportAttributeAccessIssue]\n",
    "        np.linspace(0, 1, len(this_cell_results_list)),\n",
    "    )\n",
    "    # ==== PLOT 3: Training Efficiency Analysis ====\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    for i, result in enumerate(this_cell_results_list):\n",
    "        incomplete_indicator = \" ⚠️\" if result[\"total_tokens\"] < billion_tokens else \"\"\n",
    "        alpha = 0.7 if result[\"total_tokens\"] < billion_tokens else 0.8\n",
    "        edge_color = \"darkred\" if result[\"total_tokens\"] < billion_tokens else \"black\"\n",
    "        edge_width = 2.5 if result[\"total_tokens\"] < billion_tokens else 1.5\n",
    "\n",
    "        plt.scatter(\n",
    "            result[\"total_tokens\"] / 1e9,  # Convert to billions for readability\n",
    "            result[\"final_perplexity\"],\n",
    "            s=result[\"n_local_experts\"] * 80\n",
    "            + 120,  # Size proportional to local experts\n",
    "            alpha=alpha,\n",
    "            color=colors[i],\n",
    "            edgecolors=edge_color,\n",
    "            linewidth=edge_width,\n",
    "            label=(\n",
    "                f\"TE: {result['n_total_experts']}, \"\n",
    "                f\"LE: {result['n_local_experts']}, \"\n",
    "                f\"OF: {result['overlapping_factor']:.1f}\"\n",
    "                f\"{incomplete_indicator}\"\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Total Tokens Consumed (Billions)\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.ylabel(\"Final Perplexity\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.title(\n",
    "        (\n",
    "            \"Training Efficiency Analysis\\n\"\n",
    "            \"Marker Size ∝ Local Experts | Red edges = Incomplete runs\"\n",
    "        ),\n",
    "        fontsize=16,\n",
    "        fontweight=\"bold\",\n",
    "        pad=20,\n",
    "    )\n",
    "\n",
    "    plt.legend(\n",
    "        title=(\n",
    "            \"TE: Total Experts, LE: Local Experts, OF: Overlap Factor\"\n",
    "            \"\\n⚠️ = Incomplete runs (<1B tokens)\"\n",
    "        ),\n",
    "        frameon=True,\n",
    "        fancybox=True,\n",
    "        shadow=True,\n",
    "        fontsize=10,\n",
    "        title_fontsize=11,\n",
    "        loc=\"upper left\",\n",
    "        bbox_to_anchor=(1.02, 1),\n",
    "    )\n",
    "    plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ==== PLOT 4: Convergence Rate Comparison ====\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    for i, result in enumerate(this_cell_results_list):\n",
    "        tokens = np.array(result[\"tokens\"])\n",
    "        perplexity = np.array(result[\"perplexity\"])\n",
    "\n",
    "        if len(tokens) > 1:\n",
    "            tokens_norm = (tokens - tokens.min()) / (tokens.max() - tokens.min())\n",
    "            incomplete_indicator = (\n",
    "                \" ⚠️\" if result[\"total_tokens\"] < billion_tokens else \"\"\n",
    "            )\n",
    "            linestyle = \"--\" if result[\"total_tokens\"] < billion_tokens else \"-\"\n",
    "            alpha = 0.7 if result[\"total_tokens\"] < billion_tokens else 0.9\n",
    "            linewidth = 2.0 if result[\"total_tokens\"] < billion_tokens else 2.5\n",
    "\n",
    "            plt.plot(\n",
    "                tokens_norm,\n",
    "                perplexity,\n",
    "                label=(\n",
    "                    f\"TE: {result['n_total_experts']}, \"\n",
    "                    f\"LE: {result['n_local_experts']}, \"\n",
    "                    f\"OF: {result['overlapping_factor']:.1f}\"\n",
    "                    f\"{incomplete_indicator}\"\n",
    "                ),\n",
    "                linewidth=linewidth,\n",
    "                alpha=alpha,\n",
    "                linestyle=linestyle,\n",
    "                color=colors[i],\n",
    "                marker=\"o\" if i < 3 else (\"s\" if i < 6 else \"^\"),\n",
    "                markersize=4,\n",
    "                markevery=max(1, len(tokens_norm) // 20),\n",
    "                markerfacecolor=\"white\",\n",
    "                markeredgewidth=1.5,\n",
    "                markeredgecolor=colors[i],\n",
    "            )\n",
    "\n",
    "    plt.xlabel(\n",
    "        \"Normalized Training Progress (0 = Start, 1 = End)\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    plt.ylabel(\"Language Perplexity\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.title(\n",
    "        (\n",
    "            \"Convergence Rate Comparison\\n\"\n",
    "            \"Normalized Training Progress with Expert Configurations\"\n",
    "        ),\n",
    "        fontsize=16,\n",
    "        fontweight=\"bold\",\n",
    "        pad=20,\n",
    "    )\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend(\n",
    "        title=(\n",
    "            \"TE: Total Experts, LE: Local Experts, OF: Overlap Factor\"\n",
    "            \"\\n ⚠️ = Incomplete runs (<1B tokens)\"\n",
    "        ),\n",
    "        frameon=True,\n",
    "        fancybox=True,\n",
    "        shadow=True,\n",
    "        fontsize=10,\n",
    "        title_fontsize=11,\n",
    "        ncol=1 if len(this_cell_results_list) <= 4 else 2,\n",
    "    )\n",
    "    plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ==== PLOT 5: Configuration Summary Heatmap ====\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Create a summary matrix for visualization\n",
    "    config_data = []\n",
    "    config_labels = []\n",
    "\n",
    "    for result in this_cell_results_list:\n",
    "        config_data.append(\n",
    "            [\n",
    "                result[\"n_total_experts\"],\n",
    "                result[\"n_local_experts\"],\n",
    "                result[\"overlapping_factor\"],\n",
    "                result[\"experts_global_batch_size\"],\n",
    "                result[\"non_experts_global_batch_size\"],\n",
    "                result[\"final_perplexity\"],\n",
    "                result[\"total_tokens\"] / 1e9,\n",
    "            ],\n",
    "        )\n",
    "        incomplete_mark = \"⚠️\" if result[\"total_tokens\"] < billion_tokens else \"\"\n",
    "        config_labels.append(f\"{result['run_uuid'][:8]}...{incomplete_mark}\")\n",
    "\n",
    "    config_matrix = np.array(config_data)\n",
    "\n",
    "    # Normalize each column to [0, 1] for better heatmap visualization\n",
    "    config_matrix_norm = np.zeros_like(config_matrix)\n",
    "    for i in range(config_matrix.shape[1]):\n",
    "        col_min, col_max = config_matrix[:, i].min(), config_matrix[:, i].max()\n",
    "        if col_max > col_min:\n",
    "            config_matrix_norm[:, i] = (config_matrix[:, i] - col_min) / (\n",
    "                col_max - col_min\n",
    "            )\n",
    "        else:\n",
    "            config_matrix_norm[:, i] = 0.5  # If all values are the same\n",
    "\n",
    "    im = plt.imshow(config_matrix_norm.T, cmap=\"RdYlBu_r\", aspect=\"auto\", alpha=0.8)\n",
    "\n",
    "    # Set labels\n",
    "    plt.xticks(range(len(config_labels)), config_labels, rotation=45, ha=\"right\")\n",
    "    plt.yticks(\n",
    "        range(len(config_data[0])),\n",
    "        [\n",
    "            \"Total Experts\",\n",
    "            \"Local Experts\",\n",
    "            \"Overlap Factor\",\n",
    "            \"Expert Global BS\",\n",
    "            \"Non-Expert Global BS\",\n",
    "            \"Final Perplexity\",\n",
    "            \"Total Tokens (B)\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Add text annotations with actual values\n",
    "    for i in range(len(config_labels)):\n",
    "        for j in range(len(config_data[0])):\n",
    "            if j < 5:  # Integer values\n",
    "                text = f\"{int(config_matrix[i, j])}\"\n",
    "            else:  # Float values\n",
    "                text = f\"{config_matrix[i, j]:.2f}\"\n",
    "            plt.text(\n",
    "                i,\n",
    "                j,\n",
    "                text,\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                color=\"white\" if config_matrix_norm[i, j] > 0.5 else \"black\",\n",
    "                fontweight=\"bold\",\n",
    "                fontsize=9,\n",
    "            )\n",
    "\n",
    "    plt.title(\n",
    "        (\n",
    "            \"Configuration Summary Heatmap\\n\"\n",
    "            \"Normalized values with actual values overlaid\"\n",
    "        ),\n",
    "        fontsize=16,\n",
    "        fontweight=\"bold\",\n",
    "        pad=20,\n",
    "    )\n",
    "\n",
    "    cbar = plt.colorbar(im, shrink=0.8, aspect=20)\n",
    "    cbar.set_label(\n",
    "        \"Normalized Value (0 = Min, 1 = Max)\",\n",
    "        fontsize=12,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    log.info(\"✅ Enhanced analysis with improved cosmetics completed!\")\n",
    "    log.info(\"📊 Generated 5 independent plots:\")\n",
    "    log.info(\"   1. Training Progress (Perplexity vs Tokens)\")\n",
    "    log.info(\"   2. Final Performance Scatter\")\n",
    "    log.info(\"   3. Training Efficiency Analysis\")\n",
    "    log.info(\"   4. Convergence Rate Comparison\")\n",
    "    log.info(\"   5. Configuration Summary Heatmap\")\n",
    "\n",
    "    if incomplete_runs:\n",
    "        log.warning(\n",
    "            \"⚠️  Note: %s run(s) marked as incomplete in all plots\",\n",
    "            len(incomplete_runs),\n",
    "        )\n",
    "\n",
    "else:\n",
    "    log.info(\"❌ No results available for analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392e73a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Expert Density Analysis - Throughput vs Steps Analysis\n",
    "log.info(\"Generating Throughput vs Steps Analysis...\")\n",
    "\n",
    "this_cell_results_list = results_list\n",
    "if EXCLUDE_INCOMPLETE_RUNS:\n",
    "    this_cell_results_list = complete_runs\n",
    "\n",
    "if len(this_cell_results_list) > 0:\n",
    "    # Quick token count check before plotting\n",
    "    billion_tokens = 1e9\n",
    "    incomplete_runs = [\n",
    "        r for r in this_cell_results_list if r[\"total_tokens\"] < billion_tokens\n",
    "    ]\n",
    "\n",
    "    if incomplete_runs:\n",
    "        log.warning(\n",
    "            \"\\n ATTENTION: %s of %s runs didn't reach 1B tokens!\",\n",
    "            len(incomplete_runs),\n",
    "            len(this_cell_results_list),\n",
    "        )\n",
    "        log.info(\"   This may affect throughput analysis.\\n\")\n",
    "\n",
    "    # Set up enhanced plotting style\n",
    "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "    colors = plt.cm.Set1(  # pyright: ignore[reportAttributeAccessIssue]\n",
    "        np.linspace(0, 1, len(this_cell_results_list)),\n",
    "    )\n",
    "\n",
    "    # ==== PLOT 6: Throughput vs Steps Analysis ====\n",
    "    plt.figure(figsize=(16, 10))\n",
    "\n",
    "    # Subplot 1: Raw throughput over training steps\n",
    "    plt.subplot(2, 2, 1)\n",
    "    for i, result in enumerate(this_cell_results_list):\n",
    "        steps = np.array(result[\"steps\"])\n",
    "        throughput = np.array(result[\"throughput\"])\n",
    "\n",
    "        if len(steps) > 0 and len(throughput) > 0:\n",
    "            # Enhanced legend label with key information\n",
    "            incomplete_indicator = (\n",
    "                \" ⚠️\" if result[\"total_tokens\"] < billion_tokens else \"\"\n",
    "            )\n",
    "            legend_label = (\n",
    "                f\"TE: {result['n_total_experts']}, LE: {result['n_local_experts']}, \"\n",
    "                f\"NC: {result['n_total_clients']},\"\n",
    "                f\" OF: {result['overlapping_factor']:.1f}\"\n",
    "                f\"{incomplete_indicator}\"\n",
    "            )\n",
    "\n",
    "            # Use different line style for incomplete runs\n",
    "            linestyle = \"--\" if result[\"total_tokens\"] < billion_tokens else \"-\"\n",
    "            alpha = 0.7 if result[\"total_tokens\"] < billion_tokens else 0.9\n",
    "            linewidth = 2.0 if result[\"total_tokens\"] < billion_tokens else 2.5\n",
    "\n",
    "            plt.plot(\n",
    "                steps,\n",
    "                throughput,\n",
    "                label=legend_label,\n",
    "                linewidth=linewidth,\n",
    "                alpha=alpha,\n",
    "                color=colors[i],\n",
    "                linestyle=linestyle,\n",
    "                marker=\"o\" if i < 3 else (\"s\" if i < 6 else \"^\"),\n",
    "                markersize=3,\n",
    "                markevery=max(1, len(steps) // 20),\n",
    "                markerfacecolor=\"white\",\n",
    "                markeredgewidth=1.2,\n",
    "                markeredgecolor=colors[i],\n",
    "            )\n",
    "\n",
    "    plt.xlabel(\"Training Steps\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.ylabel(\"Device Throughput (tokens/s)\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.title(\n",
    "        \"Device Throughput vs Training Steps\\nExpert Density Impact on Training Speed\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "        pad=15,\n",
    "    )\n",
    "    plt.legend(\n",
    "        frameon=True,\n",
    "        fancybox=True,\n",
    "        shadow=True,\n",
    "        ncol=1,\n",
    "        fontsize=9,\n",
    "        loc=\"best\",\n",
    "    )\n",
    "    plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5)\n",
    "\n",
    "    # Subplot 2: Average throughput by configuration\n",
    "    plt.subplot(2, 2, 2)\n",
    "    avg_throughputs = []\n",
    "    config_labels = []\n",
    "    local_experts = []\n",
    "    overlapping_factors = []\n",
    "\n",
    "    for result in this_cell_results_list:\n",
    "        throughput = np.array(result[\"throughput\"])\n",
    "        if len(throughput) > 0:\n",
    "            avg_throughput = np.mean(throughput)\n",
    "            avg_throughputs.append(avg_throughput)\n",
    "            local_experts.append(result[\"n_local_experts\"])\n",
    "            overlapping_factors.append(result[\"overlapping_factor\"])\n",
    "\n",
    "            incomplete_indicator = (\n",
    "                \" ⚠️\" if result[\"total_tokens\"] < billion_tokens else \"\"\n",
    "            )\n",
    "            config_labels.append(\n",
    "                f\"TE: {result['n_total_experts']}, LE: {result['n_local_experts']}\\n\"\n",
    "                f\"OF: {result['overlapping_factor']:.1f}{incomplete_indicator}\",\n",
    "            )\n",
    "\n",
    "    if avg_throughputs:\n",
    "        bars = plt.bar(\n",
    "            range(len(avg_throughputs)),\n",
    "            avg_throughputs,\n",
    "            color=[colors[i] for i in range(len(avg_throughputs))],\n",
    "            alpha=0.8,\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=1.2,\n",
    "        )\n",
    "\n",
    "        # Add value labels on bars\n",
    "        for bar, throughput in zip(bars, avg_throughputs, strict=True):\n",
    "            plt.text(\n",
    "                bar.get_x() + bar.get_width() / 2,\n",
    "                bar.get_height() + max(avg_throughputs) * 0.01,\n",
    "                f\"{throughput:.1f}\",\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "                fontweight=\"bold\",\n",
    "                fontsize=10,\n",
    "            )\n",
    "\n",
    "        plt.xlabel(\"Configuration\", fontsize=12, fontweight=\"bold\")\n",
    "        plt.ylabel(\"Average Throughput (tokens/s)\", fontsize=12, fontweight=\"bold\")\n",
    "        plt.title(\n",
    "            \"Average Device Throughput by Configuration\",\n",
    "            fontsize=14,\n",
    "            fontweight=\"bold\",\n",
    "            pad=15,\n",
    "        )\n",
    "        plt.xticks(range(len(config_labels)), config_labels, rotation=45, ha=\"right\")\n",
    "        plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5, axis=\"y\")\n",
    "\n",
    "    # Subplot 3: Throughput vs Local Experts scatter\n",
    "    plt.subplot(2, 2, 3)\n",
    "    if avg_throughputs:\n",
    "        for i, (le, of, throughput) in enumerate(\n",
    "            zip(local_experts, overlapping_factors, avg_throughputs, strict=True),\n",
    "        ):\n",
    "            marker = (\n",
    "                \"o\"\n",
    "                if this_cell_results_list[i][\"total_tokens\"] >= billion_tokens\n",
    "                else \"^\"\n",
    "            )\n",
    "            alpha = (\n",
    "                0.8\n",
    "                if this_cell_results_list[i][\"total_tokens\"] >= billion_tokens\n",
    "                else 0.6\n",
    "            )\n",
    "            edge_color = (\n",
    "                \"darkred\"\n",
    "                if this_cell_results_list[i][\"total_tokens\"] < billion_tokens\n",
    "                else \"black\"\n",
    "            )\n",
    "            edge_width = (\n",
    "                2.5\n",
    "                if this_cell_results_list[i][\"total_tokens\"] < billion_tokens\n",
    "                else 1.5\n",
    "            )\n",
    "\n",
    "            scatter = plt.scatter(\n",
    "                le,\n",
    "                throughput,\n",
    "                c=of,\n",
    "                s=200,\n",
    "                alpha=alpha,\n",
    "                cmap=\"viridis\",\n",
    "                edgecolors=edge_color,\n",
    "                linewidth=edge_width,\n",
    "                marker=marker,\n",
    "                vmin=min(overlapping_factors),\n",
    "                vmax=max(overlapping_factors),\n",
    "            )\n",
    "\n",
    "        plt.xlabel(\"Number of Local Experts\", fontsize=12, fontweight=\"bold\")\n",
    "        plt.ylabel(\"Average Throughput (tokens/s)\", fontsize=12, fontweight=\"bold\")\n",
    "        plt.title(\n",
    "            \"Throughput vs Local Experts\\nColor = Overlapping Factor\",\n",
    "            fontsize=14,\n",
    "            fontweight=\"bold\",\n",
    "            pad=15,\n",
    "        )\n",
    "\n",
    "        cbar = plt.colorbar(scatter, shrink=0.8, aspect=15)\n",
    "        cbar.set_label(\"Overlapping Factor\", fontsize=10, fontweight=\"bold\")\n",
    "        cbar.ax.tick_params(labelsize=9)\n",
    "        plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5)\n",
    "\n",
    "    # Subplot 4: Throughput stability analysis (coefficient of variation)\n",
    "    plt.subplot(2, 2, 4)\n",
    "    throughput_cv = []\n",
    "    throughput_std = []\n",
    "\n",
    "    for result in this_cell_results_list:\n",
    "        throughput = np.array(result[\"throughput\"])\n",
    "        if len(throughput) > 1:\n",
    "            cv = (\n",
    "                np.std(throughput) / np.mean(throughput)\n",
    "                if np.mean(throughput) > 0\n",
    "                else 0\n",
    "            )\n",
    "            throughput_cv.append(cv)\n",
    "            throughput_std.append(np.std(throughput))\n",
    "        else:\n",
    "            throughput_cv.append(0)\n",
    "            throughput_std.append(0)\n",
    "\n",
    "    if throughput_cv:\n",
    "        bars = plt.bar(\n",
    "            range(len(throughput_cv)),\n",
    "            throughput_cv,\n",
    "            color=[colors[i] for i in range(len(throughput_cv))],\n",
    "            alpha=0.8,\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=1.2,\n",
    "        )\n",
    "\n",
    "        # Add value labels on bars\n",
    "        for bar, cv in zip(bars, throughput_cv, strict=True):\n",
    "            plt.text(\n",
    "                bar.get_x() + bar.get_width() / 2,\n",
    "                bar.get_height() + max(throughput_cv) * 0.01,\n",
    "                f\"{cv:.3f}\",\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "                fontweight=\"bold\",\n",
    "                fontsize=10,\n",
    "            )\n",
    "\n",
    "        plt.xlabel(\"Configuration\", fontsize=12, fontweight=\"bold\")\n",
    "        plt.ylabel(\n",
    "            \"Throughput Coefficient of Variation\",\n",
    "            fontsize=12,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "        plt.title(\n",
    "            \"Throughput Stability Analysis\\n(Lower CV = More Stable)\",\n",
    "            fontsize=14,\n",
    "            fontweight=\"bold\",\n",
    "            pad=15,\n",
    "        )\n",
    "        plt.xticks(range(len(config_labels)), config_labels, rotation=45, ha=\"right\")\n",
    "        plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5, axis=\"y\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Generate throughput analysis summary\n",
    "    log.info(\"\\n=== Throughput Analysis Summary ===\")\n",
    "\n",
    "    if avg_throughputs:\n",
    "        best_throughput_idx = np.argmax(avg_throughputs)\n",
    "        worst_throughput_idx = np.argmin(avg_throughputs)\n",
    "        most_stable_idx = np.argmin(throughput_cv) if throughput_cv else 0\n",
    "\n",
    "        log.info(\"🚀 Highest Average Throughput:\")\n",
    "        log.info(\"   UUID: %s\", this_cell_results_list[best_throughput_idx][\"run_uuid\"])\n",
    "        log.info(\n",
    "            \"   Local Experts: %s\",\n",
    "            this_cell_results_list[best_throughput_idx][\"n_local_experts\"],\n",
    "        )\n",
    "        log.info(\n",
    "            \"   Overlapping Factor: %s\",\n",
    "            this_cell_results_list[best_throughput_idx][\"overlapping_factor\"],\n",
    "        )\n",
    "        log.info(\n",
    "            \"   Average Throughput: %.2f tokens/s\",\n",
    "            avg_throughputs[best_throughput_idx],\n",
    "        )\n",
    "\n",
    "        log.info(\"\\n🐌 Lowest Average Throughput:\")\n",
    "        log.info(\n",
    "            \"   UUID: %s\",\n",
    "            this_cell_results_list[worst_throughput_idx][\"run_uuid\"],\n",
    "        )\n",
    "        log.info(\n",
    "            \"   Local Experts: %s\",\n",
    "            this_cell_results_list[worst_throughput_idx][\"n_local_experts\"],\n",
    "        )\n",
    "        log.info(\n",
    "            \"   Overlapping Factor: %s\",\n",
    "            this_cell_results_list[worst_throughput_idx][\"overlapping_factor\"],\n",
    "        )\n",
    "        log.info(\n",
    "            \"   Average Throughput: %.2f tokens/s\",\n",
    "            avg_throughputs[worst_throughput_idx],\n",
    "        )\n",
    "\n",
    "        if throughput_cv:\n",
    "            log.info(\"\\n📊 Most Stable Throughput:\")\n",
    "            log.info(\"   UUID: %s\", this_cell_results_list[most_stable_idx][\"run_uuid\"])\n",
    "            log.info(\n",
    "                \"   Local Experts: %s\",\n",
    "                this_cell_results_list[most_stable_idx][\"n_local_experts\"],\n",
    "            )\n",
    "            log.info(\n",
    "                \"   Overlapping Factor: %s\",\n",
    "                this_cell_results_list[most_stable_idx][\"overlapping_factor\"],\n",
    "            )\n",
    "            log.info(\n",
    "                \"   Coefficient of Variation: %.4f\",\n",
    "                throughput_cv[most_stable_idx],\n",
    "            )\n",
    "\n",
    "        # Throughput vs configuration correlations\n",
    "        if len(local_experts) > 1:\n",
    "            log.info(\"\\n🔍 Throughput Correlations:\")\n",
    "            le_corr = np.corrcoef(local_experts, avg_throughputs)[0, 1]\n",
    "            of_corr = np.corrcoef(overlapping_factors, avg_throughputs)[0, 1]\n",
    "            log.info(\"   Local Experts vs Throughput: %.3f\", le_corr)\n",
    "            log.info(\"   Overlapping Factor vs Throughput: %.3f\", of_corr)\n",
    "\n",
    "    log.info(\"✅ Throughput analysis completed!\")\n",
    "\n",
    "else:\n",
    "    log.info(\"❌ No results available for throughput analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef8cce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_cell_results_list = results_list\n",
    "if EXCLUDE_INCOMPLETE_RUNS:\n",
    "    this_cell_results_list = complete_runs\n",
    "\n",
    "if len(this_cell_results_list) > 0:\n",
    "    log.info(\"Results summary:\")\n",
    "    log.info(\n",
    "        results_df[\n",
    "            [\n",
    "                \"run_uuid\",\n",
    "                \"n_total_clients\",\n",
    "                \"global_train_batch_size\",\n",
    "                \"n_local_experts\",\n",
    "                \"overlapping_factor\",\n",
    "                \"final_perplexity\",\n",
    "                \"total_tokens\",\n",
    "            ]\n",
    "        ].head(),\n",
    "    )\n",
    "\n",
    "    # Plot 1: Final Perplexity vs Experts Density (Local Experts)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "    scatter = plt.scatter(\n",
    "        results_df[\"n_local_experts\"],\n",
    "        results_df[\"final_perplexity\"],\n",
    "        c=results_df[\"overlapping_factor\"],\n",
    "        cmap=\"viridis\",\n",
    "        s=100,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    plt.xlabel(\"Experts Density (Local Experts per Client)\")\n",
    "    plt.ylabel(\"Final Perplexity\")\n",
    "    plt.title(\"Final Perplexity vs Experts Density\")\n",
    "    plt.colorbar(scatter, label=\"Overlapping Factor\")\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    # Plot 2: Final Perplexity vs Total Clients\n",
    "    plt.subplot(2, 2, 2)\n",
    "    scatter = plt.scatter(\n",
    "        results_df[\"n_total_clients\"],\n",
    "        results_df[\"final_perplexity\"],\n",
    "        c=results_df[\"n_local_experts\"],\n",
    "        cmap=\"plasma\",\n",
    "        s=100,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    plt.xlabel(\"Total Clients\")\n",
    "    plt.ylabel(\"Final Perplexity\")\n",
    "    plt.title(\"Final Perplexity vs Total Clients\")\n",
    "    plt.colorbar(scatter, label=\"Local Experts per Client\")\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    # Plot 3: Experts Density vs Overlapping Factor\n",
    "    plt.subplot(2, 2, 3)\n",
    "    scatter = plt.scatter(\n",
    "        results_df[\"overlapping_factor\"],\n",
    "        results_df[\"n_local_experts\"],\n",
    "        c=results_df[\"final_perplexity\"],\n",
    "        cmap=\"coolwarm\",\n",
    "        s=100,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    plt.xlabel(\"Overlapping Factor\")\n",
    "    plt.ylabel(\"Experts Density\")\n",
    "    plt.title(\"Experts Density vs Overlapping Factor\")\n",
    "    plt.colorbar(scatter, label=\"Final Perplexity\")\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    # Plot 4: Total Tokens vs Final Perplexity\n",
    "    plt.subplot(2, 2, 4)\n",
    "    scatter = plt.scatter(\n",
    "        results_df[\"total_tokens\"],\n",
    "        results_df[\"final_perplexity\"],\n",
    "        c=results_df[\"n_local_experts\"],\n",
    "        cmap=\"tab10\",\n",
    "        s=100,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    plt.xlabel(\"Total Tokens\")\n",
    "    plt.ylabel(\"Final Perplexity\")\n",
    "    plt.title(\"Total Tokens vs Final Perplexity\")\n",
    "    plt.colorbar(scatter, label=\"Experts Density\")\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    log.info(\"No results to plot. Check if data was successfully processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebe3440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot detailed perplexity curves\n",
    "\n",
    "\n",
    "this_cell_results_list = results_list\n",
    "if EXCLUDE_INCOMPLETE_RUNS:\n",
    "    this_cell_results_list = complete_runs\n",
    "\n",
    "if len(this_cell_results_list) > 0:\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # Plot 1: Perplexity vs Tokens for different expert densities\n",
    "    plt.subplot(2, 2, 1)\n",
    "    for result in this_cell_results_list:\n",
    "        if result[\"tokens\"] and result[\"perplexity\"]:\n",
    "            tokens = np.array(result[\"tokens\"])\n",
    "            perplexity = np.array(result[\"perplexity\"])\n",
    "            # Only plot non-NaN values\n",
    "            valid_mask = ~np.isnan(perplexity)\n",
    "            if np.any(valid_mask):\n",
    "                label = (\n",
    "                    f\"UUID: {result['run_uuid'][:8]}...\"\n",
    "                    f\" (LE: {result['n_local_experts']},\"\n",
    "                    f\" OF: {result['overlapping_factor']})\"\n",
    "                )\n",
    "                plt.plot(\n",
    "                    tokens[valid_mask],\n",
    "                    perplexity[valid_mask],\n",
    "                    label=label,\n",
    "                    linewidth=2,\n",
    "                    alpha=0.8,\n",
    "                )\n",
    "\n",
    "    plt.xlabel(\"Total Tokens\")\n",
    "    plt.ylabel(\"Perplexity\")\n",
    "    plt.title(\"Perplexity vs Tokens by Expert Configuration\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.yscale(\"log\")\n",
    "\n",
    "    # Plot 2: Convergence comparison (normalized tokens)\n",
    "    plt.subplot(2, 2, 2)\n",
    "    for result in this_cell_results_list:\n",
    "        if result[\"tokens\"] and result[\"perplexity\"]:\n",
    "            tokens = np.array(result[\"tokens\"])\n",
    "            perplexity = np.array(result[\"perplexity\"])\n",
    "            valid_mask = ~np.isnan(perplexity)\n",
    "            if np.any(valid_mask) and len(tokens[valid_mask]) > 0:\n",
    "                # Normalize tokens to [0, 1] for comparison\n",
    "                tokens_norm = (tokens[valid_mask] - tokens[valid_mask].min()) / (\n",
    "                    tokens[valid_mask].max() - tokens[valid_mask].min() + 1e-8\n",
    "                )\n",
    "                label = (\n",
    "                    f\"LE: {result['n_local_experts']},\"\n",
    "                    f\" OF: {result['overlapping_factor']}\"\n",
    "                )\n",
    "                plt.plot(\n",
    "                    tokens_norm,\n",
    "                    perplexity[valid_mask],\n",
    "                    label=label,\n",
    "                    linewidth=2,\n",
    "                    alpha=0.8,\n",
    "                )\n",
    "\n",
    "    plt.xlabel(\"Normalized Training Progress\")\n",
    "    plt.ylabel(\"Perplexity\")\n",
    "    plt.title(\"Convergence Comparison (Normalized)\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.yscale(\"log\")\n",
    "\n",
    "    # Plot 3: Final performance summary\n",
    "    plt.subplot(2, 2, 3)\n",
    "    # Group by experts density for box plot\n",
    "    expert_densities = sorted(results_df[\"n_local_experts\"].unique())\n",
    "    perplexity_by_density = [\n",
    "        results_df[results_df[\"n_local_experts\"] == ed][\"final_perplexity\"].to_numpy()\n",
    "        for ed in expert_densities\n",
    "    ]\n",
    "\n",
    "    plt.boxplot(perplexity_by_density)\n",
    "    plt.xlabel(\"Local Experts\")\n",
    "    plt.ylabel(\"Final Perplexity\")\n",
    "    plt.title(\"Final Perplexity Distribution by Local Experts\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    # Plot 4: Efficiency analysis (final perplexity vs total tokens)\n",
    "    plt.subplot(2, 2, 4)\n",
    "    for result in this_cell_results_list:\n",
    "        plt.scatter(\n",
    "            result[\"total_tokens\"],\n",
    "            result[\"final_perplexity\"],\n",
    "            s=result[\"n_local_experts\"] * 50\n",
    "            + 50,  # Size proportional to expert density\n",
    "            alpha=0.7,\n",
    "            label=(\n",
    "                f\"LE: {result['n_local_experts']},\"\n",
    "                f\" OF: {result['overlapping_factor']}\"\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Total Tokens\")\n",
    "    plt.ylabel(\"Final Perplexity\")\n",
    "    plt.title(\"Efficiency: Final Perplexity vs Training Cost\\n(Size ∝ Local Experts)\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Summary statistics\n",
    "    log.info(\"\\n=== Summary Statistics ===\")\n",
    "    log.info(\"Number of configurations analyzed: %s\", len(results_df))\n",
    "    log.info(\n",
    "        \"Local experts range: %s - %s\",\n",
    "        results_df[\"n_local_experts\"].min(),\n",
    "        results_df[\"n_local_experts\"].max(),\n",
    "    )\n",
    "    log.info(\n",
    "        \"Overlapping factor range: %s - %s\",\n",
    "        results_df[\"overlapping_factor\"].min(),\n",
    "        results_df[\"overlapping_factor\"].max(),\n",
    "    )\n",
    "    log.info(\n",
    "        \"Final perplexity range: %s - %s\",\n",
    "        results_df[\"final_perplexity\"].min(),\n",
    "        results_df[\"final_perplexity\"].max(),\n",
    "    )\n",
    "    log.info(\n",
    "        \"Best performing configuration (lowest perplexity): UUID %s\",\n",
    "        results_df.loc[results_df[\"final_perplexity\"].idxmin(), \"run_uuid\"],\n",
    "    )\n",
    "    results_df[\"efficiency\"] = (\n",
    "        results_df[\"final_perplexity\"] / results_df[\"total_tokens\"]\n",
    "    )\n",
    "    log.info(\n",
    "        \"Most efficient configuration (lowest perplexity/token ratio): UUID %s\",\n",
    "        results_df.loc[results_df[\"efficiency\"].idxmin(), \"run_uuid\"],\n",
    "    )\n",
    "else:\n",
    "    log.info(\"No results available for plotting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ba0d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table and insights\n",
    "\n",
    "\n",
    "this_cell_results_list = results_list\n",
    "if EXCLUDE_INCOMPLETE_RUNS:\n",
    "    this_cell_results_list = complete_runs\n",
    "\n",
    "if len(this_cell_results_list) > 0:\n",
    "    log.info(\"=== Expert Density Analysis Summary Table ===\")\n",
    "\n",
    "    # Create a clean summary table\n",
    "    summary_columns = [\n",
    "        \"run_uuid\",\n",
    "        \"n_total_clients\",\n",
    "        \"global_train_batch_size\",\n",
    "        \"n_local_experts\",\n",
    "        \"overlapping_factor\",\n",
    "        \"n_total_experts\",\n",
    "        \"final_perplexity\",\n",
    "        \"total_tokens\",\n",
    "    ]\n",
    "\n",
    "    summary_df = results_df[summary_columns].copy()\n",
    "    summary_df[\"run_uuid_short\"] = summary_df[\"run_uuid\"].str[:12] + \"...\"\n",
    "    summary_df = summary_df.drop(\"run_uuid\", axis=1)\n",
    "\n",
    "    # Reorder columns for better readability\n",
    "    summary_df = summary_df[\n",
    "        [\n",
    "            \"run_uuid_short\",\n",
    "            \"n_total_clients\",\n",
    "            \"n_total_experts\",\n",
    "            \"n_local_experts\",\n",
    "            \"overlapping_factor\",\n",
    "            \"global_train_batch_size\",\n",
    "            \"final_perplexity\",\n",
    "            \"total_tokens\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Sort by final perplexity for easy comparison\n",
    "    summary_df = summary_df.sort_values(\"final_perplexity\")\n",
    "\n",
    "    log.info(summary_df.to_string(index=False, float_format=\"%.4f\"))\n",
    "\n",
    "    log.info(\"\\n=== Key Insights ===\")\n",
    "\n",
    "    # Best and worst performing configurations\n",
    "    best_idx = results_df[\"final_perplexity\"].idxmin()\n",
    "    worst_idx = results_df[\"final_perplexity\"].idxmax()\n",
    "\n",
    "    log.info(\"🏆 Best Performance:\")\n",
    "    log.info(\"   UUID: %s\", results_df.loc[best_idx, \"run_uuid\"])\n",
    "    log.info(\"   Local Experts: %s\", results_df.loc[best_idx, \"n_local_experts\"])\n",
    "    log.info(\n",
    "        \"   Overlapping Factor: %s\",\n",
    "        results_df.loc[best_idx, \"overlapping_factor\"],\n",
    "    )\n",
    "    log.info(\"   Final Perplexity: %.4f\", results_df.loc[best_idx, \"final_perplexity\"])\n",
    "\n",
    "    log.info(\"\\n📉 Worst Performance:\")\n",
    "    log.info(\"   UUID: %s\", results_df.loc[worst_idx, \"run_uuid\"])\n",
    "    log.info(\"   Local Experts: %s\", results_df.loc[worst_idx, \"n_local_experts\"])\n",
    "    log.info(\n",
    "        \"   Overlapping Factor: %s\",\n",
    "        results_df.loc[worst_idx, \"overlapping_factor\"],\n",
    "    )\n",
    "    log.info(\"   Final Perplexity: %.4f\", results_df.loc[worst_idx, \"final_perplexity\"])\n",
    "\n",
    "    # Correlation analysis\n",
    "    log.info(\"\\n🔍 Correlation Analysis:\")\n",
    "    correlations = results_df[\n",
    "        [\n",
    "            \"n_local_experts\",\n",
    "            \"overlapping_factor\",\n",
    "            \"n_total_clients\",\n",
    "            \"global_train_batch_size\",\n",
    "            \"final_perplexity\",\n",
    "            \"total_tokens\",\n",
    "        ]\n",
    "    ].corr()\n",
    "\n",
    "    perplexity_corr = correlations[\"final_perplexity\"].sort_values(\n",
    "        key=abs,\n",
    "        ascending=False,\n",
    "    )\n",
    "    log.info(\"   Correlation with Final Perplexity:\")\n",
    "    for var, corr in perplexity_corr.items():\n",
    "        if var != \"final_perplexity\":\n",
    "            log.info(\"   - %s: %.3f\", var, corr)\n",
    "\n",
    "    # Efficiency analysis\n",
    "    if \"efficiency\" in results_df.columns:\n",
    "        most_efficient_idx = results_df[\"efficiency\"].idxmin()\n",
    "        log.info(\"\\n⚡ Most Efficient Configuration:\")\n",
    "        log.info(\"   UUID: %s\", results_df.loc[most_efficient_idx, \"run_uuid\"])\n",
    "        log.info(\n",
    "            \"   Local Experts: %s\",\n",
    "            results_df.loc[most_efficient_idx, \"n_local_experts\"],\n",
    "        )\n",
    "        log.info(\n",
    "            \"   Overlapping Factor: %s\",\n",
    "            results_df.loc[most_efficient_idx, \"overlapping_factor\"],\n",
    "        )\n",
    "        log.info(\n",
    "            \"   Efficiency (Perplexity/Token): %.2e\",\n",
    "            results_df.loc[most_efficient_idx, \"efficiency\"],\n",
    "        )\n",
    "\n",
    "    # Local experts impact\n",
    "    log.info(\"\\n📊 Local Experts Impact:\")\n",
    "    experts_groups = results_df.groupby(\"n_local_experts\")[\"final_perplexity\"].agg(\n",
    "        [\"mean\", \"std\", \"count\"],\n",
    "    )\n",
    "    log.info(\"   Average Final Perplexity by Local Experts:\")\n",
    "    for n_experts, stats in experts_groups.iterrows():\n",
    "        log.info(\n",
    "            \"   - %d Local Experts: %.4f ± %.4f (n=%d)\",\n",
    "            n_experts,\n",
    "            stats[\"mean\"],\n",
    "            stats[\"std\"],\n",
    "            int(stats[\"count\"]),\n",
    "        )\n",
    "\n",
    "else:\n",
    "    log.info(\"No results available for summary analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232c08c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fedmoe-plots",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
