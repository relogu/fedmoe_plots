{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce54d73d",
   "metadata": {},
   "source": [
    "# Expert Density Analysis for Federated Mixture of Experts\n",
    "\n",
    "This notebook analyzes the impact of expert density (number of local experts per client) on model performance in federated learning scenarios with Mixture of Experts (MoE) architectures.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "1. **Data Collection**: Download metrics from WandB for different expert density configurations\n",
    "2. **Performance Analysis**: Compare perplexity vs. token consumption across configurations\n",
    "3. **Efficiency Evaluation**: Assess the trade-offs between expert density and training efficiency\n",
    "4. **Configuration Impact**: Understand how overlapping factors and client counts affect performance\n",
    "\n",
    "## Key Metrics\n",
    "\n",
    "- **Expert Density**: Number of local experts per client\n",
    "- **Overlapping Factor**: Factor determining expert sharing across clients\n",
    "- **Final Perplexity**: Model performance at the end of training\n",
    "- **Total Tokens**: Computational cost measure\n",
    "- **Efficiency**: Ratio of final perplexity to total tokens consumed\n",
    "\n",
    "## Analysis Workflow\n",
    "\n",
    "1. Load and filter runs from WandB based on run UUID patterns\n",
    "2. Extract configuration parameters for each run\n",
    "3. Download server and client metrics data\n",
    "4. Compute perplexity vs. token relationships\n",
    "5. Aggregate results by configuration parameters\n",
    "6. Generate visualizations and summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b1255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import operator\n",
    "from datetime import UTC, datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "\n",
    "from fedmoe_plots.data_analysis import (\n",
    "    ColumnNotFoundError,\n",
    "    get_device_throughput_series,\n",
    "    get_microbatch_size,\n",
    "    get_n_gpus,\n",
    "    get_perplexity_versus_tokens,\n",
    "    get_throughput_series,\n",
    ")\n",
    "from fedmoe_plots.plotting_utils import configure_logging_for_jupyter\n",
    "from fedmoe_plots.wandb_utils import (\n",
    "    ClientRunNotFoundError,\n",
    "    download_photon_metrics,\n",
    "    get_clientrun_property_from_config,\n",
    "    get_experts_global_batch_size,\n",
    "    get_n_local_experts,\n",
    "    get_non_experts_global_batch_size,\n",
    "    get_run_uuid_from_config,\n",
    "    remove_runs_by_regex,\n",
    ")\n",
    "\n",
    "configure_logging_for_jupyter()\n",
    "\n",
    "log = logging.getLogger(\"experts_density.ipynb\")\n",
    "\n",
    "EXCLUDE_INCOMPLETE_RUNS = True\n",
    "BASE_BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3d8662",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_uuid_1 = \"4e_rho_bspol_scratch1\"\n",
    "run_uuid_2 = \"8e_rho_bspol_scratch1\"\n",
    "api = wandb.Api(timeout=100)\n",
    "runs = api.runs(\n",
    "    path=\"camlsys/photon\",\n",
    "    filters={\"display_name\": {\"$regex\": f\"(^{run_uuid_1})|(^{run_uuid_2})\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0be7302",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in runs:\n",
    "    log.info(\"Run name: %s, ID: %s, State: %s\", run.name, run.id, run.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181b0f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_n_total_clients = {\n",
    "    get_clientrun_property_from_config(\n",
    "        run,\n",
    "        get_property_fn=lambda config: config[\"fl\"][\"n_total_clients\"],\n",
    "    )\n",
    "    for run in runs\n",
    "}\n",
    "unique_local_batch_size = {\n",
    "    get_clientrun_property_from_config(\n",
    "        run,\n",
    "        get_property_fn=lambda config: config[\"llm_config\"][\"global_train_batch_size\"],\n",
    "    )\n",
    "    for run in runs\n",
    "}\n",
    "unique_overlapping_factor = {\n",
    "    get_clientrun_property_from_config(\n",
    "        run,\n",
    "        get_property_fn=lambda config: config[\"fl\"][\"experts_overlapping_factor\"],\n",
    "    )\n",
    "    for run in runs\n",
    "}\n",
    "unique_n_total_experts = {\n",
    "    get_clientrun_property_from_config(\n",
    "        run,\n",
    "        get_property_fn=lambda config: config[\"llm_config\"][\"model\"][\"ffn_config\"][\n",
    "            \"ff_n_experts\"\n",
    "        ],\n",
    "    )\n",
    "    for run in runs\n",
    "}\n",
    "unique_n_local_experts = {\n",
    "    get_clientrun_property_from_config(\n",
    "        run,\n",
    "        get_property_fn=get_n_local_experts,\n",
    "    )\n",
    "    for run in runs\n",
    "}\n",
    "log.info(\n",
    "    \"Unique n_total_clients: %s, unique_local_batch_size: %s, \"\n",
    "    \"unique_overlapping_factor: %s, unique_n_total_experts: %s, \"\n",
    "    \"unique_n_local_experts: %s\",\n",
    "    unique_n_total_clients,\n",
    "    unique_local_batch_size,\n",
    "    unique_overlapping_factor,\n",
    "    unique_n_total_experts,\n",
    "    unique_n_local_experts,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d187338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collection and processing for expert density analysis\n",
    "\n",
    "log.info(\"üîÑ Starting data collection and processing...\")\n",
    "unique_run_uuids = {\n",
    "    str(\n",
    "        get_clientrun_property_from_config(\n",
    "            run,\n",
    "            get_property_fn=operator.itemgetter(\"run_uuid\"),\n",
    "        ),\n",
    "    )\n",
    "    for run in runs\n",
    "}\n",
    "log.info(\"Found %s runs to process\", len(unique_run_uuids))\n",
    "results_list = []\n",
    "\n",
    "for i, unique_run_uuid in enumerate(unique_run_uuids):\n",
    "    log.info(\n",
    "        \"üìä Processing run %s/%s: %s\",\n",
    "        i + 1,\n",
    "        len(unique_run_uuids),\n",
    "        unique_run_uuid,\n",
    "    )\n",
    "\n",
    "    run: wandb.apis.public.Run | None = (  # pyright: ignore[reportAttributeAccessIssue]\n",
    "        None\n",
    "    )\n",
    "    try:\n",
    "        # Get any run that matches the unique run UUID\n",
    "        run = next(r for r in runs if get_run_uuid_from_config(r) == unique_run_uuid)\n",
    "        assert run is not None, f\"Run with UUID {unique_run_uuid} not found\"\n",
    "\n",
    "        # Extract configuration parameters\n",
    "        config = run.config\n",
    "        run_uuid = get_clientrun_property_from_config(\n",
    "            run,\n",
    "            get_property_fn=operator.itemgetter(\"run_uuid\"),\n",
    "        )\n",
    "\n",
    "        n_total_clients = get_clientrun_property_from_config(\n",
    "            run,\n",
    "            get_property_fn=lambda config: config[\"fl\"][\"n_total_clients\"],\n",
    "        )\n",
    "\n",
    "        n_total_experts = get_clientrun_property_from_config(\n",
    "            run,\n",
    "            get_property_fn=lambda config: config[\"llm_config\"][\"model\"][\"ffn_config\"][\n",
    "                \"ff_n_experts\"\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        overlapping_factor = get_clientrun_property_from_config(\n",
    "            run,\n",
    "            get_property_fn=lambda config: config[\"fl\"][\"experts_overlapping_factor\"],\n",
    "        )\n",
    "\n",
    "        local_train_batch_size = get_clientrun_property_from_config(\n",
    "            run,\n",
    "            get_property_fn=lambda config: config[\"llm_config\"][\n",
    "                \"global_train_batch_size\"\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # Calculate derived metrics\n",
    "        n_local_experts = get_n_local_experts(config)\n",
    "        experts_global_batch_size = get_experts_global_batch_size(config)\n",
    "        non_experts_global_batch_size = get_non_experts_global_batch_size(config)\n",
    "\n",
    "        log.info(\n",
    "            \"üìã Configuration: TE=%s, LE=%s, Clients=%s, OF=%s\",\n",
    "            n_total_experts,\n",
    "            n_local_experts,\n",
    "            n_total_clients,\n",
    "            overlapping_factor,\n",
    "        )\n",
    "\n",
    "        # Download and process data\n",
    "        log.info(\"üîΩ Downloading data for %s...\", run_uuid)\n",
    "\n",
    "        try:\n",
    "            # Download photon metrics for the run\n",
    "            assert run_uuid is not None, \"Run UUID must not be None\"\n",
    "            assert isinstance(\n",
    "                run_uuid,\n",
    "                str,\n",
    "            ), f\"Run UUID must be a string not a {type(run_uuid)}\"\n",
    "            _s_df, clients_df = download_photon_metrics(\n",
    "                base_name=\"camlsys/photon\",\n",
    "                run_uuid=run_uuid,\n",
    "            )\n",
    "\n",
    "            # Try to get perplexity vs tokens data\n",
    "            assert n_total_clients is not None, \"Total clients must not be None\"\n",
    "            assert isinstance(\n",
    "                n_total_clients,\n",
    "                int,\n",
    "            ), f\"Total clients must be an integer not a {type(n_total_clients)}\"\n",
    "            result = get_perplexity_versus_tokens(\n",
    "                client_metrics_df=clients_df,\n",
    "                n_clients_per_round=n_total_clients,\n",
    "            )\n",
    "\n",
    "            tokens, perplexity = result\n",
    "\n",
    "            if len(tokens) == 0 or len(perplexity) == 0:\n",
    "                log.warning(\"‚ùå Empty data arrays for %s\", run_uuid)\n",
    "                continue\n",
    "\n",
    "            # Try to get the throughput data\n",
    "            steps, device_throughput = get_device_throughput_series(\n",
    "                client_metrics_df=clients_df,\n",
    "                moving_window=10,\n",
    "            )\n",
    "            _steps, throughput = get_throughput_series(\n",
    "                client_metrics_df=clients_df,\n",
    "                moving_window=10,\n",
    "            )\n",
    "            n_gpus = get_n_gpus(clients_df)\n",
    "\n",
    "            # Get the microbatch size\n",
    "            microbatch_size = get_microbatch_size(clients_df)\n",
    "\n",
    "            # Calculate metrics\n",
    "            final_perplexity = (\n",
    "                perplexity.iloc[-1] if len(perplexity) > 0 else float(\"nan\")\n",
    "            )\n",
    "            total_tokens = tokens.iloc[-1] if len(tokens) > 0 else 0\n",
    "            n_data_points = len(tokens)\n",
    "\n",
    "            log.info(\n",
    "                (\n",
    "                    \"   ‚úÖ Data processed: %d points,\"\n",
    "                    \" Final perplexity: %.4f, Total tokens: %.0f\"\n",
    "                ),\n",
    "                n_data_points,\n",
    "                final_perplexity,\n",
    "                total_tokens,\n",
    "            )\n",
    "\n",
    "            # Store results\n",
    "            results_list.append(\n",
    "                {\n",
    "                    \"run_uuid\": str(run_uuid),\n",
    "                    \"n_total_clients\": n_total_clients,\n",
    "                    \"n_total_experts\": n_total_experts,\n",
    "                    \"n_local_experts\": n_local_experts,\n",
    "                    \"overlapping_factor\": overlapping_factor,\n",
    "                    \"local_train_batch_size\": local_train_batch_size,\n",
    "                    \"experts_global_batch_size\": experts_global_batch_size,\n",
    "                    \"non_experts_global_batch_size\": non_experts_global_batch_size,\n",
    "                    \"final_perplexity\": final_perplexity,\n",
    "                    \"total_tokens\": total_tokens,\n",
    "                    \"n_data_points\": n_data_points,\n",
    "                    \"tokens\": (\n",
    "                        tokens.tolist() if hasattr(tokens, \"tolist\") else list(tokens)\n",
    "                    ),\n",
    "                    \"perplexity\": (\n",
    "                        perplexity.tolist()\n",
    "                        if hasattr(perplexity, \"tolist\")\n",
    "                        else list(perplexity)\n",
    "                    ),\n",
    "                    \"steps\": (\n",
    "                        steps.tolist() if hasattr(steps, \"tolist\") else list(steps)\n",
    "                    ),\n",
    "                    \"device_throughput\": (\n",
    "                        device_throughput.tolist()\n",
    "                        if hasattr(device_throughput, \"tolist\")\n",
    "                        else list(device_throughput)\n",
    "                    ),\n",
    "                    \"throughput\": (\n",
    "                        throughput.tolist()\n",
    "                        if hasattr(throughput, \"tolist\")\n",
    "                        else list(throughput)\n",
    "                    ),\n",
    "                    \"n_gpus\": n_gpus,\n",
    "                    \"microbatch_size\": microbatch_size,\n",
    "                },\n",
    "            )\n",
    "\n",
    "        except ClientRunNotFoundError:\n",
    "            # Log exception with stack trace\n",
    "            log.exception(\n",
    "                \"   ‚ö†Ô∏è  Client run not found for %s\",\n",
    "                run_uuid,\n",
    "                stack_info=True,\n",
    "            )\n",
    "\n",
    "            # Remove this run from WandB runs to avoid further processing\n",
    "            remove_runs_by_regex(\"camlsys/photon\", f\"^{run_uuid}*\")\n",
    "            continue\n",
    "\n",
    "        except ColumnNotFoundError:\n",
    "            log.exception(\n",
    "                \"   ‚ö†Ô∏è Column not found in client metrics DataFrame for %s. \"\n",
    "                \"We assume this run crashed and doesn't have the expected data.\",\n",
    "                run_uuid,\n",
    "                stack_info=True,\n",
    "            )\n",
    "\n",
    "            # Remove this run from WandB runs to avoid further processing\n",
    "            remove_runs_by_regex(\"camlsys/photon\", f\"^{run_uuid}*\")\n",
    "            continue\n",
    "\n",
    "        except Exception:\n",
    "            log.exception(\"   ‚ùå Error processing %s\", run_uuid, stack_info=True)\n",
    "            continue\n",
    "\n",
    "    except Exception:\n",
    "        assert run is not None, \"Run must not be None\"\n",
    "        log.exception(\n",
    "            \"   ‚ùå Error extracting config for run %s\",\n",
    "            run.name,\n",
    "            stack_info=True,\n",
    "        )\n",
    "        continue\n",
    "\n",
    "log.info(\"\\n‚úÖ Data collection completed!\")\n",
    "log.info(\n",
    "    \"Successfully processed %d out of %d runs\",\n",
    "    len(results_list),\n",
    "    len(unique_run_uuids),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9e9e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced summary with configuration analysis\n",
    "log.info(\"\\n=== Summary ===\")\n",
    "log.info(\n",
    "    \"Successfully processed %d out of %d runs\",\n",
    "    len(results_list),\n",
    "    len(unique_run_uuids),\n",
    ")\n",
    "\n",
    "# Analyze planned configurations if we have results\n",
    "if results_list:\n",
    "    log.info(\"\\nüìä CONFIGURATION ANALYSIS üìä\")\n",
    "    log.info(\"=\" * 60)\n",
    "\n",
    "    # Group by n_total_experts to analyze configurations\n",
    "    experts_groups = {}\n",
    "    for result in results_list:\n",
    "        n_experts = result[\"n_total_experts\"]\n",
    "        if n_experts not in experts_groups:\n",
    "            experts_groups[n_experts] = []\n",
    "        experts_groups[n_experts].append(result)\n",
    "\n",
    "    for n_experts in sorted(experts_groups.keys()):\n",
    "        runs_for_experts = experts_groups[n_experts]\n",
    "        log.info(\"\\nüî¢ Total Experts: %d\", n_experts)\n",
    "        log.info(\"   Number of runs: %d\", len(runs_for_experts))\n",
    "\n",
    "        # Collect the theoretical configurations\n",
    "        theoretical_configs: set[tuple[int, int, int]] = set()\n",
    "        for i in range(1, n_experts + 1):\n",
    "            # If i is not a power of 2, skip it\n",
    "            if (i & (i - 1)) != 0:\n",
    "                continue\n",
    "            for k in range(i, n_experts + 1):\n",
    "                # If k is not a power of 2, skip it\n",
    "                if (k & (k - 1)) != 0:\n",
    "                    continue\n",
    "                theoretical_configs.update(\n",
    "                    (i, k, local_batch_size)\n",
    "                    for local_batch_size in {\n",
    "                        BASE_BATCH_SIZE // i,\n",
    "                        BASE_BATCH_SIZE // k,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        # Analyze the configuration space for this expert count\n",
    "        actual_configs: set[tuple[int, int, int]] = set()\n",
    "        actual_configs.update(\n",
    "            (\n",
    "                run[\"overlapping_factor\"],\n",
    "                run[\"n_total_clients\"],\n",
    "                run[\"local_train_batch_size\"],\n",
    "            )\n",
    "            for run in runs_for_experts\n",
    "        )\n",
    "\n",
    "        # Calculate theoretical vs actual configurations\n",
    "        log.info(\"   Theoretical configurations: %d\", len(theoretical_configs))\n",
    "        log.info(\"   Actual runs: %d\", len(actual_configs))\n",
    "\n",
    "        if len(actual_configs) < len(theoretical_configs):\n",
    "            coverage = (len(actual_configs) / len(theoretical_configs)) * 100\n",
    "            log.info(\"   Coverage: %.1f%% ‚ö†Ô∏è\", coverage)\n",
    "        else:\n",
    "            log.info(\"   Coverage: 100%% ‚úÖ\")\n",
    "\n",
    "        # Show detailed configuration breakdown by showing first those that are missing\n",
    "        # and then those that are present\n",
    "        missing_configs = theoretical_configs - actual_configs\n",
    "        if missing_configs:\n",
    "            log.warning(\"   ‚ö†Ô∏è Missing configurations (%d):\", len(missing_configs))\n",
    "            for config in sorted(missing_configs):\n",
    "                log.warning(\n",
    "                    \"      ‚Ä¢ Overlapping Factor: %.1f, Clients: %d, \"\n",
    "                    \"Local Batch Size: %d\",\n",
    "                    config[0],\n",
    "                    config[1],\n",
    "                    config[2],\n",
    "                )\n",
    "        else:\n",
    "            log.info(\"   All theoretical configurations are present\")\n",
    "\n",
    "# Check for runs that didn't reach 1 billion tokens and log warnings\n",
    "incomplete_runs = []\n",
    "complete_runs = []\n",
    "if results_list:\n",
    "    log.info(\"\\n‚ö†Ô∏è  TOKEN COUNT ANALYSIS ‚ö†Ô∏è\")\n",
    "    log.info(\"=\" * 60)\n",
    "\n",
    "    billion_tokens = 1e9\n",
    "\n",
    "    for result in results_list:\n",
    "        if result[\"total_tokens\"] < billion_tokens:\n",
    "            incomplete_runs.append(result)\n",
    "        else:\n",
    "            complete_runs.append(result)\n",
    "\n",
    "    if incomplete_runs:\n",
    "        log.warning(\n",
    "            \"üî¥ WARNING: %d run(s) did NOT reach 1 billion tokens:\",\n",
    "            len(incomplete_runs),\n",
    "        )\n",
    "        log.info(\"-\" * 60)\n",
    "\n",
    "        for i, result in enumerate(incomplete_runs, 1):\n",
    "            log.info(\"\\n%s. Run UUID: %s\", i, result[\"run_uuid\"])\n",
    "            log.info(\n",
    "                \"   Total Tokens: %s (%.3fB)\",\n",
    "                format(result[\"total_tokens\"], \",\"),\n",
    "                result[\"total_tokens\"] / 1e9,\n",
    "            )\n",
    "            log.info(\n",
    "                \"   Completion: %.1f%% of 1B tokens\",\n",
    "                result[\"total_tokens\"] / billion_tokens * 100,\n",
    "            )\n",
    "            log.info(\"   üìã Full Configuration:\")\n",
    "            log.info(\"      ‚Ä¢ Total Experts: %s\", result[\"n_total_experts\"])\n",
    "            log.info(\"      ‚Ä¢ Local Experts: %s\", result[\"n_local_experts\"])\n",
    "            log.info(\"      ‚Ä¢ Total Clients: %s\", result[\"n_total_clients\"])\n",
    "            log.info(\"      ‚Ä¢ Overlapping Factor: %.1f\", result[\"overlapping_factor\"])\n",
    "            log.info(\n",
    "                \"      ‚Ä¢ Expert Global Batch Size: %s\",\n",
    "                result[\"experts_global_batch_size\"],\n",
    "            )\n",
    "            log.info(\n",
    "                \"      ‚Ä¢ Non-Expert Global Batch Size: %s\",\n",
    "                result[\"non_experts_global_batch_size\"],\n",
    "            )\n",
    "            log.info(\"      ‚Ä¢ Local Batch Size: %s\", result[\"local_train_batch_size\"])\n",
    "            log.info(\"      ‚Ä¢ Final Perplexity: %.4f\", result[\"final_perplexity\"])\n",
    "            log.info(\"      ‚Ä¢ Data Points: %s\", result[\"n_data_points\"])\n",
    "\n",
    "    if complete_runs:\n",
    "        log.info(\n",
    "            \"‚úÖ %d run(s) successfully reached 1+ billion tokens:\",\n",
    "            len(complete_runs),\n",
    "        )\n",
    "        for result in complete_runs:\n",
    "            log.info(\n",
    "                \"   ‚Ä¢ %s: %d tokens (%.3fB)\",\n",
    "                result[\"run_uuid\"],\n",
    "                result[\"total_tokens\"],\n",
    "                result[\"total_tokens\"] / 1e9,\n",
    "            )\n",
    "\n",
    "    log.info(\"\\nüìä Token Count Summary:\")\n",
    "    log.info(\"   ‚Ä¢ Complete runs (‚â•1B tokens): %d\", len(complete_runs))\n",
    "    log.info(\"   ‚Ä¢ Incomplete runs (<1B tokens): %d\", len(incomplete_runs))\n",
    "    if results_list:\n",
    "        avg_tokens = sum(r[\"total_tokens\"] for r in results_list) / len(results_list)\n",
    "        log.info(\n",
    "            \"   ‚Ä¢ Average tokens across all runs: %.0f (%.3fB)\",\n",
    "            avg_tokens,\n",
    "            avg_tokens / 1e9,\n",
    "        )\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "this_cell_results_list = results_list\n",
    "if EXCLUDE_INCOMPLETE_RUNS:\n",
    "    this_cell_results_list = complete_runs\n",
    "if this_cell_results_list:\n",
    "    results_df = pd.DataFrame(this_cell_results_list)\n",
    "else:\n",
    "    log.info(\"No results to analyze\")\n",
    "    results_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503a2d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump complete run UUIDs to file\n",
    "\n",
    "if complete_runs:\n",
    "    # Extract just the UUIDs from complete runs\n",
    "    complete_run_uuids = [run[\"run_uuid\"] for run in complete_runs]\n",
    "\n",
    "    # Create output filename with timestamp\n",
    "    timestamp = datetime.now(tz=UTC).strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_file = Path(f\"complete_run_uuids_{timestamp}.json\")\n",
    "\n",
    "    # Save to JSON file for easy reading\n",
    "    output_data = {\n",
    "        \"timestamp\": timestamp,\n",
    "        \"total_complete_runs\": len(complete_run_uuids),\n",
    "        \"total_runs_analyzed\": len(results_list),\n",
    "        \"complete_run_uuids\": complete_run_uuids,\n",
    "        \"run_details\": [\n",
    "            {\n",
    "                \"run_uuid\": run[\"run_uuid\"],\n",
    "                \"n_total_experts\": run[\"n_total_experts\"],\n",
    "                \"n_local_experts\": run[\"n_local_experts\"],\n",
    "                \"overlapping_factor\": run[\"overlapping_factor\"],\n",
    "                \"final_perplexity\": run[\"final_perplexity\"],\n",
    "                \"total_tokens\": run[\"total_tokens\"],\n",
    "            }\n",
    "            for run in complete_runs\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    with output_file.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(output_data, f, indent=2)\n",
    "\n",
    "    log.info(\"‚úÖ Complete run UUIDs saved to: %s\", output_file)\n",
    "    log.info(\"üìä Summary:\")\n",
    "    log.info(\"   - Total complete runs: %d\", len(complete_run_uuids))\n",
    "    log.info(\"   - Total runs analyzed: %d\", len(results_list))\n",
    "    log.info(\"   - Complete run UUIDs with total experts:\")\n",
    "    for i, run in enumerate(complete_runs, 1):\n",
    "        log.info(\"     %d. %s (TE: %d)\", i, run[\"run_uuid\"], run[\"n_total_experts\"])\n",
    "\n",
    "    # Also save a simple text file with just the UUIDs and total experts (one per line)\n",
    "    txt_file = Path(f\"complete_run_uuids_{timestamp}.txt\")\n",
    "    with txt_file.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"# Complete Run UUIDs with Total Experts\\n\")\n",
    "        f.write(\"# Format: run_uuid,n_total_experts\\n\")\n",
    "        for run in complete_runs:\n",
    "            f.write(f\"{run['run_uuid']},{run['n_total_experts']}\\n\")\n",
    "\n",
    "    log.info(\"üìù Also saved text version with total experts to: %s\", txt_file)\n",
    "\n",
    "else:\n",
    "    log.warning(\"‚ùå No complete runs found to save\")\n",
    "    log.info(\"   All %d runs are incomplete (< 1B tokens)\", len(results_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f6be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Expert Density Analysis with Independent, High-Quality Plots\n",
    "log.info(\"Generating enhanced Expert Density Analysis with improved cosmetics...\")\n",
    "\n",
    "this_cell_results_list = results_list\n",
    "if EXCLUDE_INCOMPLETE_RUNS:\n",
    "    this_cell_results_list = complete_runs\n",
    "\n",
    "if len(this_cell_results_list) > 0:\n",
    "    # Quick token count check before plotting\n",
    "    billion_tokens = 1e9\n",
    "    incomplete_runs = [\n",
    "        r for r in this_cell_results_list if r[\"total_tokens\"] < billion_tokens\n",
    "    ]\n",
    "\n",
    "    if incomplete_runs:\n",
    "        log.warning(\n",
    "            \"\\n ATTENTION: %s of %s runs didn't reach 1B tokens!\",\n",
    "            len(incomplete_runs),\n",
    "            len(this_cell_results_list),\n",
    "        )\n",
    "        log.info(\"   This may affect training convergence analysis.\\n\")\n",
    "\n",
    "    # Set up enhanced plotting style\n",
    "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "    colors = plt.cm.Set1(  # pyright: ignore[reportAttributeAccessIssue]\n",
    "        np.linspace(0, 1, len(this_cell_results_list)),\n",
    "    )\n",
    "\n",
    "    # ==== PLOT 1: Training Progress - Perplexity vs Total Tokens ====\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    for i, result in enumerate(this_cell_results_list):\n",
    "        tokens = np.array(result[\"tokens\"])\n",
    "        perplexity = np.array(result[\"perplexity\"])\n",
    "\n",
    "        # Enhanced legend label with key information\n",
    "        incomplete_indicator = \" ‚ö†Ô∏è\" if result[\"total_tokens\"] < billion_tokens else \"\"\n",
    "        legend_label = (\n",
    "            f\"TE: {result['n_total_experts']}, LE: {result['n_local_experts']}, \"\n",
    "            f\"TC: {result['n_total_clients']}, OF: {result['overlapping_factor']:.1f}, \"\n",
    "            f\"LocalBS: {result['local_train_batch_size']}, \"\n",
    "            f\"EgBS: {result['experts_global_batch_size']},\"\n",
    "            f\" nEgBS: {result['non_experts_global_batch_size']}{incomplete_indicator}\"\n",
    "        )\n",
    "\n",
    "        # Use different line style for incomplete runs\n",
    "        linestyle = \"--\" if result[\"total_tokens\"] < billion_tokens else \"-\"\n",
    "        alpha = 0.7 if result[\"total_tokens\"] < billion_tokens else 0.9\n",
    "        linewidth = 2.0 if result[\"total_tokens\"] < billion_tokens else 2.5\n",
    "\n",
    "        plt.plot(\n",
    "            tokens,\n",
    "            perplexity,\n",
    "            label=legend_label,\n",
    "            linewidth=linewidth,\n",
    "            alpha=alpha,\n",
    "            color=colors[i],\n",
    "            linestyle=linestyle,\n",
    "            marker=\"o\" if i < 3 else (\"s\" if i < 6 else \"^\"),\n",
    "            markersize=4,\n",
    "            markevery=max(1, len(tokens) // 15),\n",
    "            markerfacecolor=\"white\",\n",
    "            markeredgewidth=1.5,\n",
    "            markeredgecolor=colors[i],\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Total Tokens\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.ylabel(\"Language Perplexity\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.title(\n",
    "        (\n",
    "            \"Training Progress: Perplexity vs Total Tokens\\n\"\n",
    "            \"Expert Density Analysis with Batch Size Configurations\"\n",
    "        ),\n",
    "        fontsize=16,\n",
    "        fontweight=\"bold\",\n",
    "        pad=20,\n",
    "    )\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend(\n",
    "        frameon=True,\n",
    "        fancybox=True,\n",
    "        shadow=True,\n",
    "        ncol=1 if len(this_cell_results_list) <= 4 else 2,\n",
    "        fontsize=10,\n",
    "        loc=\"upper right\",\n",
    "    )\n",
    "    plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3173d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Expert Density Analysis with Independent, High-Quality Plots\n",
    "log.info(\"Generating enhanced Expert Density Analysis with improved cosmetics...\")\n",
    "\n",
    "this_cell_results_list = results_list\n",
    "if EXCLUDE_INCOMPLETE_RUNS:\n",
    "    this_cell_results_list = complete_runs\n",
    "\n",
    "if len(this_cell_results_list) > 0:\n",
    "    # Quick token count check before plotting\n",
    "    billion_tokens = 1e9\n",
    "    incomplete_runs = [\n",
    "        r for r in this_cell_results_list if r[\"total_tokens\"] < billion_tokens\n",
    "    ]\n",
    "\n",
    "    if incomplete_runs:\n",
    "        log.warning(\n",
    "            \"\\n ATTENTION: %s of %s runs didn't reach 1B tokens!\",\n",
    "            len(incomplete_runs),\n",
    "            len(this_cell_results_list),\n",
    "        )\n",
    "        log.info(\"   This may affect training convergence analysis.\\n\")\n",
    "\n",
    "    # Set up enhanced plotting style\n",
    "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "    colors = plt.cm.Set1(  # pyright: ignore[reportAttributeAccessIssue]\n",
    "        np.linspace(0, 1, len(this_cell_results_list)),\n",
    "    )\n",
    "    # ==== PLOT 2: Final Performance Scatter ====\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Create scatter plot with enhanced styling\n",
    "    for result in this_cell_results_list:\n",
    "        marker = \"o\" if result[\"total_tokens\"] >= billion_tokens else \"^\"\n",
    "        alpha = 0.8 if result[\"total_tokens\"] >= billion_tokens else 0.6\n",
    "        edge_color = \"darkred\" if result[\"total_tokens\"] < billion_tokens else \"black\"\n",
    "        edge_width = 2.5 if result[\"total_tokens\"] < billion_tokens else 1.5\n",
    "\n",
    "        scatter = plt.scatter(\n",
    "            result[\"n_local_experts\"],\n",
    "            result[\"final_perplexity\"],\n",
    "            c=result[\"overlapping_factor\"],\n",
    "            s=200,\n",
    "            alpha=alpha,\n",
    "            cmap=\"viridis\",\n",
    "            edgecolors=edge_color,\n",
    "            linewidth=edge_width,\n",
    "            marker=marker,\n",
    "            vmin=min(r[\"overlapping_factor\"] for r in this_cell_results_list),\n",
    "            vmax=max(r[\"overlapping_factor\"] for r in this_cell_results_list),\n",
    "        )\n",
    "\n",
    "    # Enhanced annotations\n",
    "    for result in this_cell_results_list:\n",
    "        incomplete_indicator = \" ‚ö†Ô∏è\" if result[\"total_tokens\"] < billion_tokens else \"\"\n",
    "        annotation_text = (\n",
    "            f\"TE: {result['n_total_experts']}, LE:{result['n_local_experts']}, \"\n",
    "            f\"TC: {result['n_total_clients']}, \"\n",
    "            f\"LocalBS: {result['local_train_batch_size']}, \"\n",
    "            f\"EBS: {result['experts_global_batch_size']},\"\n",
    "            f\" NEBS: {result['non_experts_global_batch_size']}, \"\n",
    "            f\"{result['total_tokens'] / 1e9:.2f}B tokens{incomplete_indicator}\"\n",
    "        )\n",
    "        plt.annotate(\n",
    "            annotation_text,\n",
    "            (result[\"n_local_experts\"], result[\"final_perplexity\"]),\n",
    "            xytext=(8, 8),\n",
    "            textcoords=\"offset points\",\n",
    "            fontsize=9,\n",
    "            bbox={\n",
    "                \"boxstyle\": \"round,pad=0.3\",\n",
    "                \"facecolor\": \"white\",\n",
    "                \"alpha\": 0.8,\n",
    "                \"edgecolor\": \"gray\",\n",
    "            },\n",
    "            arrowprops={\n",
    "                \"arrowstyle\": \"->\",\n",
    "                \"connectionstyle\": \"arc3,rad=0.1\",\n",
    "                \"alpha\": 0.6,\n",
    "            },\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Number of Local Experts\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.ylabel(\"Final Perplexity\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.title(\n",
    "        (\n",
    "            \"Final Performance vs Expert Configuration\\n\"\n",
    "            \"Color = Overlapping Factor | Red edges = Incomplete runs (<1B tokens)\"\n",
    "        ),\n",
    "        fontsize=16,\n",
    "        fontweight=\"bold\",\n",
    "        pad=20,\n",
    "    )\n",
    "\n",
    "    cbar = plt.colorbar(scatter, shrink=0.8, aspect=20)\n",
    "    cbar.set_label(\"Overlapping Factor\", fontsize=12, fontweight=\"bold\")\n",
    "    cbar.ax.tick_params(labelsize=10)\n",
    "\n",
    "    plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c560369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Expert Density Analysis with Independent, High-Quality Plots\n",
    "log.info(\"Generating enhanced Expert Density Analysis with improved cosmetics...\")\n",
    "\n",
    "this_cell_results_list = results_list\n",
    "if EXCLUDE_INCOMPLETE_RUNS:\n",
    "    this_cell_results_list = complete_runs\n",
    "\n",
    "if len(this_cell_results_list) > 0:\n",
    "    # Quick token count check before plotting\n",
    "    billion_tokens = 1e9\n",
    "    incomplete_runs = [\n",
    "        r for r in this_cell_results_list if r[\"total_tokens\"] < billion_tokens\n",
    "    ]\n",
    "\n",
    "    if incomplete_runs:\n",
    "        log.warning(\n",
    "            \"\\n ATTENTION: %s of %s runs didn't reach 1B tokens!\",\n",
    "            len(incomplete_runs),\n",
    "            len(this_cell_results_list),\n",
    "        )\n",
    "        log.info(\"   This may affect training convergence analysis.\\n\")\n",
    "\n",
    "    # Set up enhanced plotting style\n",
    "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "    colors = plt.cm.Set1(  # pyright: ignore[reportAttributeAccessIssue]\n",
    "        np.linspace(0, 1, len(this_cell_results_list)),\n",
    "    )\n",
    "    # ==== PLOT 3: Training Efficiency Analysis ====\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    for i, result in enumerate(this_cell_results_list):\n",
    "        incomplete_indicator = \" ‚ö†Ô∏è\" if result[\"total_tokens\"] < billion_tokens else \"\"\n",
    "        alpha = 0.7 if result[\"total_tokens\"] < billion_tokens else 0.8\n",
    "        edge_color = \"darkred\" if result[\"total_tokens\"] < billion_tokens else \"black\"\n",
    "        edge_width = 2.5 if result[\"total_tokens\"] < billion_tokens else 1.5\n",
    "\n",
    "        plt.scatter(\n",
    "            result[\"total_tokens\"] / 1e9,  # Convert to billions for readability\n",
    "            result[\"final_perplexity\"],\n",
    "            s=result[\"n_local_experts\"] * 80\n",
    "            + 120,  # Size proportional to local experts\n",
    "            alpha=alpha,\n",
    "            color=colors[i],\n",
    "            edgecolors=edge_color,\n",
    "            linewidth=edge_width,\n",
    "            label=(\n",
    "                f\"TE: {result['n_total_experts']}, \"\n",
    "                f\"LE: {result['n_local_experts']}, \"\n",
    "                f\"TC: {result['n_total_clients']}, \"\n",
    "                f\"OF: {result['overlapping_factor']:.1f}\"\n",
    "                f\"{incomplete_indicator}\"\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Total Tokens Consumed (Billions)\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.ylabel(\"Final Perplexity\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.title(\n",
    "        (\n",
    "            \"Training Efficiency Analysis\\n\"\n",
    "            \"Marker Size ‚àù Local Experts | Red edges = Incomplete runs\"\n",
    "        ),\n",
    "        fontsize=16,\n",
    "        fontweight=\"bold\",\n",
    "        pad=20,\n",
    "    )\n",
    "\n",
    "    plt.legend(\n",
    "        title=(\n",
    "            \"TE: Total Experts, LE: Local Experts, TC: Total Clients,\"\n",
    "            \" OF: Overlap Factor\"\n",
    "            \"\\n‚ö†Ô∏è = Incomplete runs (<1B tokens)\"\n",
    "        ),\n",
    "        frameon=True,\n",
    "        fancybox=True,\n",
    "        shadow=True,\n",
    "        fontsize=10,\n",
    "        title_fontsize=11,\n",
    "        loc=\"upper left\",\n",
    "        bbox_to_anchor=(1.02, 1),\n",
    "    )\n",
    "    plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ==== PLOT 4: Convergence Rate Comparison ====\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    for i, result in enumerate(this_cell_results_list):\n",
    "        tokens = np.array(result[\"tokens\"])\n",
    "        perplexity = np.array(result[\"perplexity\"])\n",
    "\n",
    "        if len(tokens) > 1:\n",
    "            tokens_norm = (tokens - tokens.min()) / (tokens.max() - tokens.min())\n",
    "            incomplete_indicator = (\n",
    "                \" ‚ö†Ô∏è\" if result[\"total_tokens\"] < billion_tokens else \"\"\n",
    "            )\n",
    "            linestyle = \"--\" if result[\"total_tokens\"] < billion_tokens else \"-\"\n",
    "            alpha = 0.7 if result[\"total_tokens\"] < billion_tokens else 0.9\n",
    "            linewidth = 2.0 if result[\"total_tokens\"] < billion_tokens else 2.5\n",
    "\n",
    "            plt.plot(\n",
    "                tokens_norm,\n",
    "                perplexity,\n",
    "                label=(\n",
    "                    f\"TE: {result['n_total_experts']}, \"\n",
    "                    f\"LE: {result['n_local_experts']}, \"\n",
    "                    f\"TC: {result['n_total_clients']}, \"\n",
    "                    f\"OF: {result['overlapping_factor']:.1f}\"\n",
    "                    f\"{incomplete_indicator}\"\n",
    "                ),\n",
    "                linewidth=linewidth,\n",
    "                alpha=alpha,\n",
    "                linestyle=linestyle,\n",
    "                color=colors[i],\n",
    "                marker=\"o\" if i < 3 else (\"s\" if i < 6 else \"^\"),\n",
    "                markersize=4,\n",
    "                markevery=max(1, len(tokens_norm) // 20),\n",
    "                markerfacecolor=\"white\",\n",
    "                markeredgewidth=1.5,\n",
    "                markeredgecolor=colors[i],\n",
    "            )\n",
    "\n",
    "    plt.xlabel(\n",
    "        \"Normalized Training Progress (0 = Start, 1 = End)\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    plt.ylabel(\"Language Perplexity\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.title(\n",
    "        (\n",
    "            \"Convergence Rate Comparison\\n\"\n",
    "            \"Normalized Training Progress with Expert Configurations\"\n",
    "        ),\n",
    "        fontsize=16,\n",
    "        fontweight=\"bold\",\n",
    "        pad=20,\n",
    "    )\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend(\n",
    "        title=(\n",
    "            \"TE: Total Experts, LE: Local Experts, TC: Total Clients,\"\n",
    "            \" OF: Overlap Factor\"\n",
    "            \"\\n ‚ö†Ô∏è = Incomplete runs (<1B tokens)\"\n",
    "        ),\n",
    "        frameon=True,\n",
    "        fancybox=True,\n",
    "        shadow=True,\n",
    "        fontsize=10,\n",
    "        title_fontsize=11,\n",
    "        ncol=1 if len(this_cell_results_list) <= 4 else 2,\n",
    "    )\n",
    "    plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ==== PLOT 5: Configuration Summary Heatmap ====\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Create a summary matrix for visualization\n",
    "    config_data = []\n",
    "    config_labels = []\n",
    "\n",
    "    for result in this_cell_results_list:\n",
    "        config_data.append(\n",
    "            [\n",
    "                result[\"n_total_experts\"],\n",
    "                result[\"n_local_experts\"],\n",
    "                result[\"overlapping_factor\"],\n",
    "                result[\"experts_global_batch_size\"],\n",
    "                result[\"non_experts_global_batch_size\"],\n",
    "                result[\"final_perplexity\"],\n",
    "                result[\"total_tokens\"] / 1e9,\n",
    "            ],\n",
    "        )\n",
    "        incomplete_mark = \"‚ö†Ô∏è\" if result[\"total_tokens\"] < billion_tokens else \"\"\n",
    "        config_labels.append(f\"{result['run_uuid'][:8]}...{incomplete_mark}\")\n",
    "\n",
    "    config_matrix = np.array(config_data)\n",
    "\n",
    "    # Normalize each column to [0, 1] for better heatmap visualization\n",
    "    config_matrix_norm = np.zeros_like(config_matrix)\n",
    "    for i in range(config_matrix.shape[1]):\n",
    "        col_min, col_max = config_matrix[:, i].min(), config_matrix[:, i].max()\n",
    "        if col_max > col_min:\n",
    "            config_matrix_norm[:, i] = (config_matrix[:, i] - col_min) / (\n",
    "                col_max - col_min\n",
    "            )\n",
    "        else:\n",
    "            config_matrix_norm[:, i] = 0.5  # If all values are the same\n",
    "\n",
    "    im = plt.imshow(config_matrix_norm.T, cmap=\"RdYlBu_r\", aspect=\"auto\", alpha=0.8)\n",
    "\n",
    "    # Set labels\n",
    "    plt.xticks(range(len(config_labels)), config_labels, rotation=45, ha=\"right\")\n",
    "    plt.yticks(\n",
    "        range(len(config_data[0])),\n",
    "        [\n",
    "            \"Total Experts\",\n",
    "            \"Local Experts\",\n",
    "            \"Overlap Factor\",\n",
    "            \"Expert Global BS\",\n",
    "            \"Non-Expert Global BS\",\n",
    "            \"Final Perplexity\",\n",
    "            \"Total Tokens (B)\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Add text annotations with actual values\n",
    "    for i in range(len(config_labels)):\n",
    "        for j in range(len(config_data[0])):\n",
    "            if j < 5:  # Integer values\n",
    "                text = f\"{int(config_matrix[i, j])}\"\n",
    "            else:  # Float values\n",
    "                text = f\"{config_matrix[i, j]:.2f}\"\n",
    "            plt.text(\n",
    "                i,\n",
    "                j,\n",
    "                text,\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                color=\"white\" if config_matrix_norm[i, j] > 0.5 else \"black\",\n",
    "                fontweight=\"bold\",\n",
    "                fontsize=9,\n",
    "            )\n",
    "\n",
    "    plt.title(\n",
    "        (\n",
    "            \"Configuration Summary Heatmap\\n\"\n",
    "            \"Normalized values with actual values overlaid\"\n",
    "        ),\n",
    "        fontsize=16,\n",
    "        fontweight=\"bold\",\n",
    "        pad=20,\n",
    "    )\n",
    "\n",
    "    cbar = plt.colorbar(im, shrink=0.8, aspect=20)\n",
    "    cbar.set_label(\n",
    "        \"Normalized Value (0 = Min, 1 = Max)\",\n",
    "        fontsize=12,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    log.info(\"‚úÖ Enhanced analysis with improved cosmetics completed!\")\n",
    "    log.info(\"üìä Generated 5 independent plots:\")\n",
    "    log.info(\"   1. Training Progress (Perplexity vs Tokens)\")\n",
    "    log.info(\"   2. Final Performance Scatter\")\n",
    "    log.info(\"   3. Training Efficiency Analysis\")\n",
    "    log.info(\"   4. Convergence Rate Comparison\")\n",
    "    log.info(\"   5. Configuration Summary Heatmap\")\n",
    "\n",
    "    if incomplete_runs:\n",
    "        log.warning(\n",
    "            \"‚ö†Ô∏è  Note: %s run(s) marked as incomplete in all plots\",\n",
    "            len(incomplete_runs),\n",
    "        )\n",
    "\n",
    "else:\n",
    "    log.info(\"‚ùå No results available for analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6457a570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Expert Density Analysis - Throughput vs Steps Analysis\n",
    "log.info(\"Generating Throughput vs Steps Analysis with focus on Local Experts...\")\n",
    "\n",
    "this_cell_results_list = results_list\n",
    "if EXCLUDE_INCOMPLETE_RUNS:\n",
    "    this_cell_results_list = complete_runs\n",
    "\n",
    "if len(this_cell_results_list) > 0:\n",
    "    # Quick token count check before plotting\n",
    "    billion_tokens = 1e9\n",
    "    incomplete_runs = [\n",
    "        r for r in this_cell_results_list if r[\"total_tokens\"] < billion_tokens\n",
    "    ]\n",
    "\n",
    "    if incomplete_runs:\n",
    "        log.warning(\n",
    "            \"\\n ATTENTION: %s of %s runs didn't reach 1B tokens!\",\n",
    "            len(incomplete_runs),\n",
    "            len(this_cell_results_list),\n",
    "        )\n",
    "        log.info(\"   This may affect throughput analysis.\\n\")\n",
    "\n",
    "    # Set up enhanced plotting style with consistent colors for local experts, GPUs, and\n",
    "    # local batch size\n",
    "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "\n",
    "    # Create color mapping based on combinations of local experts, GPUs, and local\n",
    "    # batch size\n",
    "    unique_local_experts = sorted(\n",
    "        {r[\"n_local_experts\"] for r in this_cell_results_list},\n",
    "    )\n",
    "    unique_n_gpus = sorted(\n",
    "        {\n",
    "            r[\"n_total_clients\"] for r in this_cell_results_list\n",
    "        },  # assuming n_total_clients represents GPUs\n",
    "    )\n",
    "    unique_local_batch_size = sorted(\n",
    "        {r[\"local_train_batch_size\"] for r in this_cell_results_list},\n",
    "    )\n",
    "\n",
    "    # Create all unique combinations of (local_experts, n_gpus, local_batch_size)\n",
    "    unique_combinations = sorted(\n",
    "        {\n",
    "            (r[\"n_local_experts\"], r[\"n_total_clients\"], r[\"local_train_batch_size\"])\n",
    "            for r in this_cell_results_list\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Generate enough distinct colors for all combinations\n",
    "    n_combinations = len(unique_combinations)\n",
    "    # Use a combination of different colormaps to get more distinct colors\n",
    "    if n_combinations <= 20:\n",
    "        color_map = plt.cm.tab20(  # pyright: ignore[reportAttributeAccessIssue]\n",
    "            np.linspace(0, 1, n_combinations),\n",
    "        )\n",
    "    else:\n",
    "        # For more combinations, use multiple colormaps\n",
    "        colors1 = plt.cm.tab20(\n",
    "            np.linspace(0, 1, 20),\n",
    "        )  # pyright: ignore[reportAttributeAccessIssue]\n",
    "        colors2 = plt.cm.Set3(\n",
    "            np.linspace(0, 1, n_combinations - 20),\n",
    "        )  # pyright: ignore[reportAttributeAccessIssue]\n",
    "        color_map = np.vstack([colors1, colors2])\n",
    "\n",
    "    # Create color dictionary for (local_experts, n_gpus, local_batch_size) combinations\n",
    "    combination_color_dict = {\n",
    "        combo: color_map[i] for i, combo in enumerate(unique_combinations)\n",
    "    }\n",
    "\n",
    "    # Create symbol mapping based on local batch size\n",
    "    unique_batch_sizes = sorted(unique_local_batch_size)\n",
    "    batch_size_symbols = [\n",
    "        \"o\",\n",
    "        \"s\",\n",
    "        \"^\",\n",
    "        \"D\",\n",
    "        \"v\",\n",
    "        \"<\",\n",
    "        \">\",\n",
    "        \"p\",\n",
    "        \"*\",\n",
    "        \"h\",\n",
    "        \"H\",\n",
    "        \"+\",\n",
    "        \"x\",\n",
    "    ]\n",
    "    batch_size_symbol_dict = {\n",
    "        bs: batch_size_symbols[i % len(batch_size_symbols)]\n",
    "        for i, bs in enumerate(unique_batch_sizes)\n",
    "    }\n",
    "\n",
    "    # Create linestyle mapping based on number of GPUs\n",
    "    unique_gpu_counts = sorted(unique_n_gpus)\n",
    "    gpu_linestyles = [\"-\", \"--\", \"-.\", \":\"]\n",
    "    gpu_linestyle_dict = {\n",
    "        gpu: gpu_linestyles[i % len(gpu_linestyles)]\n",
    "        for i, gpu in enumerate(unique_gpu_counts)\n",
    "    }\n",
    "\n",
    "    # Also keep the old local experts only color dict for backward compatibility\n",
    "    local_experts_color_dict = {}\n",
    "    for i, le in enumerate(unique_local_experts):\n",
    "        base_idx = i * len(unique_n_gpus) // len(unique_local_experts)\n",
    "        local_experts_color_dict[le] = color_map[base_idx % n_combinations]\n",
    "\n",
    "    log.info(\n",
    "        \"Found %s unique local expert configurations: %s\",\n",
    "        len(unique_local_experts),\n",
    "        unique_local_experts,\n",
    "    )\n",
    "    log.info(\n",
    "        \"Found %s unique GPU configurations: %s\",\n",
    "        len(unique_n_gpus),\n",
    "        unique_n_gpus,\n",
    "    )\n",
    "    log.info(\n",
    "        \"Found %s unique local batch size configurations: %s\",\n",
    "        len(unique_local_batch_size),\n",
    "        unique_local_batch_size,\n",
    "    )\n",
    "    log.info(\n",
    "        \"Found %s unique (local_experts, n_gpus, local_batch_size) combinations: %s\",\n",
    "        len(unique_combinations),\n",
    "        unique_combinations,\n",
    "    )\n",
    "\n",
    "    # ==== PLOT 6: Enhanced Throughput Analysis ====\n",
    "    plt.figure(figsize=(20, 15))\n",
    "\n",
    "    # Subplot 1: Raw throughput over training steps (colored by all three dimensions)\n",
    "    plt.subplot(2, 3, 1)\n",
    "    for result in this_cell_results_list:\n",
    "        steps = np.array(result[\"steps\"])\n",
    "        throughput = np.array(result[\"throughput\"])\n",
    "\n",
    "        if len(steps) > 0 and len(throughput) > 0:\n",
    "            # Color based on combination of local experts, GPUs, and local batch size\n",
    "            combo_key = (\n",
    "                result[\"n_local_experts\"],\n",
    "                result[\"n_total_clients\"],\n",
    "                result[\"local_train_batch_size\"],\n",
    "            )\n",
    "            color = combination_color_dict[combo_key]\n",
    "\n",
    "            # Symbol based on local batch size\n",
    "            marker = batch_size_symbol_dict[result[\"local_train_batch_size\"]]\n",
    "\n",
    "            # Line style based on GPU count\n",
    "            linestyle_base = gpu_linestyle_dict[result[\"n_total_clients\"]]\n",
    "\n",
    "            # Enhanced legend label with key information including all dimensions\n",
    "            incomplete_indicator = (\n",
    "                \" ‚ö†Ô∏è\" if result[\"total_tokens\"] < billion_tokens else \"\"\n",
    "            )\n",
    "            legend_label = (\n",
    "                f\"LE: {result['n_local_experts']}, \"\n",
    "                f\"GPUs: {result['n_total_clients']}, \"\n",
    "                f\"TE: {result['n_total_experts']}, \"\n",
    "                f\"OF: {result['overlapping_factor']:.1f}, \"\n",
    "                f\"LocalBS: {result['local_train_batch_size']}, \"\n",
    "                f\"mBS: {result['microbatch_size']}, \"\n",
    "                f\"{incomplete_indicator}\"\n",
    "            )\n",
    "\n",
    "            # Use different line style for incomplete runs\n",
    "            linestyle = (\n",
    "                \"--\" if result[\"total_tokens\"] < billion_tokens else linestyle_base\n",
    "            )\n",
    "            alpha = 0.7 if result[\"total_tokens\"] < billion_tokens else 0.9\n",
    "            linewidth = 2.0 if result[\"total_tokens\"] < billion_tokens else 2.5\n",
    "\n",
    "            plt.plot(\n",
    "                steps,\n",
    "                throughput,\n",
    "                label=legend_label,\n",
    "                linewidth=linewidth,\n",
    "                alpha=alpha,\n",
    "                color=color,\n",
    "                linestyle=linestyle,\n",
    "                marker=marker,\n",
    "                markersize=4,\n",
    "                markevery=max(1, len(steps) // 20),\n",
    "                markerfacecolor=\"white\",\n",
    "                markeredgewidth=1.2,\n",
    "                markeredgecolor=color,\n",
    "            )\n",
    "\n",
    "    plt.xlabel(\"Training Steps\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.ylabel(\"Throughput (tokens/s)\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.title(\n",
    "        \"Throughput vs Training Steps\\n\"\n",
    "        \"Grouped by Local Experts + GPU Count + Local Batch Size\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "        pad=15,\n",
    "    )\n",
    "    plt.legend(\n",
    "        frameon=True,\n",
    "        fancybox=True,\n",
    "        shadow=True,\n",
    "        ncol=1,\n",
    "        fontsize=8,\n",
    "        loc=\"best\",\n",
    "    )\n",
    "    plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5)\n",
    "\n",
    "    # Calculate statistics by combination of local experts, GPUs, and local batch size\n",
    "    combination_stats = {}\n",
    "    for result in this_cell_results_list:\n",
    "        combo = (\n",
    "            result[\"n_local_experts\"],\n",
    "            result[\"n_total_clients\"],\n",
    "            result[\"local_train_batch_size\"],\n",
    "        )\n",
    "        throughput = np.array(result[\"throughput\"])\n",
    "        if len(throughput) > 0:\n",
    "            avg_throughput = np.mean(throughput)\n",
    "            if combo not in combination_stats:\n",
    "                combination_stats[combo] = []\n",
    "            combination_stats[combo].append(avg_throughput)\n",
    "\n",
    "    # Calculate mean and std for each combination\n",
    "    combination_summary = {}\n",
    "    for combo, throughputs in combination_stats.items():\n",
    "        combination_summary[combo] = {\n",
    "            \"mean\": np.mean(throughputs),\n",
    "            \"std\": np.std(throughputs),\n",
    "            \"count\": len(throughputs),\n",
    "            \"values\": throughputs,\n",
    "        }\n",
    "\n",
    "    # Also calculate statistics by local experts only for compatibility\n",
    "    throughput_stats = {}\n",
    "    for result in this_cell_results_list:\n",
    "        le = result[\"n_local_experts\"]\n",
    "        throughput = np.array(result[\"throughput\"])\n",
    "        if len(throughput) > 0:\n",
    "            avg_throughput = np.mean(throughput)\n",
    "            if le not in throughput_stats:\n",
    "                throughput_stats[le] = []\n",
    "            throughput_stats[le].append(avg_throughput)\n",
    "\n",
    "    # Calculate mean and std for each local expert configuration\n",
    "    local_experts_summary = {}\n",
    "    for le, throughputs in throughput_stats.items():\n",
    "        local_experts_summary[le] = {\n",
    "            \"mean\": np.mean(throughputs),\n",
    "            \"std\": np.std(throughputs),\n",
    "            \"count\": len(throughputs),\n",
    "            \"values\": throughputs,\n",
    "        }\n",
    "\n",
    "    # Subplot 2: Average throughput by combination with error bars\n",
    "    plt.subplot(2, 3, 2)\n",
    "    combination_list = sorted(combination_summary.keys())\n",
    "    means = [combination_summary[combo][\"mean\"] for combo in combination_list]\n",
    "    stds = [combination_summary[combo][\"std\"] for combo in combination_list]\n",
    "    colors = [combination_color_dict[combo] for combo in combination_list]\n",
    "\n",
    "    # Create x-axis labels showing LE + GPU + Local Batch Size info\n",
    "    x_labels = [\n",
    "        f\"LE:{combo[0]}\\nGPU:{combo[1]}\\nBS:{combo[2]}\" for combo in combination_list\n",
    "    ]\n",
    "    x_positions = range(len(combination_list))\n",
    "\n",
    "    bars = plt.bar(\n",
    "        x_positions,\n",
    "        means,\n",
    "        yerr=stds,\n",
    "        color=colors,\n",
    "        alpha=0.8,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=1.2,\n",
    "        capsize=5,\n",
    "        error_kw={\"linewidth\": 2, \"ecolor\": \"black\"},\n",
    "    )\n",
    "\n",
    "    # Add value labels on bars\n",
    "    for i, (combo, mean, std) in enumerate(\n",
    "        zip(combination_list, means, stds, strict=True),\n",
    "    ):\n",
    "        count = combination_summary[combo][\"count\"]\n",
    "        plt.text(\n",
    "            i,\n",
    "            mean + std + max(means) * 0.02,\n",
    "            f\"{mean:.1f}¬±{std:.1f}\\n(n={count})\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontweight=\"bold\",\n",
    "            fontsize=8,\n",
    "        )\n",
    "\n",
    "    plt.xticks(x_positions, x_labels, fontsize=9, rotation=45)\n",
    "    plt.xlabel(\"Local Experts + GPU Count + Batch Size\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.ylabel(\"Average Throughput (tokens/s)\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.title(\n",
    "        \"Average Throughput by LE+GPU+BS Combination\\n\"\n",
    "        \"Error bars show ¬±1 standard deviation\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "        pad=15,\n",
    "    )\n",
    "    plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5, axis=\"y\")\n",
    "\n",
    "    # Subplot 3: Detailed scatter plot with individual runs\n",
    "    plt.subplot(2, 3, 3)\n",
    "    for result in this_cell_results_list:\n",
    "        throughput = np.array(result[\"throughput\"])\n",
    "        if len(throughput) > 0:\n",
    "            avg_throughput = np.mean(throughput)\n",
    "            combo_key = (\n",
    "                result[\"n_local_experts\"],\n",
    "                result[\"n_total_clients\"],\n",
    "                result[\"local_train_batch_size\"],\n",
    "            )\n",
    "            color = combination_color_dict[combo_key]\n",
    "\n",
    "            # Symbol based on local batch size\n",
    "            marker = batch_size_symbol_dict[result[\"local_train_batch_size\"]]\n",
    "\n",
    "            marker_incomplete = (\n",
    "                \"x\" if result[\"total_tokens\"] < billion_tokens else marker\n",
    "            )\n",
    "            alpha = 0.8 if result[\"total_tokens\"] >= billion_tokens else 0.6\n",
    "            edge_color = (\n",
    "                \"darkred\" if result[\"total_tokens\"] < billion_tokens else \"black\"\n",
    "            )\n",
    "            edge_width = 2.5 if result[\"total_tokens\"] < billion_tokens else 1.5\n",
    "\n",
    "            # Use local experts for x-axis but color by full combination\n",
    "            # Add slight offsets based on GPU count and batch size for better separation\n",
    "            gpu_offset = (result[\"n_total_clients\"] - min(unique_n_gpus)) * 0.05\n",
    "            bs_offset = (\n",
    "                unique_batch_sizes.index(result[\"local_train_batch_size\"])\n",
    "            ) * 0.03\n",
    "            x_pos = result[\"n_local_experts\"] + gpu_offset + bs_offset\n",
    "\n",
    "            plt.scatter(\n",
    "                x_pos,\n",
    "                avg_throughput,\n",
    "                c=[color],\n",
    "                s=120,\n",
    "                alpha=alpha,\n",
    "                edgecolors=edge_color,\n",
    "                linewidth=edge_width,\n",
    "                marker=marker_incomplete,\n",
    "                label=(\n",
    "                    f\"LE:{result['n_local_experts']}, GPU:{result['n_total_clients']},\"\n",
    "                    f\" BS:{result['local_train_batch_size']}\"\n",
    "                    if result == this_cell_results_list[0]\n",
    "                    else \"\"\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    plt.xlabel(\"Number of Local Experts\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.ylabel(\"Average Throughput (tokens/s)\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.title(\n",
    "        \"Individual Run Throughput\\nGrouped by LE+GPU+BS Combinations\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "        pad=15,\n",
    "    )\n",
    "    plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5)\n",
    "\n",
    "    # Add jitter to x-axis for better visibility\n",
    "    plt.xlim(min(unique_local_experts) - 0.5, max(unique_local_experts) + 0.5)\n",
    "\n",
    "    # Subplot 4: Box plot showing distribution by local experts (keeping original)\n",
    "    plt.subplot(2, 3, 4)\n",
    "    throughput_by_le = [\n",
    "        local_experts_summary[le][\"values\"]\n",
    "        for le in sorted(local_experts_summary.keys())\n",
    "    ]\n",
    "\n",
    "    bp = plt.boxplot(\n",
    "        throughput_by_le,\n",
    "        tick_labels=[str(le) for le in sorted(local_experts_summary.keys())],\n",
    "        patch_artist=True,\n",
    "        notch=True,\n",
    "        showmeans=True,\n",
    "    )\n",
    "\n",
    "    # Color the boxes according to local experts\n",
    "    local_experts_list = sorted(local_experts_summary.keys())\n",
    "    colors_le = [local_experts_color_dict[le] for le in local_experts_list]\n",
    "    for patch, color in zip(bp[\"boxes\"], colors_le, strict=True):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.7)\n",
    "\n",
    "    plt.xlabel(\"Number of Local Experts\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.ylabel(\"Average Throughput (tokens/s)\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.title(\n",
    "        (\n",
    "            \"Throughput Distribution by Local Experts\\n\"\n",
    "            \"Box plots with mean (triangle) and median (line)\"\n",
    "        ),\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "        pad=15,\n",
    "    )\n",
    "    plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5, axis=\"y\")\n",
    "\n",
    "    # Subplot 5: Throughput coefficient of variation by combination\n",
    "    plt.subplot(2, 3, 5)\n",
    "    cv_by_combination = {}\n",
    "    for result in this_cell_results_list:\n",
    "        combo = (\n",
    "            result[\"n_local_experts\"],\n",
    "            result[\"n_total_clients\"],\n",
    "            result[\"local_train_batch_size\"],\n",
    "        )\n",
    "        throughput = np.array(result[\"throughput\"])\n",
    "        if len(throughput) > 1:\n",
    "            cv = (\n",
    "                np.std(throughput) / np.mean(throughput)\n",
    "                if np.mean(throughput) > 0\n",
    "                else 0\n",
    "            )\n",
    "            if combo not in cv_by_combination:\n",
    "                cv_by_combination[combo] = []\n",
    "            cv_by_combination[combo].append(cv)\n",
    "\n",
    "    if cv_by_combination:\n",
    "        combo_list = sorted(cv_by_combination.keys())\n",
    "        cv_means = [np.mean(cv_by_combination[combo]) for combo in combo_list]\n",
    "        cv_stds = [\n",
    "            np.std(cv_by_combination[combo]) if len(cv_by_combination[combo]) > 1 else 0\n",
    "            for combo in combo_list\n",
    "        ]\n",
    "        colors_cv = [combination_color_dict[combo] for combo in combo_list]\n",
    "        x_labels_cv = [\n",
    "            f\"LE:{combo[0]}\\nGPU:{combo[1]}\\nBS:{combo[2]}\" for combo in combo_list\n",
    "        ]\n",
    "        x_positions_cv = range(len(combo_list))\n",
    "\n",
    "        bars = plt.bar(\n",
    "            x_positions_cv,\n",
    "            cv_means,\n",
    "            yerr=cv_stds,\n",
    "            color=colors_cv,\n",
    "            alpha=0.8,\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=1.2,\n",
    "            capsize=5,\n",
    "            error_kw={\"linewidth\": 2, \"ecolor\": \"black\"},\n",
    "        )\n",
    "\n",
    "        # Add value labels\n",
    "        for i, (combo, mean, std) in enumerate(\n",
    "            zip(combo_list, cv_means, cv_stds, strict=True),\n",
    "        ):\n",
    "            count = len(cv_by_combination[combo])\n",
    "            plt.text(\n",
    "                i,\n",
    "                mean + std + max(cv_means) * 0.02,\n",
    "                f\"{mean:.3f}¬±{std:.3f}\\n(n={count})\",\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "                fontweight=\"bold\",\n",
    "                fontsize=8,\n",
    "            )\n",
    "\n",
    "        plt.xticks(x_positions_cv, x_labels_cv, fontsize=9, rotation=45)\n",
    "        plt.xlabel(\n",
    "            \"Local Experts + GPU Count + Batch Size\",\n",
    "            fontsize=12,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "        plt.ylabel(\n",
    "            \"Throughput Coefficient of Variation\",\n",
    "            fontsize=12,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "        plt.title(\n",
    "            \"Throughput Stability by LE+GPU+BS Combination\\n(Lower CV = More Stable)\",\n",
    "            fontsize=14,\n",
    "            fontweight=\"bold\",\n",
    "            pad=15,\n",
    "        )\n",
    "        plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5, axis=\"y\")\n",
    "\n",
    "    # Subplot 6: Summary statistics table for combinations\n",
    "    plt.subplot(2, 3, 6)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Create summary table for combinations\n",
    "    table_data = []\n",
    "    headers = [\n",
    "        \"Local\\nExperts\",\n",
    "        \"GPUs\",\n",
    "        \"Batch\\nSize\",\n",
    "        \"Count\",\n",
    "        \"Mean\\nThroughput\",\n",
    "        \"Std Dev\",\n",
    "        \"CV Mean\",\n",
    "    ]\n",
    "\n",
    "    for combo in sorted(combination_summary.keys()):\n",
    "        stats = combination_summary[combo]\n",
    "        cv_stats = cv_by_combination.get(combo, [0])\n",
    "        table_data.append(\n",
    "            [\n",
    "                str(combo[0]),\n",
    "                str(combo[1]),\n",
    "                str(combo[2]),\n",
    "                str(stats[\"count\"]),\n",
    "                f\"{stats['mean']:.1f}\",\n",
    "                f\"{stats['std']:.1f}\",\n",
    "                f\"{np.mean(cv_stats):.3f}\" if cv_stats else \"N/A\",\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    # Create table\n",
    "    table = plt.table(\n",
    "        cellText=table_data,\n",
    "        colLabels=headers,\n",
    "        cellLoc=\"center\",\n",
    "        loc=\"center\",\n",
    "        bbox=[0, 0.2, 1, 0.8],\n",
    "    )\n",
    "    table.auto_set_font_size(value=False)\n",
    "    table.set_fontsize(8)\n",
    "    table.scale(1, 1.5)\n",
    "\n",
    "    # Color the rows according to combinations\n",
    "    for i, combo in enumerate(sorted(combination_summary.keys())):\n",
    "        color = combination_color_dict[combo]\n",
    "        for j in range(len(headers)):\n",
    "            table[i + 1, j].set_facecolor(color)\n",
    "            table[i + 1, j].set_alpha(0.3)\n",
    "\n",
    "    plt.title(\n",
    "        \"Throughput Summary Statistics\\nby LE+GPU+BS Combinations\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "        pad=20,\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Generate enhanced throughput analysis summary focused on combinations\n",
    "    log.info(\"\\n=== Throughput Analysis Summary by LE+GPU+BS Combinations ===\")\n",
    "\n",
    "    for combo in sorted(combination_summary.keys()):\n",
    "        stats = combination_summary[combo]\n",
    "        cv_stats = cv_by_combination.get(combo, [])\n",
    "\n",
    "        log.info(\n",
    "            \"\\nüìä %s Local Experts + %s GPUs + %s Batch Size:\",\n",
    "            combo[0],\n",
    "            combo[1],\n",
    "            combo[2],\n",
    "        )\n",
    "        log.info(\"   Number of runs: %s\", stats[\"count\"])\n",
    "        log.info(\n",
    "            \"   Average throughput: %.2f ¬± %.2f tokens/s\",\n",
    "            stats[\"mean\"],\n",
    "            stats[\"std\"],\n",
    "        )\n",
    "        log.info(\n",
    "            \"   Range: %.2f - %.2f tokens/s\",\n",
    "            min(stats[\"values\"]),\n",
    "            max(stats[\"values\"]),\n",
    "        )\n",
    "        if cv_stats:\n",
    "            log.info(\n",
    "                \"   Stability (CV): %.4f ¬± %.4f\",\n",
    "                np.mean(cv_stats),\n",
    "                np.std(cv_stats),\n",
    "            )\n",
    "\n",
    "        # Show individual run details\n",
    "        log.info(\"   Individual runs:\")\n",
    "        for result in this_cell_results_list:\n",
    "            if (\n",
    "                result[\"n_local_experts\"],\n",
    "                result[\"n_total_clients\"],\n",
    "                result[\"local_train_batch_size\"],\n",
    "            ) == combo:\n",
    "                throughput = np.array(result[\"throughput\"])\n",
    "                if len(throughput) > 0:\n",
    "                    avg_tp = np.mean(throughput)\n",
    "                    incomplete_mark = (\n",
    "                        \"‚ö†Ô∏è\" if result[\"total_tokens\"] < billion_tokens else \"‚úÖ\"\n",
    "                    )\n",
    "                    log.info(\n",
    "                        \"     %s %s...: %.2f tokens/s (TE:%s, OF:%.1f)\",\n",
    "                        incomplete_mark,\n",
    "                        result[\"run_uuid\"][:12],\n",
    "                        avg_tp,\n",
    "                        result[\"n_total_experts\"],\n",
    "                        result[\"overlapping_factor\"],\n",
    "                    )\n",
    "\n",
    "    # Statistical analysis for combinations\n",
    "    if len(combination_summary) > 1:\n",
    "        log.info(\"\\nüîç Statistical Analysis by Combinations:\")\n",
    "\n",
    "        # Find best and worst performing combinations\n",
    "        best_combo = max(\n",
    "            combination_summary.keys(),\n",
    "            key=lambda x: combination_summary[x][\"mean\"],\n",
    "        )\n",
    "        worst_combo = min(\n",
    "            combination_summary.keys(),\n",
    "            key=lambda x: combination_summary[x][\"mean\"],\n",
    "        )\n",
    "\n",
    "        log.info(\n",
    "            \"   üöÄ Best average throughput: %s LE + %s GPUs + %s BS (%.2f tokens/s)\",\n",
    "            best_combo[0],\n",
    "            best_combo[1],\n",
    "            best_combo[2],\n",
    "            combination_summary[best_combo][\"mean\"],\n",
    "        )\n",
    "        log.info(\n",
    "            \"   Worst average throughput: %s LE + %s GPUs + %s BS (%.2f tokens/s)\",\n",
    "            worst_combo[0],\n",
    "            worst_combo[1],\n",
    "            worst_combo[2],\n",
    "            combination_summary[worst_combo][\"mean\"],\n",
    "        )\n",
    "\n",
    "        # Performance difference\n",
    "        perf_diff = (\n",
    "            combination_summary[best_combo][\"mean\"]\n",
    "            - combination_summary[worst_combo][\"mean\"]\n",
    "        )\n",
    "        perf_ratio = (\n",
    "            combination_summary[best_combo][\"mean\"]\n",
    "            / combination_summary[worst_combo][\"mean\"]\n",
    "        )\n",
    "        log.info(\n",
    "            \"   üìà Performance difference: %.2f tokens/s (%.2f x speedup)\",\n",
    "            perf_diff,\n",
    "            perf_ratio,\n",
    "        )\n",
    "\n",
    "        # Most stable combination\n",
    "        if cv_by_combination:\n",
    "            most_stable_combo = min(\n",
    "                cv_by_combination.keys(),\n",
    "                key=lambda x: np.mean(cv_by_combination[x]),\n",
    "            )\n",
    "            log.info(\n",
    "                \"   üìä Most stable: %s LE + %s GPUs + %s BS (CV: %.4f)\",\n",
    "                most_stable_combo[0],\n",
    "                most_stable_combo[1],\n",
    "                most_stable_combo[2],\n",
    "                np.mean(cv_by_combination[most_stable_combo]),\n",
    "            )\n",
    "\n",
    "    # Print symbol and linestyle legend for better understanding\n",
    "    log.info(\"\\nüé® Visual Encoding Legend:\")\n",
    "    log.info(\"   Colors: Unique for each (LE, GPU, BatchSize) combination\")\n",
    "    log.info(\"   Symbols by Local Batch Size:\")\n",
    "    for bs in sorted(unique_batch_sizes):\n",
    "        symbol = batch_size_symbol_dict[bs]\n",
    "        log.info(\"     Batch Size %s: %s\", bs, symbol)\n",
    "    log.info(\"   Line Styles by GPU Count:\")\n",
    "    for gpu in sorted(unique_gpu_counts):\n",
    "        style = gpu_linestyle_dict[gpu]\n",
    "        log.info(\"     %s GPUs: %s\", gpu, style)\n",
    "\n",
    "    log.info(\"‚úÖ Enhanced throughput analysis by LE+GPU+BS combinations completed!\")\n",
    "\n",
    "else:\n",
    "    log.info(\"‚ùå No results available for throughput analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52331177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a visual legend for the enhanced color/symbol encoding\n",
    "log.info(\"Creating visual legend for the enhanced encoding scheme...\")\n",
    "\n",
    "if len(this_cell_results_list) > 0:\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    # Create legend for symbols (batch sizes)\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Symbol Legend: Local Batch Size\", fontsize=14, fontweight=\"bold\", pad=20)\n",
    "\n",
    "    for i, bs in enumerate(sorted(unique_batch_sizes)):\n",
    "        symbol = batch_size_symbol_dict[bs]\n",
    "        plt.scatter(\n",
    "            0,\n",
    "            i,\n",
    "            marker=symbol,\n",
    "            s=200,\n",
    "            c=\"black\",\n",
    "            edgecolors=\"gray\",\n",
    "            linewidth=2,\n",
    "        )\n",
    "        plt.text(\n",
    "            0.5,\n",
    "            i,\n",
    "            f\"Batch Size {bs}\",\n",
    "            va=\"center\",\n",
    "            fontsize=12,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "    plt.xlim(-0.5, 2)\n",
    "    plt.ylim(-0.5, len(unique_batch_sizes) - 0.5)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Create legend for linestyles (GPU counts)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"Line Style Legend: GPU Count\", fontsize=14, fontweight=\"bold\", pad=20)\n",
    "\n",
    "    for i, gpu in enumerate(sorted(unique_gpu_counts)):\n",
    "        style = gpu_linestyle_dict[gpu]\n",
    "        x = np.linspace(0, 1, 10)\n",
    "        y = np.full_like(x, i)\n",
    "        plt.plot(x, y, linestyle=style, linewidth=3, color=\"black\")\n",
    "        plt.text(1.2, i, f\"{gpu} GPUs\", va=\"center\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "    plt.xlim(-0.1, 2)\n",
    "    plt.ylim(-0.5, len(unique_gpu_counts) - 0.5)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Create legend for colors (full combinations)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"Color Legend: Full Combinations\", fontsize=14, fontweight=\"bold\", pad=20)\n",
    "\n",
    "    for i, combo in enumerate(sorted(unique_combinations)):\n",
    "        color = combination_color_dict[combo]\n",
    "        le, gpu, bs = combo\n",
    "        symbol = batch_size_symbol_dict[bs]\n",
    "        linestyle = gpu_linestyle_dict[gpu]\n",
    "\n",
    "        # Draw a line with the appropriate style and color\n",
    "        x = np.linspace(0, 0.8, 10)\n",
    "        y = np.full_like(x, i)\n",
    "        plt.plot(x, y, linestyle=linestyle, linewidth=3, color=color, alpha=0.8)\n",
    "\n",
    "        # Add the symbol at the end\n",
    "        plt.scatter(\n",
    "            0.9,\n",
    "            i,\n",
    "            marker=symbol,\n",
    "            s=150,\n",
    "            c=color,\n",
    "            edgecolors=\"black\",\n",
    "            linewidth=1.5,\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "        # Add text description\n",
    "        plt.text(\n",
    "            1.1,\n",
    "            i,\n",
    "            f\"LE:{le}, GPU:{gpu}, BS:{bs}\",\n",
    "            va=\"center\",\n",
    "            fontsize=11,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "    plt.xlim(-0.1, 3.5)\n",
    "    plt.ylim(-0.5, len(unique_combinations) - 0.5)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(\n",
    "        \"Visual Encoding Legend for Enhanced Throughput Analysis\\nColor + Symbol + Line\"\n",
    "        \" Style = Unique (Local Experts, GPU Count, Batch Size) Combination\",\n",
    "        fontsize=16,\n",
    "        fontweight=\"bold\",\n",
    "        y=0.95,\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Summary of encoding scheme\n",
    "    log.info(\"\\nüé® Enhanced Visual Encoding Summary:\")\n",
    "    log.info(\n",
    "        \"   üìä Each unique combination of (Local Experts, GPU Count, Local Batch Size)\"\n",
    "        \" gets:\",\n",
    "    )\n",
    "    log.info(\"      ‚Ä¢ Unique COLOR for the combination\")\n",
    "    log.info(\"      ‚Ä¢ SYMBOL based on Local Batch Size\")\n",
    "    log.info(\"      ‚Ä¢ LINE STYLE based on GPU Count\")\n",
    "    log.info(\n",
    "        \"   üìà This allows distinguishing between %s different configurations\",\n",
    "        len(unique_combinations),\n",
    "    )\n",
    "    log.info(\"   üîç Incomplete runs (< 1B tokens) use dashed lines and 'x' markers\")\n",
    "\n",
    "else:\n",
    "    log.info(\"‚ùå No data available for legend creation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74586ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Expert Density Analysis - Device Throughput vs Steps Analysis\n",
    "log.info(\"Generating Device Throughput vs Steps Analysis w/ focus on Local Experts...\")\n",
    "\n",
    "this_cell_results_list = results_list\n",
    "if EXCLUDE_INCOMPLETE_RUNS:\n",
    "    this_cell_results_list = complete_runs\n",
    "\n",
    "if len(this_cell_results_list) > 0:\n",
    "    # Quick token count check before plotting\n",
    "    billion_tokens = 1e9\n",
    "    incomplete_runs = [\n",
    "        r for r in this_cell_results_list if r[\"total_tokens\"] < billion_tokens\n",
    "    ]\n",
    "\n",
    "    if incomplete_runs:\n",
    "        log.warning(\n",
    "            \"\\n ATTENTION: %s of %s runs didn't reach 1B tokens!\",\n",
    "            len(incomplete_runs),\n",
    "            len(this_cell_results_list),\n",
    "        )\n",
    "        log.info(\"   This may affect device throughput analysis.\\n\")\n",
    "\n",
    "    # Set up enhanced plotting style with consistent colors\n",
    "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "\n",
    "    # Create color mapping\n",
    "    unique_local_experts = sorted(\n",
    "        {r[\"n_local_experts\"] for r in this_cell_results_list},\n",
    "    )\n",
    "    unique_n_gpus = sorted(\n",
    "        {\n",
    "            r[\"n_total_clients\"] for r in this_cell_results_list\n",
    "        },  # assuming n_total_clients represents GPUs\n",
    "    )\n",
    "    unique_local_batch_size = sorted(\n",
    "        {r[\"local_train_batch_size\"] for r in this_cell_results_list},\n",
    "    )\n",
    "\n",
    "    # Create all unique combinations of (local_experts, n_gpus, local_batch_size)\n",
    "    unique_combinations = sorted(\n",
    "        {\n",
    "            (r[\"n_local_experts\"], r[\"n_total_clients\"], r[\"local_train_batch_size\"])\n",
    "            for r in this_cell_results_list\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Generate enough distinct colors for all combinations\n",
    "    n_combinations = len(unique_combinations)\n",
    "    # Use a combination of different colormaps to get more distinct colors\n",
    "    if n_combinations <= 20:\n",
    "        color_map = plt.cm.tab20(  # pyright: ignore[reportAttributeAccessIssue]\n",
    "            np.linspace(0, 1, n_combinations),\n",
    "        )\n",
    "    else:\n",
    "        # For more combinations, use multiple colormaps\n",
    "        colors1 = plt.cm.tab20(\n",
    "            np.linspace(0, 1, 20),\n",
    "        )  # pyright: ignore[reportAttributeAccessIssue]\n",
    "        colors2 = plt.cm.Set3(\n",
    "            np.linspace(0, 1, n_combinations - 20),\n",
    "        )  # pyright: ignore[reportAttributeAccessIssue]\n",
    "        color_map = np.vstack([colors1, colors2])\n",
    "\n",
    "    # Create color dictionary for (local_experts, n_gpus, local_batch_size) combinations\n",
    "    combination_color_dict = {\n",
    "        combo: color_map[i] for i, combo in enumerate(unique_combinations)\n",
    "    }\n",
    "\n",
    "    # Create symbol mapping based on local batch size\n",
    "    unique_batch_sizes = sorted(unique_local_batch_size)\n",
    "    batch_size_symbols = [\n",
    "        \"o\",\n",
    "        \"s\",\n",
    "        \"^\",\n",
    "        \"D\",\n",
    "        \"v\",\n",
    "        \"<\",\n",
    "        \">\",\n",
    "        \"p\",\n",
    "        \"*\",\n",
    "        \"h\",\n",
    "        \"H\",\n",
    "        \"+\",\n",
    "        \"x\",\n",
    "    ]\n",
    "    batch_size_symbol_dict = {\n",
    "        bs: batch_size_symbols[i % len(batch_size_symbols)]\n",
    "        for i, bs in enumerate(unique_batch_sizes)\n",
    "    }\n",
    "\n",
    "    # Create linestyle mapping based on number of GPUs\n",
    "    unique_gpu_counts = sorted(unique_n_gpus)\n",
    "    gpu_linestyles = [\"-\", \"--\", \"-.\", \":\"]\n",
    "    gpu_linestyle_dict = {\n",
    "        gpu: gpu_linestyles[i % len(gpu_linestyles)]\n",
    "        for i, gpu in enumerate(unique_gpu_counts)\n",
    "    }\n",
    "\n",
    "    # Also keep the old local experts only color dict for backward compatibility\n",
    "    local_experts_color_dict = {}\n",
    "    for i, le in enumerate(unique_local_experts):\n",
    "        base_idx = i * len(unique_n_gpus) // len(unique_local_experts)\n",
    "        local_experts_color_dict[le] = color_map[base_idx % n_combinations]\n",
    "\n",
    "    log.info(\n",
    "        \"Found %s unique local expert configurations: %s\",\n",
    "        len(unique_local_experts),\n",
    "        unique_local_experts,\n",
    "    )\n",
    "    log.info(\n",
    "        \"Found %s unique GPU configurations: %s\",\n",
    "        len(unique_n_gpus),\n",
    "        unique_n_gpus,\n",
    "    )\n",
    "    log.info(\n",
    "        \"Found %s unique local batch size configurations: %s\",\n",
    "        len(unique_local_batch_size),\n",
    "        unique_local_batch_size,\n",
    "    )\n",
    "    log.info(\n",
    "        \"Found %s unique (local_experts, n_gpus, local_batch_size) combinations: %s\",\n",
    "        len(unique_combinations),\n",
    "        unique_combinations,\n",
    "    )\n",
    "\n",
    "    # ==== PLOT 6: Enhanced Device Throughput Analysis  ====\n",
    "    plt.figure(figsize=(20, 15))\n",
    "\n",
    "    # Subplot 1: Raw device throughput over training steps (colored by all three\n",
    "    # dimensions)\n",
    "    plt.subplot(2, 3, 1)\n",
    "    for result in this_cell_results_list:\n",
    "        steps = np.array(result[\"steps\"])\n",
    "        device_throughput = np.array(result[\"device_throughput\"])\n",
    "\n",
    "        if len(steps) > 0 and len(device_throughput) > 0:\n",
    "            # Color based on combination of local experts, GPUs, and local batch size\n",
    "            combo_key = (\n",
    "                result[\"n_local_experts\"],\n",
    "                result[\"n_total_clients\"],\n",
    "                result[\"local_train_batch_size\"],\n",
    "            )\n",
    "            color = combination_color_dict[combo_key]\n",
    "\n",
    "            # Symbol based on local batch size\n",
    "            marker = batch_size_symbol_dict[result[\"local_train_batch_size\"]]\n",
    "\n",
    "            # Line style based on GPU count\n",
    "            linestyle_base = gpu_linestyle_dict[result[\"n_total_clients\"]]\n",
    "\n",
    "            # Enhanced legend label with key information including all dimensions\n",
    "            incomplete_indicator = (\n",
    "                \" ‚ö†Ô∏è\" if result[\"total_tokens\"] < billion_tokens else \"\"\n",
    "            )\n",
    "            legend_label = (\n",
    "                f\"LE: {result['n_local_experts']}, \"\n",
    "                f\"GPUs: {result['n_total_clients']}, \"\n",
    "                f\"TE: {result['n_total_experts']}, \"\n",
    "                f\"OF: {result['overlapping_factor']:.1f}, \"\n",
    "                f\"LocalBS: {result['local_train_batch_size']}, \"\n",
    "                f\"mBS: {result['microbatch_size']}, \"\n",
    "                f\"{incomplete_indicator}\"\n",
    "            )\n",
    "\n",
    "            # Use different line style for incomplete runs\n",
    "            linestyle = (\n",
    "                \"--\" if result[\"total_tokens\"] < billion_tokens else linestyle_base\n",
    "            )\n",
    "            alpha = 0.7 if result[\"total_tokens\"] < billion_tokens else 0.9\n",
    "            linewidth = 2.0 if result[\"total_tokens\"] < billion_tokens else 2.5\n",
    "\n",
    "            plt.plot(\n",
    "                steps,\n",
    "                device_throughput,\n",
    "                label=legend_label,\n",
    "                linewidth=linewidth,\n",
    "                alpha=alpha,\n",
    "                color=color,\n",
    "                linestyle=linestyle,\n",
    "                marker=marker,\n",
    "                markersize=4,\n",
    "                markevery=max(1, len(steps) // 20),\n",
    "                markerfacecolor=\"white\",\n",
    "                markeredgewidth=1.2,\n",
    "                markeredgecolor=color,\n",
    "            )\n",
    "\n",
    "    plt.xlabel(\"Training Steps\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.ylabel(\"Device Throughput (tokens/s)\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.title(\n",
    "        \"Device Throughput vs Training Steps\\n\"\n",
    "        \"Grouped by Local Experts + GPU Count + Local Batch Size\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "        pad=15,\n",
    "    )\n",
    "    plt.legend(\n",
    "        frameon=True,\n",
    "        fancybox=True,\n",
    "        shadow=True,\n",
    "        ncol=1,\n",
    "        fontsize=8,\n",
    "        loc=\"best\",\n",
    "    )\n",
    "    plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5)\n",
    "\n",
    "    # Calculate statistics by combination of local experts, GPUs, and local batch size\n",
    "    device_combination_stats = {}\n",
    "    for result in this_cell_results_list:\n",
    "        combo = (\n",
    "            result[\"n_local_experts\"],\n",
    "            result[\"n_total_clients\"],\n",
    "            result[\"local_train_batch_size\"],\n",
    "        )\n",
    "        device_throughput = np.array(result[\"device_throughput\"])\n",
    "        if len(device_throughput) > 0:\n",
    "            avg_device_throughput = np.mean(device_throughput)\n",
    "            if combo not in device_combination_stats:\n",
    "                device_combination_stats[combo] = []\n",
    "            device_combination_stats[combo].append(avg_device_throughput)\n",
    "\n",
    "    # Calculate mean and std for each combination\n",
    "    device_combination_summary = {}\n",
    "    for combo, device_throughputs in device_combination_stats.items():\n",
    "        device_combination_summary[combo] = {\n",
    "            \"mean\": np.mean(device_throughputs),\n",
    "            \"std\": np.std(device_throughputs),\n",
    "            \"count\": len(device_throughputs),\n",
    "            \"values\": device_throughputs,\n",
    "        }\n",
    "\n",
    "    # Also calculate statistics by local experts only for compatibility\n",
    "    device_throughput_stats = {}\n",
    "    for result in this_cell_results_list:\n",
    "        le = result[\"n_local_experts\"]\n",
    "        device_throughput = np.array(result[\"device_throughput\"])\n",
    "        if len(device_throughput) > 0:\n",
    "            avg_device_throughput = np.mean(device_throughput)\n",
    "            if le not in device_throughput_stats:\n",
    "                device_throughput_stats[le] = []\n",
    "            device_throughput_stats[le].append(avg_device_throughput)\n",
    "\n",
    "    # Calculate mean and std for each local expert configuration\n",
    "    local_experts_summary = {}\n",
    "    for le, device_throughputs in device_throughput_stats.items():\n",
    "        local_experts_summary[le] = {\n",
    "            \"mean\": np.mean(device_throughputs),\n",
    "            \"std\": np.std(device_throughputs),\n",
    "            \"count\": len(device_throughputs),\n",
    "            \"values\": device_throughputs,\n",
    "        }\n",
    "\n",
    "    # Subplot 2: Average device throughput by combination with error bars\n",
    "    plt.subplot(2, 3, 2)\n",
    "    combination_list = sorted(device_combination_summary.keys())\n",
    "    means = [device_combination_summary[combo][\"mean\"] for combo in combination_list]\n",
    "    stds = [device_combination_summary[combo][\"std\"] for combo in combination_list]\n",
    "    colors = [combination_color_dict[combo] for combo in combination_list]\n",
    "\n",
    "    # Create x-axis labels showing LE + GPU + Local Batch Size info\n",
    "    x_labels = [\n",
    "        f\"LE:{combo[0]}\\nGPU:{combo[1]}\\nBS:{combo[2]}\" for combo in combination_list\n",
    "    ]\n",
    "    x_positions = range(len(combination_list))\n",
    "\n",
    "    bars = plt.bar(\n",
    "        x_positions,\n",
    "        means,\n",
    "        yerr=stds,\n",
    "        color=colors,\n",
    "        alpha=0.8,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=1.2,\n",
    "        capsize=5,\n",
    "        error_kw={\"linewidth\": 2, \"ecolor\": \"black\"},\n",
    "    )\n",
    "\n",
    "    # Add value labels on bars\n",
    "    for i, (combo, mean, std) in enumerate(\n",
    "        zip(combination_list, means, stds, strict=True),\n",
    "    ):\n",
    "        count = device_combination_summary[combo][\"count\"]\n",
    "        plt.text(\n",
    "            i,\n",
    "            mean + std + max(means) * 0.02,\n",
    "            f\"{mean:.1f}¬±{std:.1f}\\n(n={count})\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontweight=\"bold\",\n",
    "            fontsize=8,\n",
    "        )\n",
    "\n",
    "    plt.xticks(x_positions, x_labels, fontsize=9, rotation=45)\n",
    "    plt.xlabel(\"Local Experts + GPU Count + Batch Size\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.ylabel(\"Average Device Throughput (tokens/s)\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.title(\n",
    "        \"Average Device Throughput by LE+GPU+BS Combination\\n\"\n",
    "        \"Error bars show ¬±1 standard deviation\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "        pad=15,\n",
    "    )\n",
    "    plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5, axis=\"y\")\n",
    "\n",
    "    # Subplot 3: Detailed scatter plot with individual runs\n",
    "    plt.subplot(2, 3, 3)\n",
    "    for result in this_cell_results_list:\n",
    "        device_throughput = np.array(result[\"device_throughput\"])\n",
    "        if len(device_throughput) > 0:\n",
    "            avg_device_throughput = np.mean(device_throughput)\n",
    "            combo_key = (\n",
    "                result[\"n_local_experts\"],\n",
    "                result[\"n_total_clients\"],\n",
    "                result[\"local_train_batch_size\"],\n",
    "            )\n",
    "            color = combination_color_dict[combo_key]\n",
    "\n",
    "            # Symbol based on local batch size\n",
    "            marker = batch_size_symbol_dict[result[\"local_train_batch_size\"]]\n",
    "\n",
    "            marker_incomplete = (\n",
    "                \"x\" if result[\"total_tokens\"] < billion_tokens else marker\n",
    "            )\n",
    "            alpha = 0.8 if result[\"total_tokens\"] >= billion_tokens else 0.6\n",
    "            edge_color = (\n",
    "                \"darkred\" if result[\"total_tokens\"] < billion_tokens else \"black\"\n",
    "            )\n",
    "            edge_width = 2.5 if result[\"total_tokens\"] < billion_tokens else 1.5\n",
    "\n",
    "            # Use local experts for x-axis but color by full combination\n",
    "            # Add slight offsets based on GPU count and batch size for better separation\n",
    "            gpu_offset = (result[\"n_total_clients\"] - min(unique_n_gpus)) * 0.05\n",
    "            bs_offset = (\n",
    "                unique_batch_sizes.index(result[\"local_train_batch_size\"])\n",
    "            ) * 0.03\n",
    "            x_pos = result[\"n_local_experts\"] + gpu_offset + bs_offset\n",
    "\n",
    "            plt.scatter(\n",
    "                x_pos,\n",
    "                avg_device_throughput,\n",
    "                c=[color],\n",
    "                s=120,\n",
    "                alpha=alpha,\n",
    "                edgecolors=edge_color,\n",
    "                linewidth=edge_width,\n",
    "                marker=marker_incomplete,\n",
    "                label=(\n",
    "                    (\n",
    "                        f\"LE:{result['n_local_experts']},\"\n",
    "                        f\" GPU:{result['n_total_clients']},\"\n",
    "                        f\" BS:{result['local_train_batch_size']}\"\n",
    "                    )\n",
    "                    if result == this_cell_results_list[0]\n",
    "                    else \"\"\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    plt.xlabel(\"Number of Local Experts\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.ylabel(\"Average Device Throughput (tokens/s)\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.title(\n",
    "        \"Individual Run Device Throughput\\nGrouped by LE+GPU+BS Combinations\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "        pad=15,\n",
    "    )\n",
    "    plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5)\n",
    "\n",
    "    # Add jitter to x-axis for better visibility\n",
    "    plt.xlim(min(unique_local_experts) - 0.5, max(unique_local_experts) + 0.5)\n",
    "\n",
    "    # Subplot 4: Box plot showing distribution by local experts (keeping original)\n",
    "    plt.subplot(2, 3, 4)\n",
    "    device_throughput_by_le = [\n",
    "        local_experts_summary[le][\"values\"]\n",
    "        for le in sorted(local_experts_summary.keys())\n",
    "    ]\n",
    "\n",
    "    bp = plt.boxplot(\n",
    "        device_throughput_by_le,\n",
    "        tick_labels=[str(le) for le in sorted(local_experts_summary.keys())],\n",
    "        patch_artist=True,\n",
    "        notch=True,\n",
    "        showmeans=True,\n",
    "    )\n",
    "\n",
    "    # Color the boxes according to local experts\n",
    "    local_experts_list = sorted(local_experts_summary.keys())\n",
    "    colors_le = [local_experts_color_dict[le] for le in local_experts_list]\n",
    "    for patch, color in zip(bp[\"boxes\"], colors_le, strict=True):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.7)\n",
    "\n",
    "    plt.xlabel(\"Number of Local Experts\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.ylabel(\"Average Device Throughput (tokens/s)\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.title(\n",
    "        (\n",
    "            \"Device Throughput Distribution by Local Experts\\n\"\n",
    "            \"Box plots with mean (triangle) and median (line)\"\n",
    "        ),\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "        pad=15,\n",
    "    )\n",
    "    plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5, axis=\"y\")\n",
    "\n",
    "    # Subplot 5: Device throughput coefficient of variation by combination\n",
    "    plt.subplot(2, 3, 5)\n",
    "    device_cv_by_combination = {}\n",
    "    for result in this_cell_results_list:\n",
    "        combo = (\n",
    "            result[\"n_local_experts\"],\n",
    "            result[\"n_total_clients\"],\n",
    "            result[\"local_train_batch_size\"],\n",
    "        )\n",
    "        device_throughput = np.array(result[\"device_throughput\"])\n",
    "        if len(device_throughput) > 1:\n",
    "            cv = (\n",
    "                np.std(device_throughput) / np.mean(device_throughput)\n",
    "                if np.mean(device_throughput) > 0\n",
    "                else 0\n",
    "            )\n",
    "            if combo not in device_cv_by_combination:\n",
    "                device_cv_by_combination[combo] = []\n",
    "            device_cv_by_combination[combo].append(cv)\n",
    "\n",
    "    if device_cv_by_combination:\n",
    "        combo_list = sorted(device_cv_by_combination.keys())\n",
    "        cv_means = [np.mean(device_cv_by_combination[combo]) for combo in combo_list]\n",
    "        cv_stds = [\n",
    "            (\n",
    "                np.std(device_cv_by_combination[combo])\n",
    "                if len(device_cv_by_combination[combo]) > 1\n",
    "                else 0\n",
    "            )\n",
    "            for combo in combo_list\n",
    "        ]\n",
    "        colors_cv = [combination_color_dict[combo] for combo in combo_list]\n",
    "        x_labels_cv = [\n",
    "            f\"LE:{combo[0]}\\nGPU:{combo[1]}\\nBS:{combo[2]}\" for combo in combo_list\n",
    "        ]\n",
    "        x_positions_cv = range(len(combo_list))\n",
    "\n",
    "        bars = plt.bar(\n",
    "            x_positions_cv,\n",
    "            cv_means,\n",
    "            yerr=cv_stds,\n",
    "            color=colors_cv,\n",
    "            alpha=0.8,\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=1.2,\n",
    "            capsize=5,\n",
    "            error_kw={\"linewidth\": 2, \"ecolor\": \"black\"},\n",
    "        )\n",
    "\n",
    "        # Add value labels\n",
    "        for i, (combo, mean, std) in enumerate(\n",
    "            zip(combo_list, cv_means, cv_stds, strict=True),\n",
    "        ):\n",
    "            count = len(device_cv_by_combination[combo])\n",
    "            plt.text(\n",
    "                i,\n",
    "                mean + std + max(cv_means) * 0.02,\n",
    "                f\"{mean:.3f}¬±{std:.3f}\\n(n={count})\",\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "                fontweight=\"bold\",\n",
    "                fontsize=8,\n",
    "            )\n",
    "\n",
    "        plt.xticks(x_positions_cv, x_labels_cv, fontsize=9, rotation=45)\n",
    "        plt.xlabel(\n",
    "            \"Local Experts + GPU Count + Batch Size\",\n",
    "            fontsize=12,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "        plt.ylabel(\n",
    "            \"Device Throughput Coefficient of Variation\",\n",
    "            fontsize=12,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "        plt.title(\n",
    "            (\n",
    "                \"Device Throughput Stability by LE+GPU+BS Combination\\n\"\n",
    "                \"(Lower CV = More Stable)\"\n",
    "            ),\n",
    "            fontsize=14,\n",
    "            fontweight=\"bold\",\n",
    "            pad=15,\n",
    "        )\n",
    "        plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5, axis=\"y\")\n",
    "\n",
    "    # Subplot 6: Summary statistics table for combinations\n",
    "    plt.subplot(2, 3, 6)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Create summary table for combinations\n",
    "    table_data = []\n",
    "    headers = [\n",
    "        \"Local\\nExperts\",\n",
    "        \"GPUs\",\n",
    "        \"Batch\\nSize\",\n",
    "        \"Count\",\n",
    "        \"Mean\\nDevice Throughput\",\n",
    "        \"Std Dev\",\n",
    "        \"CV Mean\",\n",
    "    ]\n",
    "\n",
    "    for combo in sorted(device_combination_summary.keys()):\n",
    "        stats = device_combination_summary[combo]\n",
    "        cv_stats = device_cv_by_combination.get(combo, [0])\n",
    "        table_data.append(\n",
    "            [\n",
    "                str(combo[0]),\n",
    "                str(combo[1]),\n",
    "                str(combo[2]),\n",
    "                str(stats[\"count\"]),\n",
    "                f\"{stats['mean']:.1f}\",\n",
    "                f\"{stats['std']:.1f}\",\n",
    "                f\"{np.mean(cv_stats):.3f}\" if cv_stats else \"N/A\",\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    # Create table\n",
    "    table = plt.table(\n",
    "        cellText=table_data,\n",
    "        colLabels=headers,\n",
    "        cellLoc=\"center\",\n",
    "        loc=\"center\",\n",
    "        bbox=[0, 0.2, 1, 0.8],\n",
    "    )\n",
    "    table.auto_set_font_size(value=False)\n",
    "    table.set_fontsize(8)\n",
    "    table.scale(1, 1.5)\n",
    "\n",
    "    # Color the rows according to combinations\n",
    "    for i, combo in enumerate(sorted(device_combination_summary.keys())):\n",
    "        color = combination_color_dict[combo]\n",
    "        for j in range(len(headers)):\n",
    "            table[i + 1, j].set_facecolor(color)\n",
    "            table[i + 1, j].set_alpha(0.3)\n",
    "\n",
    "    plt.title(\n",
    "        \"Device Throughput Summary Statistics\\nby LE+GPU+BS Combinations\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "        pad=20,\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Generate enhanced device throughput analysis summary focused on combinations\n",
    "    log.info(\"\\n=== Device Throughput Analysis Summary by LE+GPU+BS Combinations ===\")\n",
    "\n",
    "    for combo in sorted(device_combination_summary.keys()):\n",
    "        stats = device_combination_summary[combo]\n",
    "        cv_stats = device_cv_by_combination.get(combo, [])\n",
    "\n",
    "        log.info(\n",
    "            \"\\nüìä %s Local Experts + %s GPUs + %s Batch Size:\",\n",
    "            combo[0],\n",
    "            combo[1],\n",
    "            combo[2],\n",
    "        )\n",
    "        log.info(\"   Number of runs: %s\", stats[\"count\"])\n",
    "        log.info(\n",
    "            \"   Average device throughput: %.2f ¬± %.2f tokens/s\",\n",
    "            stats[\"mean\"],\n",
    "            stats[\"std\"],\n",
    "        )\n",
    "        log.info(\n",
    "            \"   Range: %.2f - %.2f tokens/s\",\n",
    "            min(stats[\"values\"]),\n",
    "            max(stats[\"values\"]),\n",
    "        )\n",
    "        if cv_stats:\n",
    "            log.info(\n",
    "                \"   Stability (CV): %.4f ¬± %.4f\",\n",
    "                np.mean(cv_stats),\n",
    "                np.std(cv_stats),\n",
    "            )\n",
    "\n",
    "        # Show individual run details\n",
    "        log.info(\"   Individual runs:\")\n",
    "        for result in this_cell_results_list:\n",
    "            if (\n",
    "                result[\"n_local_experts\"],\n",
    "                result[\"n_total_clients\"],\n",
    "                result[\"local_train_batch_size\"],\n",
    "            ) == combo:\n",
    "                device_throughput = np.array(result[\"device_throughput\"])\n",
    "                if len(device_throughput) > 0:\n",
    "                    avg_tp = np.mean(device_throughput)\n",
    "                    incomplete_mark = (\n",
    "                        \"‚ö†Ô∏è\" if result[\"total_tokens\"] < billion_tokens else \"‚úÖ\"\n",
    "                    )\n",
    "                    log.info(\n",
    "                        \"     %s %s...: %.2f tokens/s (TE:%s, OF:%.1f)\",\n",
    "                        incomplete_mark,\n",
    "                        result[\"run_uuid\"][:12],\n",
    "                        avg_tp,\n",
    "                        result[\"n_total_experts\"],\n",
    "                        result[\"overlapping_factor\"],\n",
    "                    )\n",
    "\n",
    "    # Statistical analysis for combinations\n",
    "    if len(device_combination_summary) > 1:\n",
    "        log.info(\"\\nüîç Statistical Analysis by Combinations:\")\n",
    "\n",
    "        # Find best and worst performing combinations\n",
    "        best_combo = max(\n",
    "            device_combination_summary.keys(),\n",
    "            key=lambda x: device_combination_summary[x][\"mean\"],\n",
    "        )\n",
    "        worst_combo = min(\n",
    "            device_combination_summary.keys(),\n",
    "            key=lambda x: device_combination_summary[x][\"mean\"],\n",
    "        )\n",
    "\n",
    "        log.info(\n",
    "            \"   üöÄ Best average device throughput: %s LE + %s GPUs\"\n",
    "            \" + %s BS (%.2f tokens/s)\",\n",
    "            best_combo[0],\n",
    "            best_combo[1],\n",
    "            best_combo[2],\n",
    "            device_combination_summary[best_combo][\"mean\"],\n",
    "        )\n",
    "        log.info(\n",
    "            \"   Worst average device throughput: %s LE + %s GPUs\"\n",
    "            \" + %s BS (%.2f tokens/s)\",\n",
    "            worst_combo[0],\n",
    "            worst_combo[1],\n",
    "            worst_combo[2],\n",
    "            device_combination_summary[worst_combo][\"mean\"],\n",
    "        )\n",
    "\n",
    "        # Performance difference\n",
    "        perf_diff = (\n",
    "            device_combination_summary[best_combo][\"mean\"]\n",
    "            - device_combination_summary[worst_combo][\"mean\"]\n",
    "        )\n",
    "        perf_ratio = (\n",
    "            device_combination_summary[best_combo][\"mean\"]\n",
    "            / device_combination_summary[worst_combo][\"mean\"]\n",
    "        )\n",
    "        log.info(\n",
    "            \"   üìà Performance difference: %.2f tokens/s (%.2f x speedup)\",\n",
    "            perf_diff,\n",
    "            perf_ratio,\n",
    "        )\n",
    "\n",
    "        # Most stable combination\n",
    "        if device_cv_by_combination:\n",
    "            most_stable_combo = min(\n",
    "                device_cv_by_combination.keys(),\n",
    "                key=lambda x: np.mean(device_cv_by_combination[x]),\n",
    "            )\n",
    "            log.info(\n",
    "                \"   üìä Most stable: %s LE + %s GPUs + %s BS (CV: %.4f)\",\n",
    "                most_stable_combo[0],\n",
    "                most_stable_combo[1],\n",
    "                most_stable_combo[2],\n",
    "                np.mean(device_cv_by_combination[most_stable_combo]),\n",
    "            )\n",
    "\n",
    "    # Print symbol and linestyle legend for better understanding\n",
    "    log.info(\"\\nüé® Visual Encoding Legend:\")\n",
    "    log.info(\"   Colors: Unique for each (LE, GPU, BatchSize) combination\")\n",
    "    log.info(\"   Symbols by Local Batch Size:\")\n",
    "    for bs in sorted(unique_batch_sizes):\n",
    "        symbol = batch_size_symbol_dict[bs]\n",
    "        log.info(\"     Batch Size %s: %s\", bs, symbol)\n",
    "    log.info(\"   Line Styles by GPU Count:\")\n",
    "    for gpu in sorted(unique_gpu_counts):\n",
    "        style = gpu_linestyle_dict[gpu]\n",
    "        log.info(\"     %s GPUs: %s\", gpu, style)\n",
    "\n",
    "    log.info(\n",
    "        \"‚úÖ Enhanced device throughput analysis by LE+GPU+BS combinations completed!\",\n",
    "    )\n",
    "\n",
    "else:\n",
    "    log.info(\"‚ùå No results available for device throughput analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ae0db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a visual legend for the enhanced device throughput encoding\n",
    "log.info(\"Creating visual legend for the enhanced device throughput encoding scheme...\")\n",
    "\n",
    "if len(this_cell_results_list) > 0:\n",
    "    plt.figure(figsize=(16, 6))\n",
    "\n",
    "    # Create legend for symbols (batch sizes)\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\n",
    "        \"Symbol Legend: Local Batch Size\\n(Device Throughput)\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "        pad=20,\n",
    "    )\n",
    "\n",
    "    for i, bs in enumerate(sorted(unique_batch_sizes)):\n",
    "        symbol = batch_size_symbol_dict[bs]\n",
    "        plt.scatter(\n",
    "            0,\n",
    "            i,\n",
    "            marker=symbol,\n",
    "            s=200,\n",
    "            c=\"darkblue\",\n",
    "            edgecolors=\"gray\",\n",
    "            linewidth=2,\n",
    "        )\n",
    "        plt.text(\n",
    "            0.5,\n",
    "            i,\n",
    "            f\"Batch Size {bs}\",\n",
    "            va=\"center\",\n",
    "            fontsize=12,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "    plt.xlim(-0.5, 2)\n",
    "    plt.ylim(-0.5, len(unique_batch_sizes) - 0.5)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Create legend for linestyles (GPU counts)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\n",
    "        \"Line Style Legend: GPU Count\\n(Device Throughput)\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "        pad=20,\n",
    "    )\n",
    "\n",
    "    for i, gpu in enumerate(sorted(unique_gpu_counts)):\n",
    "        style = gpu_linestyle_dict[gpu]\n",
    "        x = np.linspace(0, 1, 10)\n",
    "        y = np.full_like(x, i)\n",
    "        plt.plot(x, y, linestyle=style, linewidth=3, color=\"darkblue\")\n",
    "        plt.text(1.2, i, f\"{gpu} GPUs\", va=\"center\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "    plt.xlim(-0.1, 2)\n",
    "    plt.ylim(-0.5, len(unique_gpu_counts) - 0.5)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Create legend for colors (full combinations)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\n",
    "        \"Color Legend: Full Combinations\\n(Device Throughput)\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "        pad=20,\n",
    "    )\n",
    "\n",
    "    for i, combo in enumerate(sorted(unique_combinations)):\n",
    "        color = combination_color_dict[combo]\n",
    "        le, gpu, bs = combo\n",
    "        symbol = batch_size_symbol_dict[bs]\n",
    "        linestyle = gpu_linestyle_dict[gpu]\n",
    "\n",
    "        # Draw a line with the appropriate style and color\n",
    "        x = np.linspace(0, 0.8, 10)\n",
    "        y = np.full_like(x, i)\n",
    "        plt.plot(x, y, linestyle=linestyle, linewidth=3, color=color, alpha=0.8)\n",
    "\n",
    "        # Add the symbol at the end\n",
    "        plt.scatter(\n",
    "            0.9,\n",
    "            i,\n",
    "            marker=symbol,\n",
    "            s=150,\n",
    "            color=color,\n",
    "            edgecolors=\"black\",\n",
    "            linewidth=1.5,\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "        # Add text description\n",
    "        plt.text(\n",
    "            1.1,\n",
    "            i,\n",
    "            f\"LE:{le}, GPU:{gpu}, BS:{bs}\",\n",
    "            va=\"center\",\n",
    "            fontsize=11,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "    plt.xlim(-0.1, 3.5)\n",
    "    plt.ylim(-0.5, len(unique_combinations) - 0.5)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(\n",
    "        \"Visual Encoding Legend for Enhanced Device Throughput Analysis\\nColor + Symbol\"\n",
    "        \" + Line Style = Unique (Local Experts, GPU Count, Batch Size) Combination\",\n",
    "        fontsize=16,\n",
    "        fontweight=\"bold\",\n",
    "        y=0.95,\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Summary of encoding scheme for device throughput\n",
    "    log.info(\"\\nüé® Enhanced Device Throughput Visual Encoding Summary:\")\n",
    "    log.info(\n",
    "        \"   üìä Each unique combination of (Local Experts, GPU Count, Local Batch Size)\"\n",
    "        \" gets:\",\n",
    "    )\n",
    "    log.info(\"      ‚Ä¢ Unique COLOR for the combination\")\n",
    "    log.info(\"      ‚Ä¢ SYMBOL based on Local Batch Size\")\n",
    "    log.info(\"      ‚Ä¢ LINE STYLE based on GPU Count\")\n",
    "    log.info(\n",
    "        \"   üìà This allows distinguishing between %s different configurations in device\"\n",
    "        \" throughput\",\n",
    "        len(unique_combinations),\n",
    "    )\n",
    "    log.info(\"   üîç Incomplete runs (< 1B tokens) use dashed lines and 'x' markers\")\n",
    "    log.info(\"   üìâ Device throughput = Total throughput / Number of devices\")\n",
    "\n",
    "else:\n",
    "    log.info(\"‚ùå No data available for device throughput legend creation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef8cce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_cell_results_list = results_list\n",
    "if EXCLUDE_INCOMPLETE_RUNS:\n",
    "    this_cell_results_list = complete_runs\n",
    "\n",
    "if len(this_cell_results_list) > 0:\n",
    "    log.info(\"Results summary:\")\n",
    "    log.info(\n",
    "        results_df[\n",
    "            [\n",
    "                \"run_uuid\",\n",
    "                \"n_total_clients\",\n",
    "                \"local_train_batch_size\",\n",
    "                \"n_local_experts\",\n",
    "                \"overlapping_factor\",\n",
    "                \"final_perplexity\",\n",
    "                \"total_tokens\",\n",
    "            ]\n",
    "        ].head(),\n",
    "    )\n",
    "\n",
    "    # Plot 1: Final Perplexity vs Experts Density (Local Experts)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "    scatter = plt.scatter(\n",
    "        results_df[\"n_local_experts\"],\n",
    "        results_df[\"final_perplexity\"],\n",
    "        c=results_df[\"overlapping_factor\"],\n",
    "        cmap=\"viridis\",\n",
    "        s=100,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    plt.xlabel(\"Experts Density (Local Experts per Client)\")\n",
    "    plt.ylabel(\"Final Perplexity\")\n",
    "    plt.title(\"Final Perplexity vs Experts Density\")\n",
    "    plt.colorbar(scatter, label=\"Overlapping Factor\")\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    # Plot 2: Final Perplexity vs Total Clients\n",
    "    plt.subplot(2, 2, 2)\n",
    "    scatter = plt.scatter(\n",
    "        results_df[\"n_total_clients\"],\n",
    "        results_df[\"final_perplexity\"],\n",
    "        c=results_df[\"n_local_experts\"],\n",
    "        cmap=\"plasma\",\n",
    "        s=100,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    plt.xlabel(\"Total Clients\")\n",
    "    plt.ylabel(\"Final Perplexity\")\n",
    "    plt.title(\"Final Perplexity vs Total Clients\")\n",
    "    plt.colorbar(scatter, label=\"Local Experts per Client\")\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    # Plot 3: Experts Density vs Overlapping Factor\n",
    "    plt.subplot(2, 2, 3)\n",
    "    scatter = plt.scatter(\n",
    "        results_df[\"overlapping_factor\"],\n",
    "        results_df[\"n_local_experts\"],\n",
    "        c=results_df[\"final_perplexity\"],\n",
    "        cmap=\"coolwarm\",\n",
    "        s=100,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    plt.xlabel(\"Overlapping Factor\")\n",
    "    plt.ylabel(\"Experts Density\")\n",
    "    plt.title(\"Experts Density vs Overlapping Factor\")\n",
    "    plt.colorbar(scatter, label=\"Final Perplexity\")\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    # Plot 4: Total Tokens vs Final Perplexity\n",
    "    plt.subplot(2, 2, 4)\n",
    "    scatter = plt.scatter(\n",
    "        results_df[\"total_tokens\"],\n",
    "        results_df[\"final_perplexity\"],\n",
    "        c=results_df[\"n_local_experts\"],\n",
    "        cmap=\"tab10\",\n",
    "        s=100,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    plt.xlabel(\"Total Tokens\")\n",
    "    plt.ylabel(\"Final Perplexity\")\n",
    "    plt.title(\"Total Tokens vs Final Perplexity\")\n",
    "    plt.colorbar(scatter, label=\"Experts Density\")\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    log.info(\"No results to plot. Check if data was successfully processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebe3440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot detailed perplexity curves\n",
    "\n",
    "\n",
    "this_cell_results_list = results_list\n",
    "if EXCLUDE_INCOMPLETE_RUNS:\n",
    "    this_cell_results_list = complete_runs\n",
    "\n",
    "if len(this_cell_results_list) > 0:\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # Plot 1: Perplexity vs Tokens for different expert densities\n",
    "    plt.subplot(2, 2, 1)\n",
    "    for result in this_cell_results_list:\n",
    "        if result[\"tokens\"] and result[\"perplexity\"]:\n",
    "            tokens = np.array(result[\"tokens\"])\n",
    "            perplexity = np.array(result[\"perplexity\"])\n",
    "            # Only plot non-NaN values\n",
    "            valid_mask = ~np.isnan(perplexity)\n",
    "            if np.any(valid_mask):\n",
    "                label = (\n",
    "                    f\"UUID: {result['run_uuid'][:8]}...\"\n",
    "                    f\" (LE: {result['n_local_experts']},\"\n",
    "                    f\" TC: {result['n_total_clients']},\"\n",
    "                    f\" OF: {result['overlapping_factor']})\"\n",
    "                )\n",
    "                plt.plot(\n",
    "                    tokens[valid_mask],\n",
    "                    perplexity[valid_mask],\n",
    "                    label=label,\n",
    "                    linewidth=2,\n",
    "                    alpha=0.8,\n",
    "                )\n",
    "\n",
    "    plt.xlabel(\"Total Tokens\")\n",
    "    plt.ylabel(\"Perplexity\")\n",
    "    plt.title(\"Perplexity vs Tokens by Expert Configuration\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.yscale(\"log\")\n",
    "\n",
    "    # Plot 2: Convergence comparison (normalized tokens)\n",
    "    plt.subplot(2, 2, 2)\n",
    "    for result in this_cell_results_list:\n",
    "        if result[\"tokens\"] and result[\"perplexity\"]:\n",
    "            tokens = np.array(result[\"tokens\"])\n",
    "            perplexity = np.array(result[\"perplexity\"])\n",
    "            valid_mask = ~np.isnan(perplexity)\n",
    "            if np.any(valid_mask) and len(tokens[valid_mask]) > 0:\n",
    "                # Normalize tokens to [0, 1] for comparison\n",
    "                tokens_norm = (tokens[valid_mask] - tokens[valid_mask].min()) / (\n",
    "                    tokens[valid_mask].max() - tokens[valid_mask].min() + 1e-8\n",
    "                )\n",
    "                label = (\n",
    "                    f\"LE: {result['n_local_experts']},\"\n",
    "                    f\" TC: {result['n_total_clients']},\"\n",
    "                    f\" OF: {result['overlapping_factor']}\"\n",
    "                )\n",
    "                plt.plot(\n",
    "                    tokens_norm,\n",
    "                    perplexity[valid_mask],\n",
    "                    label=label,\n",
    "                    linewidth=2,\n",
    "                    alpha=0.8,\n",
    "                )\n",
    "\n",
    "    plt.xlabel(\"Normalized Training Progress\")\n",
    "    plt.ylabel(\"Perplexity\")\n",
    "    plt.title(\"Convergence Comparison (Normalized)\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.yscale(\"log\")\n",
    "\n",
    "    # Plot 3: Final performance summary\n",
    "    plt.subplot(2, 2, 3)\n",
    "    # Group by experts density for box plot\n",
    "    expert_densities = sorted(results_df[\"n_local_experts\"].unique())\n",
    "    perplexity_by_density = [\n",
    "        results_df[results_df[\"n_local_experts\"] == ed][\"final_perplexity\"].to_numpy()\n",
    "        for ed in expert_densities\n",
    "    ]\n",
    "\n",
    "    plt.boxplot(perplexity_by_density)\n",
    "    plt.xlabel(\"Local Experts\")\n",
    "    plt.ylabel(\"Final Perplexity\")\n",
    "    plt.title(\"Final Perplexity Distribution by Local Experts\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    # Plot 4: Efficiency analysis (final perplexity vs total tokens)\n",
    "    plt.subplot(2, 2, 4)\n",
    "    for result in this_cell_results_list:\n",
    "        plt.scatter(\n",
    "            result[\"total_tokens\"],\n",
    "            result[\"final_perplexity\"],\n",
    "            s=result[\"n_local_experts\"] * 50\n",
    "            + 50,  # Size proportional to expert density\n",
    "            alpha=0.7,\n",
    "            label=(\n",
    "                f\"LE: {result['n_local_experts']},\"\n",
    "                f\" TC: {result['n_total_clients']},\"\n",
    "                f\" OF: {result['overlapping_factor']}\"\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Total Tokens\")\n",
    "    plt.ylabel(\"Final Perplexity\")\n",
    "    plt.title(\"Efficiency: Final Perplexity vs Training Cost\\n(Size ‚àù Local Experts)\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Summary statistics\n",
    "    log.info(\"\\n=== Summary Statistics ===\")\n",
    "    log.info(\"Number of configurations analyzed: %s\", len(results_df))\n",
    "    log.info(\n",
    "        \"Local experts range: %s - %s\",\n",
    "        results_df[\"n_local_experts\"].min(),\n",
    "        results_df[\"n_local_experts\"].max(),\n",
    "    )\n",
    "    log.info(\n",
    "        \"Overlapping factor range: %s - %s\",\n",
    "        results_df[\"overlapping_factor\"].min(),\n",
    "        results_df[\"overlapping_factor\"].max(),\n",
    "    )\n",
    "    log.info(\n",
    "        \"Final perplexity range: %s - %s\",\n",
    "        results_df[\"final_perplexity\"].min(),\n",
    "        results_df[\"final_perplexity\"].max(),\n",
    "    )\n",
    "    log.info(\n",
    "        \"Best performing configuration (lowest perplexity): UUID %s\",\n",
    "        results_df.loc[results_df[\"final_perplexity\"].idxmin(), \"run_uuid\"],\n",
    "    )\n",
    "    results_df[\"efficiency\"] = (\n",
    "        results_df[\"final_perplexity\"] / results_df[\"total_tokens\"]\n",
    "    )\n",
    "    log.info(\n",
    "        \"Most efficient configuration (lowest perplexity/token ratio): UUID %s\",\n",
    "        results_df.loc[results_df[\"efficiency\"].idxmin(), \"run_uuid\"],\n",
    "    )\n",
    "else:\n",
    "    log.info(\"No results available for plotting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ba0d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table and insights\n",
    "\n",
    "\n",
    "this_cell_results_list = results_list\n",
    "if EXCLUDE_INCOMPLETE_RUNS:\n",
    "    this_cell_results_list = complete_runs\n",
    "\n",
    "if len(this_cell_results_list) > 0:\n",
    "    log.info(\"=== Expert Density Analysis Summary Table ===\")\n",
    "\n",
    "    # Create a clean summary table\n",
    "    summary_columns = [\n",
    "        \"run_uuid\",\n",
    "        \"n_total_clients\",\n",
    "        \"local_train_batch_size\",\n",
    "        \"n_local_experts\",\n",
    "        \"overlapping_factor\",\n",
    "        \"n_total_experts\",\n",
    "        \"final_perplexity\",\n",
    "        \"total_tokens\",\n",
    "    ]\n",
    "\n",
    "    summary_df = results_df[summary_columns].copy()\n",
    "    summary_df[\"run_uuid_short\"] = summary_df[\"run_uuid\"].str[:12] + \"...\"\n",
    "    summary_df = summary_df.drop(\"run_uuid\", axis=1)\n",
    "\n",
    "    # Reorder columns for better readability\n",
    "    summary_df = summary_df[\n",
    "        [\n",
    "            \"run_uuid_short\",\n",
    "            \"n_total_clients\",\n",
    "            \"n_total_experts\",\n",
    "            \"n_local_experts\",\n",
    "            \"overlapping_factor\",\n",
    "            \"local_train_batch_size\",\n",
    "            \"final_perplexity\",\n",
    "            \"total_tokens\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Sort by final perplexity for easy comparison\n",
    "    summary_df = summary_df.sort_values(\"final_perplexity\")\n",
    "\n",
    "    log.info(summary_df.to_string(index=False, float_format=\"%.4f\"))\n",
    "\n",
    "    log.info(\"\\n=== Key Insights ===\")\n",
    "\n",
    "    # Best and worst performing configurations\n",
    "    best_idx = results_df[\"final_perplexity\"].idxmin()\n",
    "    worst_idx = results_df[\"final_perplexity\"].idxmax()\n",
    "\n",
    "    log.info(\"üèÜ Best Performance:\")\n",
    "    log.info(\"   UUID: %s\", results_df.loc[best_idx, \"run_uuid\"])\n",
    "    log.info(\"   Local Experts: %s\", results_df.loc[best_idx, \"n_local_experts\"])\n",
    "    log.info(\n",
    "        \"   Overlapping Factor: %s\",\n",
    "        results_df.loc[best_idx, \"overlapping_factor\"],\n",
    "    )\n",
    "    log.info(\"   Final Perplexity: %.4f\", results_df.loc[best_idx, \"final_perplexity\"])\n",
    "\n",
    "    log.info(\"\\nüìâ Worst Performance:\")\n",
    "    log.info(\"   UUID: %s\", results_df.loc[worst_idx, \"run_uuid\"])\n",
    "    log.info(\"   Local Experts: %s\", results_df.loc[worst_idx, \"n_local_experts\"])\n",
    "    log.info(\n",
    "        \"   Overlapping Factor: %s\",\n",
    "        results_df.loc[worst_idx, \"overlapping_factor\"],\n",
    "    )\n",
    "    log.info(\"   Final Perplexity: %.4f\", results_df.loc[worst_idx, \"final_perplexity\"])\n",
    "\n",
    "    # Correlation analysis\n",
    "    log.info(\"\\nüîç Correlation Analysis:\")\n",
    "    correlations = results_df[\n",
    "        [\n",
    "            \"n_local_experts\",\n",
    "            \"overlapping_factor\",\n",
    "            \"n_total_clients\",\n",
    "            \"local_train_batch_size\",\n",
    "            \"final_perplexity\",\n",
    "            \"total_tokens\",\n",
    "        ]\n",
    "    ].corr()\n",
    "\n",
    "    perplexity_corr = correlations[\"final_perplexity\"].sort_values(\n",
    "        key=abs,\n",
    "        ascending=False,\n",
    "    )\n",
    "    log.info(\"   Correlation with Final Perplexity:\")\n",
    "    for var, corr in perplexity_corr.items():\n",
    "        if var != \"final_perplexity\":\n",
    "            log.info(\"   - %s: %.3f\", var, corr)\n",
    "\n",
    "    # Efficiency analysis\n",
    "    if \"efficiency\" in results_df.columns:\n",
    "        most_efficient_idx = results_df[\"efficiency\"].idxmin()\n",
    "        log.info(\"\\n‚ö° Most Efficient Configuration:\")\n",
    "        log.info(\"   UUID: %s\", results_df.loc[most_efficient_idx, \"run_uuid\"])\n",
    "        log.info(\n",
    "            \"   Local Experts: %s\",\n",
    "            results_df.loc[most_efficient_idx, \"n_local_experts\"],\n",
    "        )\n",
    "        log.info(\n",
    "            \"   Overlapping Factor: %s\",\n",
    "            results_df.loc[most_efficient_idx, \"overlapping_factor\"],\n",
    "        )\n",
    "        log.info(\n",
    "            \"   Efficiency (Perplexity/Token): %.2e\",\n",
    "            results_df.loc[most_efficient_idx, \"efficiency\"],\n",
    "        )\n",
    "\n",
    "    # Local experts impact\n",
    "    log.info(\"\\nüìä Local Experts Impact:\")\n",
    "    experts_groups = results_df.groupby(\"n_local_experts\")[\"final_perplexity\"].agg(\n",
    "        [\"mean\", \"std\", \"count\"],\n",
    "    )\n",
    "    log.info(\"   Average Final Perplexity by Local Experts:\")\n",
    "    for n_experts, stats in experts_groups.iterrows():\n",
    "        log.info(\n",
    "            \"   - %d Local Experts: %.4f ¬± %.4f (n=%d)\",\n",
    "            n_experts,\n",
    "            stats[\"mean\"],\n",
    "            stats[\"std\"],\n",
    "            int(stats[\"count\"]),\n",
    "        )\n",
    "\n",
    "else:\n",
    "    log.info(\"No results available for summary analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232c08c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fedmoe-plots",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
