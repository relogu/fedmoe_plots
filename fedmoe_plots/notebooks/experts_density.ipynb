{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce54d73d",
   "metadata": {},
   "source": [
    "# Expert Density Analysis for Federated Mixture of Experts\n",
    "\n",
    "This notebook analyzes the impact of expert density (number of local experts per client) on model performance in federated learning scenarios with Mixture of Experts (MoE) architectures.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "1. **Data Collection**: Download metrics from WandB for different expert density configurations\n",
    "2. **Performance Analysis**: Compare perplexity vs. token consumption across configurations\n",
    "3. **Efficiency Evaluation**: Assess the trade-offs between expert density and training efficiency\n",
    "4. **Configuration Impact**: Understand how overlapping factors and client counts affect performance\n",
    "\n",
    "## Key Metrics\n",
    "\n",
    "- **Expert Density**: Number of local experts per client\n",
    "- **Overlapping Factor**: Factor determining expert sharing across clients\n",
    "- **Final Perplexity**: Model performance at the end of training\n",
    "- **Total Tokens**: Computational cost measure\n",
    "- **Efficiency**: Ratio of final perplexity to total tokens consumed\n",
    "\n",
    "## Analysis Workflow\n",
    "\n",
    "1. Load and filter runs from WandB based on run UUID patterns\n",
    "2. Extract configuration parameters for each run\n",
    "3. Download server and client metrics data\n",
    "4. Compute perplexity vs. token relationships\n",
    "5. Aggregate results by configuration parameters\n",
    "6. Generate visualizations and summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b1255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import operator\n",
    "from datetime import UTC, datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "\n",
    "from fedmoe_plots.data_analysis import (\n",
    "    ColumnNotFoundError,\n",
    "    get_device_throughput_series,\n",
    "    get_perplexity_versus_tokens,\n",
    ")\n",
    "from fedmoe_plots.plotting_utils import configure_logging_for_jupyter\n",
    "from fedmoe_plots.wandb_utils import (\n",
    "    ClientRunNotFoundError,\n",
    "    download_photon_metrics,\n",
    "    get_clientrun_property_from_config,\n",
    "    get_experts_global_batch_size,\n",
    "    get_n_local_experts,\n",
    "    get_non_experts_global_batch_size,\n",
    "    get_run_uuid_from_config,\n",
    "    remove_runs_by_regex,\n",
    ")\n",
    "\n",
    "configure_logging_for_jupyter()\n",
    "\n",
    "log = logging.getLogger(\"experts_density.ipynb\")\n",
    "\n",
    "EXCLUDE_INCOMPLETE_RUNS = True\n",
    "BASE_BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3d8662",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_uuid_1 = \"4e_rho_bspol_scratch\"\n",
    "run_uuid_2 = \"8e_rho_bspol_scratch\"\n",
    "api = wandb.Api(timeout=100)\n",
    "runs = api.runs(\n",
    "    path=\"camlsys/photon\",\n",
    "    filters={\"display_name\": {\"$regex\": f\"(^{run_uuid_1})|(^{run_uuid_2})\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0be7302",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in runs:\n",
    "    log.info(\"Run name: %s, ID: %s, State: %s\", run.name, run.id, run.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181b0f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_n_total_clients = {\n",
    "    get_clientrun_property_from_config(\n",
    "        run,\n",
    "        get_property_fn=lambda config: config[\"fl\"][\"n_total_clients\"],\n",
    "    )\n",
    "    for run in runs\n",
    "}\n",
    "unique_local_batch_size = {\n",
    "    get_clientrun_property_from_config(\n",
    "        run,\n",
    "        get_property_fn=lambda config: config[\"llm_config\"][\"global_train_batch_size\"],\n",
    "    )\n",
    "    for run in runs\n",
    "}\n",
    "unique_overlapping_factor = {\n",
    "    get_clientrun_property_from_config(\n",
    "        run,\n",
    "        get_property_fn=lambda config: config[\"fl\"][\"experts_overlapping_factor\"],\n",
    "    )\n",
    "    for run in runs\n",
    "}\n",
    "unique_n_total_experts = {\n",
    "    get_clientrun_property_from_config(\n",
    "        run,\n",
    "        get_property_fn=lambda config: config[\"llm_config\"][\"model\"][\"ffn_config\"][\n",
    "            \"ff_n_experts\"\n",
    "        ],\n",
    "    )\n",
    "    for run in runs\n",
    "}\n",
    "unique_n_local_experts = {\n",
    "    get_clientrun_property_from_config(\n",
    "        run,\n",
    "        get_property_fn=get_n_local_experts,\n",
    "    )\n",
    "    for run in runs\n",
    "}\n",
    "log.info(\n",
    "    \"Unique n_total_clients: %s, unique_local_batch_size: %s, \"\n",
    "    \"unique_overlapping_factor: %s, unique_n_total_experts: %s, \"\n",
    "    \"unique_n_local_experts: %s\",\n",
    "    unique_n_total_clients,\n",
    "    unique_local_batch_size,\n",
    "    unique_overlapping_factor,\n",
    "    unique_n_total_experts,\n",
    "    unique_n_local_experts,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d187338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collection and processing for expert density analysis\n",
    "\n",
    "log.info(\"🔄 Starting data collection and processing...\")\n",
    "unique_run_uuids = {\n",
    "    str(\n",
    "        get_clientrun_property_from_config(\n",
    "            run,\n",
    "            get_property_fn=operator.itemgetter(\"run_uuid\"),\n",
    "        ),\n",
    "    )\n",
    "    for run in runs\n",
    "}\n",
    "log.info(\"Found %s runs to process\", len(unique_run_uuids))\n",
    "results_list = []\n",
    "\n",
    "for i, unique_run_uuid in enumerate(unique_run_uuids):\n",
    "    log.info(\n",
    "        \"📊 Processing run %s/%s: %s\",\n",
    "        i + 1,\n",
    "        len(unique_run_uuids),\n",
    "        unique_run_uuid,\n",
    "    )\n",
    "\n",
    "    run: wandb.apis.public.Run | None = (  # pyright: ignore[reportAttributeAccessIssue]\n",
    "        None\n",
    "    )\n",
    "    try:\n",
    "        # Get any run that matches the unique run UUID\n",
    "        run = next(r for r in runs if get_run_uuid_from_config(r) == unique_run_uuid)\n",
    "        assert run is not None, f\"Run with UUID {unique_run_uuid} not found\"\n",
    "\n",
    "        # Extract configuration parameters\n",
    "        config = run.config\n",
    "        run_uuid = get_clientrun_property_from_config(\n",
    "            run,\n",
    "            get_property_fn=operator.itemgetter(\"run_uuid\"),\n",
    "        )\n",
    "\n",
    "        n_total_clients = get_clientrun_property_from_config(\n",
    "            run,\n",
    "            get_property_fn=lambda config: config[\"fl\"][\"n_total_clients\"],\n",
    "        )\n",
    "\n",
    "        n_total_experts = get_clientrun_property_from_config(\n",
    "            run,\n",
    "            get_property_fn=lambda config: config[\"llm_config\"][\"model\"][\"ffn_config\"][\n",
    "                \"ff_n_experts\"\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        overlapping_factor = get_clientrun_property_from_config(\n",
    "            run,\n",
    "            get_property_fn=lambda config: config[\"fl\"][\"experts_overlapping_factor\"],\n",
    "        )\n",
    "\n",
    "        global_train_batch_size = get_clientrun_property_from_config(\n",
    "            run,\n",
    "            get_property_fn=lambda config: config[\"llm_config\"][\n",
    "                \"global_train_batch_size\"\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # Calculate derived metrics\n",
    "        n_local_experts = get_n_local_experts(config)\n",
    "        experts_global_batch_size = get_experts_global_batch_size(config)\n",
    "        non_experts_global_batch_size = get_non_experts_global_batch_size(config)\n",
    "\n",
    "        log.info(\n",
    "            \"📋 Configuration: TE=%s, LE=%s, Clients=%s, OF=%s\",\n",
    "            n_total_experts,\n",
    "            n_local_experts,\n",
    "            n_total_clients,\n",
    "            overlapping_factor,\n",
    "        )\n",
    "\n",
    "        # Download and process data\n",
    "        log.info(\"🔽 Downloading data for %s...\", run_uuid)\n",
    "\n",
    "        try:\n",
    "            # Download photon metrics for the run\n",
    "            assert run_uuid is not None, \"Run UUID must not be None\"\n",
    "            assert isinstance(\n",
    "                run_uuid,\n",
    "                str,\n",
    "            ), f\"Run UUID must be a string not a {type(run_uuid)}\"\n",
    "            _s_df, clients_df = download_photon_metrics(\n",
    "                base_name=\"camlsys/photon\",\n",
    "                run_uuid=run_uuid,\n",
    "            )\n",
    "\n",
    "            # Try to get perplexity vs tokens data\n",
    "            assert n_total_clients is not None, \"Total clients must not be None\"\n",
    "            assert isinstance(\n",
    "                n_total_clients,\n",
    "                int,\n",
    "            ), f\"Total clients must be an integer not a {type(n_total_clients)}\"\n",
    "            result = get_perplexity_versus_tokens(\n",
    "                client_metrics_df=clients_df,\n",
    "                n_clients_per_round=n_total_clients,\n",
    "            )\n",
    "\n",
    "            tokens, perplexity = result\n",
    "\n",
    "            if len(tokens) == 0 or len(perplexity) == 0:\n",
    "                log.warning(\"❌ Empty data arrays for %s\", run_uuid)\n",
    "                continue\n",
    "\n",
    "            # Try to get the throughput data\n",
    "            steps, throughput = get_device_throughput_series(\n",
    "                client_metrics_df=clients_df,\n",
    "                moving_window=10,\n",
    "            )\n",
    "\n",
    "            # Calculate metrics\n",
    "            final_perplexity = (\n",
    "                perplexity.iloc[-1] if len(perplexity) > 0 else float(\"nan\")\n",
    "            )\n",
    "            total_tokens = tokens.iloc[-1] if len(tokens) > 0 else 0\n",
    "            n_data_points = len(tokens)\n",
    "\n",
    "            log.info(\n",
    "                (\n",
    "                    \"   ✅ Data processed: %d points,\"\n",
    "                    \" Final perplexity: %.4f, Total tokens: %.0f\"\n",
    "                ),\n",
    "                n_data_points,\n",
    "                final_perplexity,\n",
    "                total_tokens,\n",
    "            )\n",
    "\n",
    "            # Store results\n",
    "            results_list.append(\n",
    "                {\n",
    "                    \"run_uuid\": str(run_uuid),\n",
    "                    \"n_total_clients\": n_total_clients,\n",
    "                    \"n_total_experts\": n_total_experts,\n",
    "                    \"n_local_experts\": n_local_experts,\n",
    "                    \"overlapping_factor\": overlapping_factor,\n",
    "                    \"global_train_batch_size\": global_train_batch_size,\n",
    "                    \"experts_global_batch_size\": experts_global_batch_size,\n",
    "                    \"non_experts_global_batch_size\": non_experts_global_batch_size,\n",
    "                    \"final_perplexity\": final_perplexity,\n",
    "                    \"total_tokens\": total_tokens,\n",
    "                    \"n_data_points\": n_data_points,\n",
    "                    \"tokens\": (\n",
    "                        tokens.tolist() if hasattr(tokens, \"tolist\") else list(tokens)\n",
    "                    ),\n",
    "                    \"perplexity\": (\n",
    "                        perplexity.tolist()\n",
    "                        if hasattr(perplexity, \"tolist\")\n",
    "                        else list(perplexity)\n",
    "                    ),\n",
    "                    \"steps\": (\n",
    "                        steps.tolist() if hasattr(steps, \"tolist\") else list(steps)\n",
    "                    ),\n",
    "                    \"throughput\": (\n",
    "                        throughput.tolist()\n",
    "                        if hasattr(throughput, \"tolist\")\n",
    "                        else list(throughput)\n",
    "                    ),\n",
    "                },\n",
    "            )\n",
    "\n",
    "        except ClientRunNotFoundError:\n",
    "            # Log exception with stack trace\n",
    "            log.exception(\n",
    "                \"   ⚠️  Client run not found for %s\",\n",
    "                run_uuid,\n",
    "                stack_info=True,\n",
    "            )\n",
    "\n",
    "            # Remove this run from WandB runs to avoid further processing\n",
    "            remove_runs_by_regex(\"camlsys/photon\", f\"^{run_uuid}*\")\n",
    "            continue\n",
    "\n",
    "        except ColumnNotFoundError:\n",
    "            log.exception(\n",
    "                \"   ⚠️ Column not found in client metrics DataFrame for %s. \"\n",
    "                \"We assume this run crashed and doesn't have the expected data.\",\n",
    "                run_uuid,\n",
    "                stack_info=True,\n",
    "            )\n",
    "\n",
    "            # Remove this run from WandB runs to avoid further processing\n",
    "            remove_runs_by_regex(\"camlsys/photon\", f\"^{run_uuid}*\")\n",
    "            continue\n",
    "\n",
    "        except Exception:\n",
    "            log.exception(\"   ❌ Error processing %s\", run_uuid, stack_info=True)\n",
    "            continue\n",
    "\n",
    "    except Exception:\n",
    "        assert run is not None, \"Run must not be None\"\n",
    "        log.exception(\n",
    "            \"   ❌ Error extracting config for run %s\",\n",
    "            run.name,\n",
    "            stack_info=True,\n",
    "        )\n",
    "        continue\n",
    "\n",
    "log.info(\"\\n✅ Data collection completed!\")\n",
    "log.info(\n",
    "    \"Successfully processed %d out of %d runs\",\n",
    "    len(results_list),\n",
    "    len(unique_run_uuids),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9e9e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced summary with configuration analysis\n",
    "log.info(\"\\n=== Summary ===\")\n",
    "log.info(\n",
    "    \"Successfully processed %d out of %d runs\",\n",
    "    len(results_list),\n",
    "    len(unique_run_uuids),\n",
    ")\n",
    "\n",
    "# Analyze planned configurations if we have results\n",
    "if results_list:\n",
    "    log.info(\"\\n📊 CONFIGURATION ANALYSIS 📊\")\n",
    "    log.info(\"=\" * 60)\n",
    "\n",
    "    # Group by n_total_experts to analyze configurations\n",
    "    experts_groups = {}\n",
    "    for result in results_list:\n",
    "        n_experts = result[\"n_total_experts\"]\n",
    "        if n_experts not in experts_groups:\n",
    "            experts_groups[n_experts] = []\n",
    "        experts_groups[n_experts].append(result)\n",
    "\n",
    "    for n_experts in sorted(experts_groups.keys()):\n",
    "        runs_for_experts = experts_groups[n_experts]\n",
    "        log.info(\"\\n🔢 Total Experts: %d\", n_experts)\n",
    "        log.info(\"   Number of runs: %d\", len(runs_for_experts))\n",
    "\n",
    "        # Collect the theoretical configurations\n",
    "        theoretical_configs: set[tuple[int, int, int]] = set()\n",
    "        for i in range(1, n_experts + 1):\n",
    "            # If i is not a power of 2, skip it\n",
    "            if (i & (i - 1)) != 0:\n",
    "                continue\n",
    "            for k in range(i, n_experts + 1):\n",
    "                # If k is not a power of 2, skip it\n",
    "                if (k & (k - 1)) != 0:\n",
    "                    continue\n",
    "                theoretical_configs.update(\n",
    "                    (i, k, local_batch_size)\n",
    "                    for local_batch_size in {\n",
    "                        BASE_BATCH_SIZE // i,\n",
    "                        BASE_BATCH_SIZE // k,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        # Analyze the configuration space for this expert count\n",
    "        actual_configs: set[tuple[int, int, int]] = set()\n",
    "        actual_configs.update(\n",
    "            (\n",
    "                run[\"overlapping_factor\"],\n",
    "                run[\"n_total_clients\"],\n",
    "                run[\"global_train_batch_size\"],\n",
    "            )\n",
    "            for run in runs_for_experts\n",
    "        )\n",
    "\n",
    "        # Calculate theoretical vs actual configurations\n",
    "        log.info(\"   Theoretical configurations: %d\", len(theoretical_configs))\n",
    "        log.info(\"   Actual runs: %d\", len(actual_configs))\n",
    "\n",
    "        if len(actual_configs) < len(theoretical_configs):\n",
    "            coverage = (len(actual_configs) / len(theoretical_configs)) * 100\n",
    "            log.info(\"   Coverage: %.1f%% ⚠️\", coverage)\n",
    "        else:\n",
    "            log.info(\"   Coverage: 100%% ✅\")\n",
    "\n",
    "        # Show detailed configuration breakdown by showing first those that are missing\n",
    "        # and then those that are present\n",
    "        missing_configs = theoretical_configs - actual_configs\n",
    "        if missing_configs:\n",
    "            log.warning(\"   ⚠️ Missing configurations (%d):\", len(missing_configs))\n",
    "            for config in sorted(missing_configs):\n",
    "                log.warning(\n",
    "                    \"      • Overlapping Factor: %.1f, Clients: %d, \"\n",
    "                    \"Local Batch Size: %d\",\n",
    "                    config[0],\n",
    "                    config[1],\n",
    "                    config[2],\n",
    "                )\n",
    "        else:\n",
    "            log.info(\"   All theoretical configurations are present\")\n",
    "\n",
    "# Check for runs that didn't reach 1 billion tokens and log warnings\n",
    "incomplete_runs = []\n",
    "complete_runs = []\n",
    "if results_list:\n",
    "    log.info(\"\\n⚠️  TOKEN COUNT ANALYSIS ⚠️\")\n",
    "    log.info(\"=\" * 60)\n",
    "\n",
    "    billion_tokens = 1e9\n",
    "\n",
    "    for result in results_list:\n",
    "        if result[\"total_tokens\"] < billion_tokens:\n",
    "            incomplete_runs.append(result)\n",
    "        else:\n",
    "            complete_runs.append(result)\n",
    "\n",
    "    if incomplete_runs:\n",
    "        log.warning(\n",
    "            \"🔴 WARNING: %d run(s) did NOT reach 1 billion tokens:\",\n",
    "            len(incomplete_runs),\n",
    "        )\n",
    "        log.info(\"-\" * 60)\n",
    "\n",
    "        for i, result in enumerate(incomplete_runs, 1):\n",
    "            log.info(\"\\n%s. Run UUID: %s\", i, result[\"run_uuid\"])\n",
    "            log.info(\n",
    "                \"   Total Tokens: %s (%.3fB)\",\n",
    "                format(result[\"total_tokens\"], \",\"),\n",
    "                result[\"total_tokens\"] / 1e9,\n",
    "            )\n",
    "            log.info(\n",
    "                \"   Completion: %.1f%% of 1B tokens\",\n",
    "                result[\"total_tokens\"] / billion_tokens * 100,\n",
    "            )\n",
    "            log.info(\"   📋 Full Configuration:\")\n",
    "            log.info(\"      • Total Experts: %s\", result[\"n_total_experts\"])\n",
    "            log.info(\"      • Local Experts: %s\", result[\"n_local_experts\"])\n",
    "            log.info(\"      • Total Clients: %s\", result[\"n_total_clients\"])\n",
    "            log.info(\"      • Overlapping Factor: %.1f\", result[\"overlapping_factor\"])\n",
    "            log.info(\n",
    "                \"      • Expert Global Batch Size: %s\",\n",
    "                result[\"experts_global_batch_size\"],\n",
    "            )\n",
    "            log.info(\n",
    "                \"      • Non-Expert Global Batch Size: %s\",\n",
    "                result[\"non_experts_global_batch_size\"],\n",
    "            )\n",
    "            log.info(\"      • Local Batch Size: %s\", result[\"global_train_batch_size\"])\n",
    "            log.info(\"      • Final Perplexity: %.4f\", result[\"final_perplexity\"])\n",
    "            log.info(\"      • Data Points: %s\", result[\"n_data_points\"])\n",
    "\n",
    "    if complete_runs:\n",
    "        log.info(\n",
    "            \"✅ %d run(s) successfully reached 1+ billion tokens:\",\n",
    "            len(complete_runs),\n",
    "        )\n",
    "        for result in complete_runs:\n",
    "            log.info(\n",
    "                \"   • %s: %d tokens (%.3fB)\",\n",
    "                result[\"run_uuid\"],\n",
    "                result[\"total_tokens\"],\n",
    "                result[\"total_tokens\"] / 1e9,\n",
    "            )\n",
    "\n",
    "    log.info(\"\\n📊 Token Count Summary:\")\n",
    "    log.info(\"   • Complete runs (≥1B tokens): %d\", len(complete_runs))\n",
    "    log.info(\"   • Incomplete runs (<1B tokens): %d\", len(incomplete_runs))\n",
    "    if results_list:\n",
    "        avg_tokens = sum(r[\"total_tokens\"] for r in results_list) / len(results_list)\n",
    "        log.info(\n",
    "            \"   • Average tokens across all runs: %.0f (%.3fB)\",\n",
    "            avg_tokens,\n",
    "            avg_tokens / 1e9,\n",
    "        )\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "this_cell_results_list = results_list\n",
    "if EXCLUDE_INCOMPLETE_RUNS:\n",
    "    this_cell_results_list = complete_runs\n",
    "if this_cell_results_list:\n",
    "    results_df = pd.DataFrame(this_cell_results_list)\n",
    "else:\n",
    "    log.info(\"No results to analyze\")\n",
    "    results_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503a2d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump complete run UUIDs to file\n",
    "\n",
    "if complete_runs:\n",
    "    # Extract just the UUIDs from complete runs\n",
    "    complete_run_uuids = [run[\"run_uuid\"] for run in complete_runs]\n",
    "\n",
    "    # Create output filename with timestamp\n",
    "    timestamp = datetime.now(tz=UTC).strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_file = Path(f\"complete_run_uuids_{timestamp}.json\")\n",
    "\n",
    "    # Save to JSON file for easy reading\n",
    "    output_data = {\n",
    "        \"timestamp\": timestamp,\n",
    "        \"total_complete_runs\": len(complete_run_uuids),\n",
    "        \"total_runs_analyzed\": len(results_list),\n",
    "        \"complete_run_uuids\": complete_run_uuids,\n",
    "        \"run_details\": [\n",
    "            {\n",
    "                \"run_uuid\": run[\"run_uuid\"],\n",
    "                \"n_total_experts\": run[\"n_total_experts\"],\n",
    "                \"n_local_experts\": run[\"n_local_experts\"],\n",
    "                \"overlapping_factor\": run[\"overlapping_factor\"],\n",
    "                \"final_perplexity\": run[\"final_perplexity\"],\n",
    "                \"total_tokens\": run[\"total_tokens\"],\n",
    "            }\n",
    "            for run in complete_runs\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    with output_file.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(output_data, f, indent=2)\n",
    "\n",
    "    log.info(\"✅ Complete run UUIDs saved to: %s\", output_file)\n",
    "    log.info(\"📊 Summary:\")\n",
    "    log.info(\"   - Total complete runs: %d\", len(complete_run_uuids))\n",
    "    log.info(\"   - Total runs analyzed: %d\", len(results_list))\n",
    "    log.info(\"   - Complete run UUIDs with total experts:\")\n",
    "    for i, run in enumerate(complete_runs, 1):\n",
    "        log.info(\"     %d. %s (TE: %d)\", i, run[\"run_uuid\"], run[\"n_total_experts\"])\n",
    "\n",
    "    # Also save a simple text file with just the UUIDs and total experts (one per line)\n",
    "    txt_file = Path(f\"complete_run_uuids_{timestamp}.txt\")\n",
    "    with txt_file.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"# Complete Run UUIDs with Total Experts\\n\")\n",
    "        f.write(\"# Format: run_uuid,n_total_experts\\n\")\n",
    "        for run in complete_runs:\n",
    "            f.write(f\"{run['run_uuid']},{run['n_total_experts']}\\n\")\n",
    "\n",
    "    log.info(\"📝 Also saved text version with total experts to: %s\", txt_file)\n",
    "\n",
    "else:\n",
    "    log.warning(\"❌ No complete runs found to save\")\n",
    "    log.info(\"   All %d runs are incomplete (< 1B tokens)\", len(results_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f6be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Expert Density Analysis with Independent, High-Quality Plots\n",
    "log.info(\"Generating enhanced Expert Density Analysis with improved cosmetics...\")\n",
    "\n",
    "this_cell_results_list = results_list\n",
    "if EXCLUDE_INCOMPLETE_RUNS:\n",
    "    this_cell_results_list = complete_runs\n",
    "\n",
    "if len(this_cell_results_list) > 0:\n",
    "    # Quick token count check before plotting\n",
    "    billion_tokens = 1e9\n",
    "    incomplete_runs = [\n",
    "        r for r in this_cell_results_list if r[\"total_tokens\"] < billion_tokens\n",
    "    ]\n",
    "\n",
    "    if incomplete_runs:\n",
    "        log.warning(\n",
    "            \"\\n ATTENTION: %s of %s runs didn't reach 1B tokens!\",\n",
    "            len(incomplete_runs),\n",
    "            len(this_cell_results_list),\n",
    "        )\n",
    "        log.info(\"   This may affect training convergence analysis.\\n\")\n",
    "\n",
    "    # Set up enhanced plotting style\n",
    "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "    colors = plt.cm.Set1(  # pyright: ignore[reportAttributeAccessIssue]\n",
    "        np.linspace(0, 1, len(this_cell_results_list)),\n",
    "    )\n",
    "\n",
    "    # ==== PLOT 1: Training Progress - Perplexity vs Total Tokens ====\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    for i, result in enumerate(this_cell_results_list):\n",
    "        tokens = np.array(result[\"tokens\"])\n",
    "        perplexity = np.array(result[\"perplexity\"])\n",
    "\n",
    "        # Enhanced legend label with key information\n",
    "        incomplete_indicator = \" ⚠️\" if result[\"total_tokens\"] < billion_tokens else \"\"\n",
    "        legend_label = (\n",
    "            f\"TE: {result['n_total_experts']}, LE: {result['n_local_experts']}, \"\n",
    "            f\"TC: {result['n_total_clients']}, OF: {result['overlapping_factor']:.1f}, \"\n",
    "            f\"EgBS: {result['experts_global_batch_size']},\"\n",
    "            f\" nEgBS: {result['non_experts_global_batch_size']}{incomplete_indicator}\"\n",
    "        )\n",
    "\n",
    "        # Use different line style for incomplete runs\n",
    "        linestyle = \"--\" if result[\"total_tokens\"] < billion_tokens else \"-\"\n",
    "        alpha = 0.7 if result[\"total_tokens\"] < billion_tokens else 0.9\n",
    "        linewidth = 2.0 if result[\"total_tokens\"] < billion_tokens else 2.5\n",
    "\n",
    "        plt.plot(\n",
    "            tokens,\n",
    "            perplexity,\n",
    "            label=legend_label,\n",
    "            linewidth=linewidth,\n",
    "            alpha=alpha,\n",
    "            color=colors[i],\n",
    "            linestyle=linestyle,\n",
    "            marker=\"o\" if i < 3 else (\"s\" if i < 6 else \"^\"),\n",
    "            markersize=4,\n",
    "            markevery=max(1, len(tokens) // 15),\n",
    "            markerfacecolor=\"white\",\n",
    "            markeredgewidth=1.5,\n",
    "            markeredgecolor=colors[i],\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Total Tokens\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.ylabel(\"Language Perplexity\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.title(\n",
    "        (\n",
    "            \"Training Progress: Perplexity vs Total Tokens\\n\"\n",
    "            \"Expert Density Analysis with Batch Size Configurations\"\n",
    "        ),\n",
    "        fontsize=16,\n",
    "        fontweight=\"bold\",\n",
    "        pad=20,\n",
    "    )\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend(\n",
    "        frameon=True,\n",
    "        fancybox=True,\n",
    "        shadow=True,\n",
    "        ncol=1 if len(this_cell_results_list) <= 4 else 2,\n",
    "        fontsize=10,\n",
    "        loc=\"upper right\",\n",
    "    )\n",
    "    plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3173d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Expert Density Analysis with Independent, High-Quality Plots\n",
    "log.info(\"Generating enhanced Expert Density Analysis with improved cosmetics...\")\n",
    "\n",
    "this_cell_results_list = results_list\n",
    "if EXCLUDE_INCOMPLETE_RUNS:\n",
    "    this_cell_results_list = complete_runs\n",
    "\n",
    "if len(this_cell_results_list) > 0:\n",
    "    # Quick token count check before plotting\n",
    "    billion_tokens = 1e9\n",
    "    incomplete_runs = [\n",
    "        r for r in this_cell_results_list if r[\"total_tokens\"] < billion_tokens\n",
    "    ]\n",
    "\n",
    "    if incomplete_runs:\n",
    "        log.warning(\n",
    "            \"\\n ATTENTION: %s of %s runs didn't reach 1B tokens!\",\n",
    "            len(incomplete_runs),\n",
    "            len(this_cell_results_list),\n",
    "        )\n",
    "        log.info(\"   This may affect training convergence analysis.\\n\")\n",
    "\n",
    "    # Set up enhanced plotting style\n",
    "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "    colors = plt.cm.Set1(  # pyright: ignore[reportAttributeAccessIssue]\n",
    "        np.linspace(0, 1, len(this_cell_results_list)),\n",
    "    )\n",
    "    # ==== PLOT 2: Final Performance Scatter ====\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Create scatter plot with enhanced styling\n",
    "    for result in this_cell_results_list:\n",
    "        marker = \"o\" if result[\"total_tokens\"] >= billion_tokens else \"^\"\n",
    "        alpha = 0.8 if result[\"total_tokens\"] >= billion_tokens else 0.6\n",
    "        edge_color = \"darkred\" if result[\"total_tokens\"] < billion_tokens else \"black\"\n",
    "        edge_width = 2.5 if result[\"total_tokens\"] < billion_tokens else 1.5\n",
    "\n",
    "        scatter = plt.scatter(\n",
    "            result[\"n_local_experts\"],\n",
    "            result[\"final_perplexity\"],\n",
    "            c=result[\"overlapping_factor\"],\n",
    "            s=200,\n",
    "            alpha=alpha,\n",
    "            cmap=\"viridis\",\n",
    "            edgecolors=edge_color,\n",
    "            linewidth=edge_width,\n",
    "            marker=marker,\n",
    "            vmin=min(r[\"overlapping_factor\"] for r in this_cell_results_list),\n",
    "            vmax=max(r[\"overlapping_factor\"] for r in this_cell_results_list),\n",
    "        )\n",
    "\n",
    "    # Enhanced annotations\n",
    "    for result in this_cell_results_list:\n",
    "        incomplete_indicator = \" ⚠️\" if result[\"total_tokens\"] < billion_tokens else \"\"\n",
    "        annotation_text = (\n",
    "            f\"TE: {result['n_total_experts']}, LE:{result['n_local_experts']}, \"\n",
    "            f\"TC: {result['n_total_clients']}, \"\n",
    "            f\"EBS: {result['experts_global_batch_size']},\"\n",
    "            f\" NEBS: {result['non_experts_global_batch_size']}, \"\n",
    "            f\"{result['total_tokens'] / 1e9:.2f}B tokens{incomplete_indicator}\"\n",
    "        )\n",
    "        plt.annotate(\n",
    "            annotation_text,\n",
    "            (result[\"n_local_experts\"], result[\"final_perplexity\"]),\n",
    "            xytext=(8, 8),\n",
    "            textcoords=\"offset points\",\n",
    "            fontsize=9,\n",
    "            bbox={\n",
    "                \"boxstyle\": \"round,pad=0.3\",\n",
    "                \"facecolor\": \"white\",\n",
    "                \"alpha\": 0.8,\n",
    "                \"edgecolor\": \"gray\",\n",
    "            },\n",
    "            arrowprops={\n",
    "                \"arrowstyle\": \"->\",\n",
    "                \"connectionstyle\": \"arc3,rad=0.1\",\n",
    "                \"alpha\": 0.6,\n",
    "            },\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Number of Local Experts\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.ylabel(\"Final Perplexity\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.title(\n",
    "        (\n",
    "            \"Final Performance vs Expert Configuration\\n\"\n",
    "            \"Color = Overlapping Factor | Red edges = Incomplete runs (<1B tokens)\"\n",
    "        ),\n",
    "        fontsize=16,\n",
    "        fontweight=\"bold\",\n",
    "        pad=20,\n",
    "    )\n",
    "\n",
    "    cbar = plt.colorbar(scatter, shrink=0.8, aspect=20)\n",
    "    cbar.set_label(\"Overlapping Factor\", fontsize=12, fontweight=\"bold\")\n",
    "    cbar.ax.tick_params(labelsize=10)\n",
    "\n",
    "    plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c560369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Expert Density Analysis with Independent, High-Quality Plots\n",
    "log.info(\"Generating enhanced Expert Density Analysis with improved cosmetics...\")\n",
    "\n",
    "this_cell_results_list = results_list\n",
    "if EXCLUDE_INCOMPLETE_RUNS:\n",
    "    this_cell_results_list = complete_runs\n",
    "\n",
    "if len(this_cell_results_list) > 0:\n",
    "    # Quick token count check before plotting\n",
    "    billion_tokens = 1e9\n",
    "    incomplete_runs = [\n",
    "        r for r in this_cell_results_list if r[\"total_tokens\"] < billion_tokens\n",
    "    ]\n",
    "\n",
    "    if incomplete_runs:\n",
    "        log.warning(\n",
    "            \"\\n ATTENTION: %s of %s runs didn't reach 1B tokens!\",\n",
    "            len(incomplete_runs),\n",
    "            len(this_cell_results_list),\n",
    "        )\n",
    "        log.info(\"   This may affect training convergence analysis.\\n\")\n",
    "\n",
    "    # Set up enhanced plotting style\n",
    "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "    colors = plt.cm.Set1(  # pyright: ignore[reportAttributeAccessIssue]\n",
    "        np.linspace(0, 1, len(this_cell_results_list)),\n",
    "    )\n",
    "    # ==== PLOT 3: Training Efficiency Analysis ====\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    for i, result in enumerate(this_cell_results_list):\n",
    "        incomplete_indicator = \" ⚠️\" if result[\"total_tokens\"] < billion_tokens else \"\"\n",
    "        alpha = 0.7 if result[\"total_tokens\"] < billion_tokens else 0.8\n",
    "        edge_color = \"darkred\" if result[\"total_tokens\"] < billion_tokens else \"black\"\n",
    "        edge_width = 2.5 if result[\"total_tokens\"] < billion_tokens else 1.5\n",
    "\n",
    "        plt.scatter(\n",
    "            result[\"total_tokens\"] / 1e9,  # Convert to billions for readability\n",
    "            result[\"final_perplexity\"],\n",
    "            s=result[\"n_local_experts\"] * 80\n",
    "            + 120,  # Size proportional to local experts\n",
    "            alpha=alpha,\n",
    "            color=colors[i],\n",
    "            edgecolors=edge_color,\n",
    "            linewidth=edge_width,\n",
    "            label=(\n",
    "                f\"TE: {result['n_total_experts']}, \"\n",
    "                f\"LE: {result['n_local_experts']}, \"\n",
    "                f\"TC: {result['n_total_clients']}, \"\n",
    "                f\"OF: {result['overlapping_factor']:.1f}\"\n",
    "                f\"{incomplete_indicator}\"\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Total Tokens Consumed (Billions)\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.ylabel(\"Final Perplexity\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.title(\n",
    "        (\n",
    "            \"Training Efficiency Analysis\\n\"\n",
    "            \"Marker Size ∝ Local Experts | Red edges = Incomplete runs\"\n",
    "        ),\n",
    "        fontsize=16,\n",
    "        fontweight=\"bold\",\n",
    "        pad=20,\n",
    "    )\n",
    "\n",
    "    plt.legend(\n",
    "        title=(\n",
    "            \"TE: Total Experts, LE: Local Experts, TC: Total Clients,\"\n",
    "            \" OF: Overlap Factor\"\n",
    "            \"\\n⚠️ = Incomplete runs (<1B tokens)\"\n",
    "        ),\n",
    "        frameon=True,\n",
    "        fancybox=True,\n",
    "        shadow=True,\n",
    "        fontsize=10,\n",
    "        title_fontsize=11,\n",
    "        loc=\"upper left\",\n",
    "        bbox_to_anchor=(1.02, 1),\n",
    "    )\n",
    "    plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ==== PLOT 4: Convergence Rate Comparison ====\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    for i, result in enumerate(this_cell_results_list):\n",
    "        tokens = np.array(result[\"tokens\"])\n",
    "        perplexity = np.array(result[\"perplexity\"])\n",
    "\n",
    "        if len(tokens) > 1:\n",
    "            tokens_norm = (tokens - tokens.min()) / (tokens.max() - tokens.min())\n",
    "            incomplete_indicator = (\n",
    "                \" ⚠️\" if result[\"total_tokens\"] < billion_tokens else \"\"\n",
    "            )\n",
    "            linestyle = \"--\" if result[\"total_tokens\"] < billion_tokens else \"-\"\n",
    "            alpha = 0.7 if result[\"total_tokens\"] < billion_tokens else 0.9\n",
    "            linewidth = 2.0 if result[\"total_tokens\"] < billion_tokens else 2.5\n",
    "\n",
    "            plt.plot(\n",
    "                tokens_norm,\n",
    "                perplexity,\n",
    "                label=(\n",
    "                    f\"TE: {result['n_total_experts']}, \"\n",
    "                    f\"LE: {result['n_local_experts']}, \"\n",
    "                    f\"TC: {result['n_total_clients']}, \"\n",
    "                    f\"OF: {result['overlapping_factor']:.1f}\"\n",
    "                    f\"{incomplete_indicator}\"\n",
    "                ),\n",
    "                linewidth=linewidth,\n",
    "                alpha=alpha,\n",
    "                linestyle=linestyle,\n",
    "                color=colors[i],\n",
    "                marker=\"o\" if i < 3 else (\"s\" if i < 6 else \"^\"),\n",
    "                markersize=4,\n",
    "                markevery=max(1, len(tokens_norm) // 20),\n",
    "                markerfacecolor=\"white\",\n",
    "                markeredgewidth=1.5,\n",
    "                markeredgecolor=colors[i],\n",
    "            )\n",
    "\n",
    "    plt.xlabel(\n",
    "        \"Normalized Training Progress (0 = Start, 1 = End)\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    plt.ylabel(\"Language Perplexity\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.title(\n",
    "        (\n",
    "            \"Convergence Rate Comparison\\n\"\n",
    "            \"Normalized Training Progress with Expert Configurations\"\n",
    "        ),\n",
    "        fontsize=16,\n",
    "        fontweight=\"bold\",\n",
    "        pad=20,\n",
    "    )\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend(\n",
    "        title=(\n",
    "            \"TE: Total Experts, LE: Local Experts, TC: Total Clients,\"\n",
    "            \" OF: Overlap Factor\"\n",
    "            \"\\n ⚠️ = Incomplete runs (<1B tokens)\"\n",
    "        ),\n",
    "        frameon=True,\n",
    "        fancybox=True,\n",
    "        shadow=True,\n",
    "        fontsize=10,\n",
    "        title_fontsize=11,\n",
    "        ncol=1 if len(this_cell_results_list) <= 4 else 2,\n",
    "    )\n",
    "    plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ==== PLOT 5: Configuration Summary Heatmap ====\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Create a summary matrix for visualization\n",
    "    config_data = []\n",
    "    config_labels = []\n",
    "\n",
    "    for result in this_cell_results_list:\n",
    "        config_data.append(\n",
    "            [\n",
    "                result[\"n_total_experts\"],\n",
    "                result[\"n_local_experts\"],\n",
    "                result[\"overlapping_factor\"],\n",
    "                result[\"experts_global_batch_size\"],\n",
    "                result[\"non_experts_global_batch_size\"],\n",
    "                result[\"final_perplexity\"],\n",
    "                result[\"total_tokens\"] / 1e9,\n",
    "            ],\n",
    "        )\n",
    "        incomplete_mark = \"⚠️\" if result[\"total_tokens\"] < billion_tokens else \"\"\n",
    "        config_labels.append(f\"{result['run_uuid'][:8]}...{incomplete_mark}\")\n",
    "\n",
    "    config_matrix = np.array(config_data)\n",
    "\n",
    "    # Normalize each column to [0, 1] for better heatmap visualization\n",
    "    config_matrix_norm = np.zeros_like(config_matrix)\n",
    "    for i in range(config_matrix.shape[1]):\n",
    "        col_min, col_max = config_matrix[:, i].min(), config_matrix[:, i].max()\n",
    "        if col_max > col_min:\n",
    "            config_matrix_norm[:, i] = (config_matrix[:, i] - col_min) / (\n",
    "                col_max - col_min\n",
    "            )\n",
    "        else:\n",
    "            config_matrix_norm[:, i] = 0.5  # If all values are the same\n",
    "\n",
    "    im = plt.imshow(config_matrix_norm.T, cmap=\"RdYlBu_r\", aspect=\"auto\", alpha=0.8)\n",
    "\n",
    "    # Set labels\n",
    "    plt.xticks(range(len(config_labels)), config_labels, rotation=45, ha=\"right\")\n",
    "    plt.yticks(\n",
    "        range(len(config_data[0])),\n",
    "        [\n",
    "            \"Total Experts\",\n",
    "            \"Local Experts\",\n",
    "            \"Overlap Factor\",\n",
    "            \"Expert Global BS\",\n",
    "            \"Non-Expert Global BS\",\n",
    "            \"Final Perplexity\",\n",
    "            \"Total Tokens (B)\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Add text annotations with actual values\n",
    "    for i in range(len(config_labels)):\n",
    "        for j in range(len(config_data[0])):\n",
    "            if j < 5:  # Integer values\n",
    "                text = f\"{int(config_matrix[i, j])}\"\n",
    "            else:  # Float values\n",
    "                text = f\"{config_matrix[i, j]:.2f}\"\n",
    "            plt.text(\n",
    "                i,\n",
    "                j,\n",
    "                text,\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                color=\"white\" if config_matrix_norm[i, j] > 0.5 else \"black\",\n",
    "                fontweight=\"bold\",\n",
    "                fontsize=9,\n",
    "            )\n",
    "\n",
    "    plt.title(\n",
    "        (\n",
    "            \"Configuration Summary Heatmap\\n\"\n",
    "            \"Normalized values with actual values overlaid\"\n",
    "        ),\n",
    "        fontsize=16,\n",
    "        fontweight=\"bold\",\n",
    "        pad=20,\n",
    "    )\n",
    "\n",
    "    cbar = plt.colorbar(im, shrink=0.8, aspect=20)\n",
    "    cbar.set_label(\n",
    "        \"Normalized Value (0 = Min, 1 = Max)\",\n",
    "        fontsize=12,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    log.info(\"✅ Enhanced analysis with improved cosmetics completed!\")\n",
    "    log.info(\"📊 Generated 5 independent plots:\")\n",
    "    log.info(\"   1. Training Progress (Perplexity vs Tokens)\")\n",
    "    log.info(\"   2. Final Performance Scatter\")\n",
    "    log.info(\"   3. Training Efficiency Analysis\")\n",
    "    log.info(\"   4. Convergence Rate Comparison\")\n",
    "    log.info(\"   5. Configuration Summary Heatmap\")\n",
    "\n",
    "    if incomplete_runs:\n",
    "        log.warning(\n",
    "            \"⚠️  Note: %s run(s) marked as incomplete in all plots\",\n",
    "            len(incomplete_runs),\n",
    "        )\n",
    "\n",
    "else:\n",
    "    log.info(\"❌ No results available for analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392e73a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Expert Density Analysis - Throughput vs Steps Analysis\n",
    "log.info(\"Generating Throughput vs Steps Analysis with focus on Local Experts...\")\n",
    "\n",
    "this_cell_results_list = results_list\n",
    "if EXCLUDE_INCOMPLETE_RUNS:\n",
    "    this_cell_results_list = complete_runs\n",
    "\n",
    "if len(this_cell_results_list) > 0:\n",
    "    # Quick token count check before plotting\n",
    "    billion_tokens = 1e9\n",
    "    incomplete_runs = [\n",
    "        r for r in this_cell_results_list if r[\"total_tokens\"] < billion_tokens\n",
    "    ]\n",
    "\n",
    "    if incomplete_runs:\n",
    "        log.warning(\n",
    "            \"\\n ATTENTION: %s of %s runs didn't reach 1B tokens!\",\n",
    "            len(incomplete_runs),\n",
    "            len(this_cell_results_list),\n",
    "        )\n",
    "        log.info(\"   This may affect throughput analysis.\\n\")\n",
    "\n",
    "    # Set up enhanced plotting style with consistent colors for local experts\n",
    "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "\n",
    "    # Create color mapping based on unique local experts\n",
    "    unique_local_experts = sorted(\n",
    "        {r[\"n_local_experts\"] for r in this_cell_results_list},\n",
    "    )\n",
    "    color_map = plt.cm.Set1(  # pyright: ignore[reportAttributeAccessIssue]\n",
    "        np.linspace(0, 1, len(unique_local_experts)),\n",
    "    )\n",
    "    local_experts_color_dict = {\n",
    "        le: color_map[i] for i, le in enumerate(unique_local_experts)\n",
    "    }\n",
    "\n",
    "    log.info(\n",
    "        \"Found %s unique local expert configurations: %s\",\n",
    "        len(unique_local_experts),\n",
    "        unique_local_experts,\n",
    "    )\n",
    "\n",
    "    # ==== PLOT 6: Enhanced Throughput Analysis focused on Local Experts ====\n",
    "    plt.figure(figsize=(18, 12))\n",
    "\n",
    "    # Subplot 1: Raw throughput over training steps (colored by local experts)\n",
    "    plt.subplot(2, 3, 1)\n",
    "    for result in this_cell_results_list:\n",
    "        steps = np.array(result[\"steps\"])\n",
    "        throughput = np.array(result[\"throughput\"])\n",
    "\n",
    "        if len(steps) > 0 and len(throughput) > 0:\n",
    "            # Color based on local experts\n",
    "            color = local_experts_color_dict[result[\"n_local_experts\"]]\n",
    "\n",
    "            # Enhanced legend label with key information\n",
    "            incomplete_indicator = (\n",
    "                \" ⚠️\" if result[\"total_tokens\"] < billion_tokens else \"\"\n",
    "            )\n",
    "            legend_label = (\n",
    "                f\"LE: {result['n_local_experts']}, \"\n",
    "                f\"TE: {result['n_total_experts']}, \"\n",
    "                f\"TC: {result['n_total_clients']}, \"\n",
    "                f\"OF: {result['overlapping_factor']:.1f}\"\n",
    "                f\"{incomplete_indicator}\"\n",
    "            )\n",
    "\n",
    "            # Use different line style for incomplete runs\n",
    "            linestyle = \"--\" if result[\"total_tokens\"] < billion_tokens else \"-\"\n",
    "            alpha = 0.7 if result[\"total_tokens\"] < billion_tokens else 0.9\n",
    "            linewidth = 2.0 if result[\"total_tokens\"] < billion_tokens else 2.5\n",
    "\n",
    "            plt.plot(\n",
    "                steps,\n",
    "                throughput,\n",
    "                label=legend_label,\n",
    "                linewidth=linewidth,\n",
    "                alpha=alpha,\n",
    "                color=color,\n",
    "                linestyle=linestyle,\n",
    "                marker=(\n",
    "                    \"o\"\n",
    "                    if result[\"n_local_experts\"] == min(unique_local_experts)\n",
    "                    else (\n",
    "                        \"s\"\n",
    "                        if result[\"n_local_experts\"] == max(unique_local_experts)\n",
    "                        else \"^\"\n",
    "                    )\n",
    "                ),\n",
    "                markersize=3,\n",
    "                markevery=max(1, len(steps) // 20),\n",
    "                markerfacecolor=\"white\",\n",
    "                markeredgewidth=1.2,\n",
    "                markeredgecolor=color,\n",
    "            )\n",
    "\n",
    "    plt.xlabel(\"Training Steps\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.ylabel(\"Device Throughput (tokens/s)\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.title(\n",
    "        \"Device Throughput vs Training Steps\\nGrouped by Number of Local Experts\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "        pad=15,\n",
    "    )\n",
    "    plt.legend(\n",
    "        frameon=True,\n",
    "        fancybox=True,\n",
    "        shadow=True,\n",
    "        ncol=1,\n",
    "        fontsize=9,\n",
    "        loc=\"best\",\n",
    "    )\n",
    "    plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5)\n",
    "\n",
    "    # Calculate statistics by local experts\n",
    "    throughput_stats = {}\n",
    "    for result in this_cell_results_list:\n",
    "        le = result[\"n_local_experts\"]\n",
    "        throughput = np.array(result[\"throughput\"])\n",
    "        if len(throughput) > 0:\n",
    "            avg_throughput = np.mean(throughput)\n",
    "            if le not in throughput_stats:\n",
    "                throughput_stats[le] = []\n",
    "            throughput_stats[le].append(avg_throughput)\n",
    "\n",
    "    # Calculate mean and std for each local expert configuration\n",
    "    local_experts_summary = {}\n",
    "    for le, throughputs in throughput_stats.items():\n",
    "        local_experts_summary[le] = {\n",
    "            \"mean\": np.mean(throughputs),\n",
    "            \"std\": np.std(throughputs),\n",
    "            \"count\": len(throughputs),\n",
    "            \"values\": throughputs,\n",
    "        }\n",
    "\n",
    "    # Subplot 2: Average throughput by local experts with error bars\n",
    "    plt.subplot(2, 3, 2)\n",
    "    local_experts_list = sorted(local_experts_summary.keys())\n",
    "    means = [local_experts_summary[le][\"mean\"] for le in local_experts_list]\n",
    "    stds = [local_experts_summary[le][\"std\"] for le in local_experts_list]\n",
    "    colors = [local_experts_color_dict[le] for le in local_experts_list]\n",
    "\n",
    "    bars = plt.bar(\n",
    "        [int(le) for le in local_experts_list],\n",
    "        means,\n",
    "        yerr=stds,\n",
    "        color=colors,\n",
    "        alpha=0.8,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=1.2,\n",
    "        capsize=5,\n",
    "        error_kw={\"linewidth\": 2, \"ecolor\": \"black\"},\n",
    "    )\n",
    "\n",
    "    # Add value labels on bars\n",
    "    for i, (le, mean, std) in enumerate(\n",
    "        zip(local_experts_list, means, stds, strict=True),\n",
    "    ):\n",
    "        count = local_experts_summary[le][\"count\"]\n",
    "        plt.text(\n",
    "            i,\n",
    "            mean + std + max(means) * 0.02,\n",
    "            f\"{mean:.1f}±{std:.1f}\\n(n={count})\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontweight=\"bold\",\n",
    "            fontsize=10,\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Number of Local Experts\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.ylabel(\"Average Throughput (tokens/s)\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.title(\n",
    "        \"Average Throughput by Local Experts\\nError bars show ±1 standard deviation\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "        pad=15,\n",
    "    )\n",
    "    plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5, axis=\"y\")\n",
    "\n",
    "    # Subplot 3: Detailed scatter plot with individual runs\n",
    "    plt.subplot(2, 3, 3)\n",
    "    for result in this_cell_results_list:\n",
    "        throughput = np.array(result[\"throughput\"])\n",
    "        if len(throughput) > 0:\n",
    "            avg_throughput = np.mean(throughput)\n",
    "            color = local_experts_color_dict[result[\"n_local_experts\"]]\n",
    "\n",
    "            marker = \"o\" if result[\"total_tokens\"] >= billion_tokens else \"^\"\n",
    "            alpha = 0.8 if result[\"total_tokens\"] >= billion_tokens else 0.6\n",
    "            edge_color = (\n",
    "                \"darkred\" if result[\"total_tokens\"] < billion_tokens else \"black\"\n",
    "            )\n",
    "            edge_width = 2.5 if result[\"total_tokens\"] < billion_tokens else 1.5\n",
    "\n",
    "            plt.scatter(\n",
    "                result[\"n_local_experts\"],\n",
    "                avg_throughput,\n",
    "                c=[color],\n",
    "                s=150,\n",
    "                alpha=alpha,\n",
    "                edgecolors=edge_color,\n",
    "                linewidth=edge_width,\n",
    "                marker=marker,\n",
    "            )\n",
    "\n",
    "    plt.xlabel(\"Number of Local Experts\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.ylabel(\"Average Throughput (tokens/s)\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.title(\n",
    "        \"Individual Run Throughput\\nGrouped by Local Experts\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "        pad=15,\n",
    "    )\n",
    "    plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5)\n",
    "\n",
    "    # Add jitter to x-axis for better visibility\n",
    "    plt.xlim(min(unique_local_experts) - 0.5, max(unique_local_experts) + 0.5)\n",
    "\n",
    "    # Subplot 4: Box plot showing distribution by local experts\n",
    "    plt.subplot(2, 3, 4)\n",
    "    throughput_by_le = [\n",
    "        local_experts_summary[le][\"values\"] for le in local_experts_list\n",
    "    ]\n",
    "\n",
    "    bp = plt.boxplot(\n",
    "        throughput_by_le,\n",
    "        tick_labels=[str(le) for le in local_experts_list],\n",
    "        patch_artist=True,\n",
    "        notch=True,\n",
    "        showmeans=True,\n",
    "    )\n",
    "\n",
    "    # Color the boxes according to local experts\n",
    "    for patch, color in zip(bp[\"boxes\"], colors, strict=True):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.7)\n",
    "\n",
    "    plt.xlabel(\"Number of Local Experts\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.ylabel(\"Average Throughput (tokens/s)\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.title(\n",
    "        (\n",
    "            \"Throughput Distribution by Local Experts\\n\"\n",
    "            \"Box plots with mean (triangle) and median (line)\"\n",
    "        ),\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "        pad=15,\n",
    "    )\n",
    "    plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5, axis=\"y\")\n",
    "\n",
    "    # Subplot 5: Throughput coefficient of variation by local experts\n",
    "    plt.subplot(2, 3, 5)\n",
    "    cv_by_le = {}\n",
    "    for result in this_cell_results_list:\n",
    "        le = result[\"n_local_experts\"]\n",
    "        throughput = np.array(result[\"throughput\"])\n",
    "        if len(throughput) > 1:\n",
    "            cv = (\n",
    "                np.std(throughput) / np.mean(throughput)\n",
    "                if np.mean(throughput) > 0\n",
    "                else 0\n",
    "            )\n",
    "            if le not in cv_by_le:\n",
    "                cv_by_le[le] = []\n",
    "            cv_by_le[le].append(cv)\n",
    "\n",
    "    if cv_by_le:\n",
    "        le_list = sorted(cv_by_le.keys())\n",
    "        cv_means = [np.mean(cv_by_le[le]) for le in le_list]\n",
    "        cv_stds = [\n",
    "            np.std(cv_by_le[le]) if len(cv_by_le[le]) > 1 else 0 for le in le_list\n",
    "        ]\n",
    "        colors_cv = [local_experts_color_dict[le] for le in le_list]\n",
    "\n",
    "        bars = plt.bar(\n",
    "            [int(le) for le in le_list],\n",
    "            cv_means,\n",
    "            yerr=cv_stds,\n",
    "            color=colors_cv,\n",
    "            alpha=0.8,\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=1.2,\n",
    "            capsize=5,\n",
    "            error_kw={\"linewidth\": 2, \"ecolor\": \"black\"},\n",
    "        )\n",
    "\n",
    "        # Add value labels\n",
    "        for i, (le, mean, std) in enumerate(\n",
    "            zip(le_list, cv_means, cv_stds, strict=True),\n",
    "        ):\n",
    "            count = len(cv_by_le[le])\n",
    "            plt.text(\n",
    "                i,\n",
    "                mean + std + max(cv_means) * 0.02,\n",
    "                f\"{mean:.3f}±{std:.3f}\\n(n={count})\",\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "                fontweight=\"bold\",\n",
    "                fontsize=10,\n",
    "            )\n",
    "\n",
    "        plt.xlabel(\"Number of Local Experts\", fontsize=12, fontweight=\"bold\")\n",
    "        plt.ylabel(\n",
    "            \"Throughput Coefficient of Variation\",\n",
    "            fontsize=12,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "        plt.title(\n",
    "            \"Throughput Stability by Local Experts\\n(Lower CV = More Stable)\",\n",
    "            fontsize=14,\n",
    "            fontweight=\"bold\",\n",
    "            pad=15,\n",
    "        )\n",
    "        plt.grid(alpha=0.3, linestyle=\"-\", linewidth=0.5, axis=\"y\")\n",
    "\n",
    "    # Subplot 6: Summary statistics table\n",
    "    plt.subplot(2, 3, 6)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Create summary table\n",
    "    table_data = []\n",
    "    headers = [\n",
    "        \"Local\\nExperts\",\n",
    "        \"Count\",\n",
    "        \"Mean\\nThroughput\",\n",
    "        \"Std Dev\",\n",
    "        \"CV Mean\",\n",
    "        \"CV Std\",\n",
    "    ]\n",
    "\n",
    "    for le in sorted(local_experts_summary.keys()):\n",
    "        stats = local_experts_summary[le]\n",
    "        cv_stats = cv_by_le.get(le, [0])\n",
    "        table_data.append(\n",
    "            [\n",
    "                str(le),\n",
    "                str(stats[\"count\"]),\n",
    "                f\"{stats['mean']:.1f}\",\n",
    "                f\"{stats['std']:.1f}\",\n",
    "                f\"{np.mean(cv_stats):.3f}\" if cv_stats else \"N/A\",\n",
    "                f\"{np.std(cv_stats):.3f}\" if len(cv_stats) > 1 else \"N/A\",\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    # Create table\n",
    "    table = plt.table(\n",
    "        cellText=table_data,\n",
    "        colLabels=headers,\n",
    "        cellLoc=\"center\",\n",
    "        loc=\"center\",\n",
    "        bbox=[0, 0.3, 1, 0.7],\n",
    "    )\n",
    "    table.auto_set_font_size(value=False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1, 2)\n",
    "\n",
    "    # Color the rows according to local experts\n",
    "    for i, le in enumerate(sorted(local_experts_summary.keys())):\n",
    "        color = local_experts_color_dict[le]\n",
    "        for j in range(len(headers)):\n",
    "            table[i + 1, j].set_facecolor(color)\n",
    "            table[i + 1, j].set_alpha(0.3)\n",
    "\n",
    "    plt.title(\n",
    "        \"Throughput Summary Statistics\\nby Number of Local Experts\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "        pad=20,\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Generate enhanced throughput analysis summary focused on local experts\n",
    "    log.info(\"\\n=== Throughput Analysis Summary by Local Experts ===\")\n",
    "\n",
    "    for le in sorted(local_experts_summary.keys()):\n",
    "        stats = local_experts_summary[le]\n",
    "        cv_stats = cv_by_le.get(le, [])\n",
    "\n",
    "        log.info(\"\\n📊 %s Local Experts:\", le)\n",
    "        log.info(\"   Number of runs: %s\", stats[\"count\"])\n",
    "        log.info(\n",
    "            \"   Average throughput: %.2f ± %.2f tokens/s\",\n",
    "            stats[\"mean\"],\n",
    "            stats[\"std\"],\n",
    "        )\n",
    "        log.info(\n",
    "            \"   Range: %.2f - %.2f tokens/s\",\n",
    "            min(stats[\"values\"]),\n",
    "            max(stats[\"values\"]),\n",
    "        )\n",
    "        if cv_stats:\n",
    "            log.info(\n",
    "                \"   Stability (CV): %.4f ± %.4f\",\n",
    "                np.mean(cv_stats),\n",
    "                np.std(cv_stats),\n",
    "            )\n",
    "\n",
    "        # Show individual run details\n",
    "        log.info(\"   Individual runs:\")\n",
    "        for result in this_cell_results_list:\n",
    "            if result[\"n_local_experts\"] == le:\n",
    "                throughput = np.array(result[\"throughput\"])\n",
    "                if len(throughput) > 0:\n",
    "                    avg_tp = np.mean(throughput)\n",
    "                    incomplete_mark = (\n",
    "                        \"⚠️\" if result[\"total_tokens\"] < billion_tokens else \"✅\"\n",
    "                    )\n",
    "                    log.info(\n",
    "                        \"     %s %s...: %.2f tokens/s (TE:%s, OF:%.1f)\",\n",
    "                        incomplete_mark,\n",
    "                        result[\"run_uuid\"][:12],\n",
    "                        avg_tp,\n",
    "                        result[\"n_total_experts\"],\n",
    "                        result[\"overlapping_factor\"],\n",
    "                    )\n",
    "\n",
    "    # Statistical analysis\n",
    "    if len(local_experts_summary) > 1:\n",
    "        log.info(\"\\n🔍 Statistical Analysis:\")\n",
    "\n",
    "        # Find best and worst performing local expert configurations\n",
    "        best_le = max(\n",
    "            local_experts_summary.keys(),\n",
    "            key=lambda x: local_experts_summary[x][\"mean\"],\n",
    "        )\n",
    "        worst_le = min(\n",
    "            local_experts_summary.keys(),\n",
    "            key=lambda x: local_experts_summary[x][\"mean\"],\n",
    "        )\n",
    "\n",
    "        log.info(\n",
    "            \"   🚀 Best average throughput: %s local experts (%.2f tokens/s)\",\n",
    "            best_le,\n",
    "            local_experts_summary[best_le][\"mean\"],\n",
    "        )\n",
    "        log.info(\n",
    "            \"   Worst average throughput: %s local experts (%.2f tokens/s)\",\n",
    "            worst_le,\n",
    "            local_experts_summary[worst_le][\"mean\"],\n",
    "        )\n",
    "\n",
    "        # Performance difference\n",
    "        perf_diff = (\n",
    "            local_experts_summary[best_le][\"mean\"]\n",
    "            - local_experts_summary[worst_le][\"mean\"]\n",
    "        )\n",
    "        perf_ratio = (\n",
    "            local_experts_summary[best_le][\"mean\"]\n",
    "            / local_experts_summary[worst_le][\"mean\"]\n",
    "        )\n",
    "        log.info(\n",
    "            \"   📈 Performance difference: %.2f tokens/s (%.2f x speedup)\",\n",
    "            perf_diff,\n",
    "            perf_ratio,\n",
    "        )\n",
    "\n",
    "        # Most stable configuration\n",
    "        if cv_by_le:\n",
    "            most_stable_le = min(cv_by_le.keys(), key=lambda x: np.mean(cv_by_le[x]))\n",
    "            log.info(\n",
    "                \"   📊 Most stable: %s local experts (CV: %.4f)\",\n",
    "                most_stable_le,\n",
    "                np.mean(cv_by_le[most_stable_le]),\n",
    "            )\n",
    "\n",
    "    log.info(\"✅ Enhanced throughput analysis by local experts completed!\")\n",
    "\n",
    "else:\n",
    "    log.info(\"❌ No results available for throughput analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef8cce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_cell_results_list = results_list\n",
    "if EXCLUDE_INCOMPLETE_RUNS:\n",
    "    this_cell_results_list = complete_runs\n",
    "\n",
    "if len(this_cell_results_list) > 0:\n",
    "    log.info(\"Results summary:\")\n",
    "    log.info(\n",
    "        results_df[\n",
    "            [\n",
    "                \"run_uuid\",\n",
    "                \"n_total_clients\",\n",
    "                \"global_train_batch_size\",\n",
    "                \"n_local_experts\",\n",
    "                \"overlapping_factor\",\n",
    "                \"final_perplexity\",\n",
    "                \"total_tokens\",\n",
    "            ]\n",
    "        ].head(),\n",
    "    )\n",
    "\n",
    "    # Plot 1: Final Perplexity vs Experts Density (Local Experts)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "    scatter = plt.scatter(\n",
    "        results_df[\"n_local_experts\"],\n",
    "        results_df[\"final_perplexity\"],\n",
    "        c=results_df[\"overlapping_factor\"],\n",
    "        cmap=\"viridis\",\n",
    "        s=100,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    plt.xlabel(\"Experts Density (Local Experts per Client)\")\n",
    "    plt.ylabel(\"Final Perplexity\")\n",
    "    plt.title(\"Final Perplexity vs Experts Density\")\n",
    "    plt.colorbar(scatter, label=\"Overlapping Factor\")\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    # Plot 2: Final Perplexity vs Total Clients\n",
    "    plt.subplot(2, 2, 2)\n",
    "    scatter = plt.scatter(\n",
    "        results_df[\"n_total_clients\"],\n",
    "        results_df[\"final_perplexity\"],\n",
    "        c=results_df[\"n_local_experts\"],\n",
    "        cmap=\"plasma\",\n",
    "        s=100,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    plt.xlabel(\"Total Clients\")\n",
    "    plt.ylabel(\"Final Perplexity\")\n",
    "    plt.title(\"Final Perplexity vs Total Clients\")\n",
    "    plt.colorbar(scatter, label=\"Local Experts per Client\")\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    # Plot 3: Experts Density vs Overlapping Factor\n",
    "    plt.subplot(2, 2, 3)\n",
    "    scatter = plt.scatter(\n",
    "        results_df[\"overlapping_factor\"],\n",
    "        results_df[\"n_local_experts\"],\n",
    "        c=results_df[\"final_perplexity\"],\n",
    "        cmap=\"coolwarm\",\n",
    "        s=100,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    plt.xlabel(\"Overlapping Factor\")\n",
    "    plt.ylabel(\"Experts Density\")\n",
    "    plt.title(\"Experts Density vs Overlapping Factor\")\n",
    "    plt.colorbar(scatter, label=\"Final Perplexity\")\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    # Plot 4: Total Tokens vs Final Perplexity\n",
    "    plt.subplot(2, 2, 4)\n",
    "    scatter = plt.scatter(\n",
    "        results_df[\"total_tokens\"],\n",
    "        results_df[\"final_perplexity\"],\n",
    "        c=results_df[\"n_local_experts\"],\n",
    "        cmap=\"tab10\",\n",
    "        s=100,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    plt.xlabel(\"Total Tokens\")\n",
    "    plt.ylabel(\"Final Perplexity\")\n",
    "    plt.title(\"Total Tokens vs Final Perplexity\")\n",
    "    plt.colorbar(scatter, label=\"Experts Density\")\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    log.info(\"No results to plot. Check if data was successfully processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebe3440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot detailed perplexity curves\n",
    "\n",
    "\n",
    "this_cell_results_list = results_list\n",
    "if EXCLUDE_INCOMPLETE_RUNS:\n",
    "    this_cell_results_list = complete_runs\n",
    "\n",
    "if len(this_cell_results_list) > 0:\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # Plot 1: Perplexity vs Tokens for different expert densities\n",
    "    plt.subplot(2, 2, 1)\n",
    "    for result in this_cell_results_list:\n",
    "        if result[\"tokens\"] and result[\"perplexity\"]:\n",
    "            tokens = np.array(result[\"tokens\"])\n",
    "            perplexity = np.array(result[\"perplexity\"])\n",
    "            # Only plot non-NaN values\n",
    "            valid_mask = ~np.isnan(perplexity)\n",
    "            if np.any(valid_mask):\n",
    "                label = (\n",
    "                    f\"UUID: {result['run_uuid'][:8]}...\"\n",
    "                    f\" (LE: {result['n_local_experts']},\"\n",
    "                    f\" TC: {result['n_total_clients']},\"\n",
    "                    f\" OF: {result['overlapping_factor']})\"\n",
    "                )\n",
    "                plt.plot(\n",
    "                    tokens[valid_mask],\n",
    "                    perplexity[valid_mask],\n",
    "                    label=label,\n",
    "                    linewidth=2,\n",
    "                    alpha=0.8,\n",
    "                )\n",
    "\n",
    "    plt.xlabel(\"Total Tokens\")\n",
    "    plt.ylabel(\"Perplexity\")\n",
    "    plt.title(\"Perplexity vs Tokens by Expert Configuration\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.yscale(\"log\")\n",
    "\n",
    "    # Plot 2: Convergence comparison (normalized tokens)\n",
    "    plt.subplot(2, 2, 2)\n",
    "    for result in this_cell_results_list:\n",
    "        if result[\"tokens\"] and result[\"perplexity\"]:\n",
    "            tokens = np.array(result[\"tokens\"])\n",
    "            perplexity = np.array(result[\"perplexity\"])\n",
    "            valid_mask = ~np.isnan(perplexity)\n",
    "            if np.any(valid_mask) and len(tokens[valid_mask]) > 0:\n",
    "                # Normalize tokens to [0, 1] for comparison\n",
    "                tokens_norm = (tokens[valid_mask] - tokens[valid_mask].min()) / (\n",
    "                    tokens[valid_mask].max() - tokens[valid_mask].min() + 1e-8\n",
    "                )\n",
    "                label = (\n",
    "                    f\"LE: {result['n_local_experts']},\"\n",
    "                    f\" TC: {result['n_total_clients']},\"\n",
    "                    f\" OF: {result['overlapping_factor']}\"\n",
    "                )\n",
    "                plt.plot(\n",
    "                    tokens_norm,\n",
    "                    perplexity[valid_mask],\n",
    "                    label=label,\n",
    "                    linewidth=2,\n",
    "                    alpha=0.8,\n",
    "                )\n",
    "\n",
    "    plt.xlabel(\"Normalized Training Progress\")\n",
    "    plt.ylabel(\"Perplexity\")\n",
    "    plt.title(\"Convergence Comparison (Normalized)\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.yscale(\"log\")\n",
    "\n",
    "    # Plot 3: Final performance summary\n",
    "    plt.subplot(2, 2, 3)\n",
    "    # Group by experts density for box plot\n",
    "    expert_densities = sorted(results_df[\"n_local_experts\"].unique())\n",
    "    perplexity_by_density = [\n",
    "        results_df[results_df[\"n_local_experts\"] == ed][\"final_perplexity\"].to_numpy()\n",
    "        for ed in expert_densities\n",
    "    ]\n",
    "\n",
    "    plt.boxplot(perplexity_by_density)\n",
    "    plt.xlabel(\"Local Experts\")\n",
    "    plt.ylabel(\"Final Perplexity\")\n",
    "    plt.title(\"Final Perplexity Distribution by Local Experts\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    # Plot 4: Efficiency analysis (final perplexity vs total tokens)\n",
    "    plt.subplot(2, 2, 4)\n",
    "    for result in this_cell_results_list:\n",
    "        plt.scatter(\n",
    "            result[\"total_tokens\"],\n",
    "            result[\"final_perplexity\"],\n",
    "            s=result[\"n_local_experts\"] * 50\n",
    "            + 50,  # Size proportional to expert density\n",
    "            alpha=0.7,\n",
    "            label=(\n",
    "                f\"LE: {result['n_local_experts']},\"\n",
    "                f\" TC: {result['n_total_clients']},\"\n",
    "                f\" OF: {result['overlapping_factor']}\"\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Total Tokens\")\n",
    "    plt.ylabel(\"Final Perplexity\")\n",
    "    plt.title(\"Efficiency: Final Perplexity vs Training Cost\\n(Size ∝ Local Experts)\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Summary statistics\n",
    "    log.info(\"\\n=== Summary Statistics ===\")\n",
    "    log.info(\"Number of configurations analyzed: %s\", len(results_df))\n",
    "    log.info(\n",
    "        \"Local experts range: %s - %s\",\n",
    "        results_df[\"n_local_experts\"].min(),\n",
    "        results_df[\"n_local_experts\"].max(),\n",
    "    )\n",
    "    log.info(\n",
    "        \"Overlapping factor range: %s - %s\",\n",
    "        results_df[\"overlapping_factor\"].min(),\n",
    "        results_df[\"overlapping_factor\"].max(),\n",
    "    )\n",
    "    log.info(\n",
    "        \"Final perplexity range: %s - %s\",\n",
    "        results_df[\"final_perplexity\"].min(),\n",
    "        results_df[\"final_perplexity\"].max(),\n",
    "    )\n",
    "    log.info(\n",
    "        \"Best performing configuration (lowest perplexity): UUID %s\",\n",
    "        results_df.loc[results_df[\"final_perplexity\"].idxmin(), \"run_uuid\"],\n",
    "    )\n",
    "    results_df[\"efficiency\"] = (\n",
    "        results_df[\"final_perplexity\"] / results_df[\"total_tokens\"]\n",
    "    )\n",
    "    log.info(\n",
    "        \"Most efficient configuration (lowest perplexity/token ratio): UUID %s\",\n",
    "        results_df.loc[results_df[\"efficiency\"].idxmin(), \"run_uuid\"],\n",
    "    )\n",
    "else:\n",
    "    log.info(\"No results available for plotting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ba0d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table and insights\n",
    "\n",
    "\n",
    "this_cell_results_list = results_list\n",
    "if EXCLUDE_INCOMPLETE_RUNS:\n",
    "    this_cell_results_list = complete_runs\n",
    "\n",
    "if len(this_cell_results_list) > 0:\n",
    "    log.info(\"=== Expert Density Analysis Summary Table ===\")\n",
    "\n",
    "    # Create a clean summary table\n",
    "    summary_columns = [\n",
    "        \"run_uuid\",\n",
    "        \"n_total_clients\",\n",
    "        \"global_train_batch_size\",\n",
    "        \"n_local_experts\",\n",
    "        \"overlapping_factor\",\n",
    "        \"n_total_experts\",\n",
    "        \"final_perplexity\",\n",
    "        \"total_tokens\",\n",
    "    ]\n",
    "\n",
    "    summary_df = results_df[summary_columns].copy()\n",
    "    summary_df[\"run_uuid_short\"] = summary_df[\"run_uuid\"].str[:12] + \"...\"\n",
    "    summary_df = summary_df.drop(\"run_uuid\", axis=1)\n",
    "\n",
    "    # Reorder columns for better readability\n",
    "    summary_df = summary_df[\n",
    "        [\n",
    "            \"run_uuid_short\",\n",
    "            \"n_total_clients\",\n",
    "            \"n_total_experts\",\n",
    "            \"n_local_experts\",\n",
    "            \"overlapping_factor\",\n",
    "            \"global_train_batch_size\",\n",
    "            \"final_perplexity\",\n",
    "            \"total_tokens\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Sort by final perplexity for easy comparison\n",
    "    summary_df = summary_df.sort_values(\"final_perplexity\")\n",
    "\n",
    "    log.info(summary_df.to_string(index=False, float_format=\"%.4f\"))\n",
    "\n",
    "    log.info(\"\\n=== Key Insights ===\")\n",
    "\n",
    "    # Best and worst performing configurations\n",
    "    best_idx = results_df[\"final_perplexity\"].idxmin()\n",
    "    worst_idx = results_df[\"final_perplexity\"].idxmax()\n",
    "\n",
    "    log.info(\"🏆 Best Performance:\")\n",
    "    log.info(\"   UUID: %s\", results_df.loc[best_idx, \"run_uuid\"])\n",
    "    log.info(\"   Local Experts: %s\", results_df.loc[best_idx, \"n_local_experts\"])\n",
    "    log.info(\n",
    "        \"   Overlapping Factor: %s\",\n",
    "        results_df.loc[best_idx, \"overlapping_factor\"],\n",
    "    )\n",
    "    log.info(\"   Final Perplexity: %.4f\", results_df.loc[best_idx, \"final_perplexity\"])\n",
    "\n",
    "    log.info(\"\\n📉 Worst Performance:\")\n",
    "    log.info(\"   UUID: %s\", results_df.loc[worst_idx, \"run_uuid\"])\n",
    "    log.info(\"   Local Experts: %s\", results_df.loc[worst_idx, \"n_local_experts\"])\n",
    "    log.info(\n",
    "        \"   Overlapping Factor: %s\",\n",
    "        results_df.loc[worst_idx, \"overlapping_factor\"],\n",
    "    )\n",
    "    log.info(\"   Final Perplexity: %.4f\", results_df.loc[worst_idx, \"final_perplexity\"])\n",
    "\n",
    "    # Correlation analysis\n",
    "    log.info(\"\\n🔍 Correlation Analysis:\")\n",
    "    correlations = results_df[\n",
    "        [\n",
    "            \"n_local_experts\",\n",
    "            \"overlapping_factor\",\n",
    "            \"n_total_clients\",\n",
    "            \"global_train_batch_size\",\n",
    "            \"final_perplexity\",\n",
    "            \"total_tokens\",\n",
    "        ]\n",
    "    ].corr()\n",
    "\n",
    "    perplexity_corr = correlations[\"final_perplexity\"].sort_values(\n",
    "        key=abs,\n",
    "        ascending=False,\n",
    "    )\n",
    "    log.info(\"   Correlation with Final Perplexity:\")\n",
    "    for var, corr in perplexity_corr.items():\n",
    "        if var != \"final_perplexity\":\n",
    "            log.info(\"   - %s: %.3f\", var, corr)\n",
    "\n",
    "    # Efficiency analysis\n",
    "    if \"efficiency\" in results_df.columns:\n",
    "        most_efficient_idx = results_df[\"efficiency\"].idxmin()\n",
    "        log.info(\"\\n⚡ Most Efficient Configuration:\")\n",
    "        log.info(\"   UUID: %s\", results_df.loc[most_efficient_idx, \"run_uuid\"])\n",
    "        log.info(\n",
    "            \"   Local Experts: %s\",\n",
    "            results_df.loc[most_efficient_idx, \"n_local_experts\"],\n",
    "        )\n",
    "        log.info(\n",
    "            \"   Overlapping Factor: %s\",\n",
    "            results_df.loc[most_efficient_idx, \"overlapping_factor\"],\n",
    "        )\n",
    "        log.info(\n",
    "            \"   Efficiency (Perplexity/Token): %.2e\",\n",
    "            results_df.loc[most_efficient_idx, \"efficiency\"],\n",
    "        )\n",
    "\n",
    "    # Local experts impact\n",
    "    log.info(\"\\n📊 Local Experts Impact:\")\n",
    "    experts_groups = results_df.groupby(\"n_local_experts\")[\"final_perplexity\"].agg(\n",
    "        [\"mean\", \"std\", \"count\"],\n",
    "    )\n",
    "    log.info(\"   Average Final Perplexity by Local Experts:\")\n",
    "    for n_experts, stats in experts_groups.iterrows():\n",
    "        log.info(\n",
    "            \"   - %d Local Experts: %.4f ± %.4f (n=%d)\",\n",
    "            n_experts,\n",
    "            stats[\"mean\"],\n",
    "            stats[\"std\"],\n",
    "            int(stats[\"count\"]),\n",
    "        )\n",
    "\n",
    "else:\n",
    "    log.info(\"No results available for summary analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232c08c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fedmoe-plots",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
